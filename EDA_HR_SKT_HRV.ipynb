{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import os\n",
    "\n",
    "\n",
    "DEFAULT_TZ = pytz.FixedOffset(540)  # GMT+09:00; Asia/Seoul\n",
    "\n",
    "PATH_DATA = './data'\n",
    "PATH_ESM = os.path.join(PATH_DATA, 'EsmResponse.csv')\n",
    "PATH_PARTICIPANT = os.path.join(PATH_DATA, 'UserInfo.csv')\n",
    "PATH_SENSOR = os.path.join(PATH_DATA, 'Sensor')\n",
    "\n",
    "PATH_INTERMEDIATE = './intermediate'\n",
    "\n",
    "DATA_TYPES = {\n",
    "    'EDA': 'EDA',\n",
    "    'HR': 'HRT',\n",
    "    'SkinTemperature': 'SKT',\n",
    "    'HRV': 'HRV',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import cloudpickle\n",
    "import ray\n",
    "from datetime import datetime\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "\n",
    "def load(path: str):\n",
    "    with open(path, mode='rb') as f:\n",
    "        return cloudpickle.load(f)\n",
    "    \n",
    "def dump(obj, path: str):\n",
    "    with open(path, mode='wb') as f:\n",
    "        cloudpickle.dump(obj, f)\n",
    "    \n",
    "def log(msg: any):\n",
    "    print('[{}] {}'.format(datetime.now().strftime('%y-%m-%d %H:%M:%S'), msg))\n",
    "\n",
    "def summary(x):\n",
    "    x = np.asarray(x)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        n = len(x)\n",
    "        # Here, uppercase np.dtype.kind corresponds to non-numeric data.\n",
    "        # Also, we view the boolean data as dichotomous categorical data.\n",
    "        if x.dtype.kind.isupper() or x.dtype.kind == 'b': \n",
    "            cnt = pd.Series(x).value_counts(dropna=False)\n",
    "            card = len(cnt)\n",
    "            cnt = cnt[:20]                \n",
    "            cnt_str = ', '.join([f'{u}:{c}' for u, c in zip(cnt.index, cnt)])\n",
    "            if card > 30:\n",
    "                cnt_str = f'{cnt_str}, ...'\n",
    "            return {\n",
    "                'n': n,\n",
    "                'cardinality': card,\n",
    "                'value_count': cnt_str\n",
    "            }\n",
    "        else: \n",
    "            x_nan = x[np.isnan(x)]\n",
    "            x_norm = x[~np.isnan(x)]\n",
    "            \n",
    "            tot = np.sum(x_norm)\n",
    "            m = np.mean(x_norm)\n",
    "            me = np.median(x_norm)\n",
    "            s = np.std(x_norm, ddof=1)\n",
    "            l, u = np.min(x_norm), np.max(x)\n",
    "            conf_l, conf_u = st.t.interval(0.95, len(x_norm) - 1, loc=m, scale=st.sem(x_norm))\n",
    "            n_nan = len(x_nan)\n",
    "            \n",
    "            return {\n",
    "                'n': n,\n",
    "                'sum': tot,\n",
    "                'mean': m,\n",
    "                'SD': s,\n",
    "                'med': me,\n",
    "                'range': (l, u),\n",
    "                'conf.': (conf_l, conf_u),\n",
    "                'nan_count': n_nan\n",
    "            }\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def on_ray(*args, **kwargs):\n",
    "    try:\n",
    "        if ray.is_initialized():\n",
    "            ray.shutdown()\n",
    "        ray.init(*args, **kwargs)\n",
    "        yield None\n",
    "    finally:\n",
    "        ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R\n",
    "\n",
    "# library(tidyverse)\n",
    "# library(ggforce)\n",
    "# library(ggpubr)\n",
    "# library(showtext)\n",
    "# library(rmcorr)\n",
    "# library(patchwork)\n",
    "\n",
    "# # font_add_google(\n",
    "# #     name='Source Serif Pro',\n",
    "# #     family='ssp',\n",
    "# #     db_cache=FALSE\n",
    "# # )\n",
    "\n",
    "# showtext_auto()\n",
    "\n",
    "# THEME_DEFAULT <- theme_bw(\n",
    "#     base_size=10,\n",
    "#     base_family='ssp',\n",
    "# ) + theme(\n",
    "#         axis.title.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         axis.title.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         axis.text.x=element_text(colour='grey20', size=10),\n",
    "#         axis.text.y=element_text(colour='grey20', size=10),\n",
    "#         strip.text.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         strip.text.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         legend.background=element_blank(),\n",
    "#         legend.title=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         legend.text=element_text(colour='grey20', size=10),\n",
    "#         legend.position='top',\n",
    "#         legend.box.spacing= unit(0, 'cm'),\n",
    "#         plot.subtitle=element_text(colour='grey20', size=10, hjust=.5),\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participationStartDate</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>PSS</th>\n",
       "      <th>PHQ</th>\n",
       "      <th>GHQ</th>\n",
       "      <th>particpationStartDateTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P02</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P03</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P04</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P05</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      participationStartDate  age gender  openness  conscientiousness  \\\n",
       "pcode                                                                   \n",
       "P01               2019-05-08   27      M        11                 11   \n",
       "P02               2019-05-08   21      M        14                  5   \n",
       "P03               2019-05-08   24      F        10                 15   \n",
       "P04               2019-05-08   23      M        12                 11   \n",
       "P05               2019-05-08   27      F        10                 11   \n",
       "\n",
       "       neuroticism  extraversion  agreeableness  PSS  PHQ  GHQ  \\\n",
       "pcode                                                            \n",
       "P01              3             4             13   13    0    1   \n",
       "P02             12            14              5   27    6   18   \n",
       "P03              8             7             11   18    2    6   \n",
       "P04              8             6             11   20    1    9   \n",
       "P05             13            10              6   25   14    9   \n",
       "\n",
       "      particpationStartDateTime  \n",
       "pcode                            \n",
       "P01   2019-05-08 00:00:00+09:00  \n",
       "P02   2019-05-08 00:00:00+09:00  \n",
       "P03   2019-05-08 00:00:00+09:00  \n",
       "P04   2019-05-08 00:00:00+09:00  \n",
       "P05   2019-05-08 00:00:00+09:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "PARTICIPANTS = pd.read_csv(PATH_PARTICIPANT).set_index('pcode').assign(\n",
    "    particpationStartDateTime=lambda x: pd.to_datetime(\n",
    "        x['participationStartDate'], format='%Y-%m-%d'\n",
    "    ).dt.tz_localize(DEFAULT_TZ)\n",
    ")\n",
    "PARTICIPANTS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belows are some demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- participationStartDate: {'n': 77, 'cardinality': 3, 'value_count': '2019-05-08:27, 2019-05-16:25, 2019-04-30:25'}\n",
      "- age: {'n': 77, 'sum': 1686, 'mean': 21.896103896103895, 'SD': 3.8613619617422406, 'med': 21.0, 'range': (17, 38), 'conf.': (21.019682236199852, 22.77252555600794), 'nan_count': 0}\n",
      "- gender: {'n': 77, 'cardinality': 2, 'value_count': 'M:53, F:24'}\n",
      "- openness: {'n': 77, 'sum': 787, 'mean': 10.220779220779221, 'SD': 2.8956563505732467, 'med': 11.0, 'range': (3, 15), 'conf.': (9.563545848092234, 10.878012593466208), 'nan_count': 0}\n",
      "- conscientiousness: {'n': 77, 'sum': 820, 'mean': 10.64935064935065, 'SD': 2.3662441579221882, 'med': 11.0, 'range': (5, 15), 'conf.': (10.112279104861539, 11.18642219383976), 'nan_count': 0}\n",
      "- neuroticism: {'n': 77, 'sum': 618, 'mean': 8.025974025974026, 'SD': 2.6900108881310953, 'med': 8.0, 'range': (3, 14), 'conf.': (7.4154164478204185, 8.636531604127633), 'nan_count': 0}\n",
      "- extraversion: {'n': 77, 'sum': 703, 'mean': 9.12987012987013, 'SD': 3.0015375417426937, 'med': 9.0, 'range': (3, 15), 'conf.': (8.448604674659734, 9.811135585080525), 'nan_count': 0}\n",
      "- agreeableness: {'n': 77, 'sum': 805, 'mean': 10.454545454545455, 'SD': 2.526415468527935, 'med': 11.0, 'range': (5, 15), 'conf.': (9.881119481929446, 11.027971427161464), 'nan_count': 0}\n",
      "- PSS: {'n': 77, 'sum': 1294, 'mean': 16.805194805194805, 'SD': 7.178254737745983, 'med': 16.0, 'range': (3, 32), 'conf.': (15.17593083180889, 18.434458778580723), 'nan_count': 0}\n",
      "- PHQ: {'n': 77, 'sum': 380, 'mean': 4.935064935064935, 'SD': 4.609308837152732, 'med': 4.0, 'range': (0, 19), 'conf.': (3.8888801582705144, 5.981249711859356), 'nan_count': 0}\n",
      "- GHQ: {'n': 77, 'sum': 780, 'mean': 10.12987012987013, 'SD': 5.894579689829796, 'med': 10.0, 'range': (1, 27), 'conf.': (8.791964653154256, 11.467775606586002), 'nan_count': 0}\n",
      "- particpationStartDateTime: {'n': 77, 'cardinality': 3, 'value_count': '2019-05-08 00:00:00+09:00:27, 2019-05-16 00:00:00+09:00:25, 2019-04-30 00:00:00+09:00:25'}\n"
     ]
    }
   ],
   "source": [
    "for c in PARTICIPANTS.columns:\n",
    "    print(f'- {c}:', summary(PARTICIPANTS[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels (via ESM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responseTime</th>\n",
       "      <th>scheduledTime</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>attention</th>\n",
       "      <th>stress</th>\n",
       "      <th>duration</th>\n",
       "      <th>disturbance</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557278103000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557278986000</td>\n",
       "      <td>1.557279e+12</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557281772000</td>\n",
       "      <td>1.557282e+12</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557287138000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557291117000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        responseTime  scheduledTime  valence  arousal  attention  stress  \\\n",
       "pcode                                                                      \n",
       "P01    1557278103000            NaN        0        0          0      -1   \n",
       "P01    1557278986000   1.557279e+12       -3        3          3       3   \n",
       "P01    1557281772000   1.557282e+12       -3       -2          2       2   \n",
       "P01    1557287138000            NaN        2       -1          2       0   \n",
       "P01    1557291117000            NaN        3        3          3      -3   \n",
       "\n",
       "       duration  disturbance  change  \n",
       "pcode                                 \n",
       "P01        20.0            3      -2  \n",
       "P01         5.0           -1      -3  \n",
       "P01        15.0            3      -2  \n",
       "P01        15.0            1      -1  \n",
       "P01        20.0            1       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "LABELS = pd.read_csv(PATH_ESM).set_index(\n",
    "    ['pcode']\n",
    ")\n",
    "LABELS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- responseTime: {'n': 5582, 'sum': 8694314195328000, 'mean': 1557562557385.8833, 'SD': 590915040.4254278, 'med': 1557562969500.0, 'range': (1556582982000, 1558545246000), 'conf.': (1557547052362.8618, 1557578062408.9048), 'nan_count': 0}\n",
      "- scheduledTime: {'n': 5582, 'sum': 5175814282500000.0, 'mean': 1557572760306.9517, 'SD': 591697484.8543198, 'med': 1557565860000.0, 'range': (1556586120000.0, nan), 'conf.': (1557552635074.4736, 1557592885539.4297), 'nan_count': 2259}\n",
      "- valence: {'n': 5582, 'sum': 3665, 'mean': 0.6565747044070226, 'SD': 1.4184297545899174, 'med': 1.0, 'range': (-3, 3), 'conf.': (0.6193565182132938, 0.6937928906007513), 'nan_count': 0}\n",
      "- arousal: {'n': 5582, 'sum': -529, 'mean': -0.09476890003582945, 'SD': 1.6675313128774563, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.13852326339835566, -0.051014536673303246), 'nan_count': 0}\n",
      "- attention: {'n': 5582, 'sum': 2236, 'mean': 0.4005732712289502, 'SD': 1.6113242733571864, 'med': 1.0, 'range': (-3, 3), 'conf.': (0.3582937246879792, 0.4428528177699212), 'nan_count': 0}\n",
      "- stress: {'n': 5582, 'sum': -1450, 'mean': -0.25976352561805804, 'SD': 1.6154902647587075, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.30215238363050767, -0.21737466760560845), 'nan_count': 0}\n",
      "- duration: {'n': 5582, 'sum': 141955.0, 'mean': 26.390593047034766, 'SD': 18.060980770860386, 'med': 20.0, 'range': (5.0, nan), 'conf.': (25.90782735251826, 26.87335874155127), 'nan_count': 203}\n",
      "- disturbance: {'n': 5582, 'sum': -243, 'mean': -0.04353278394840559, 'SD': 1.7587124884936127, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.0896796506833856, 0.0026140827865744204), 'nan_count': 0}\n",
      "- change: {'n': 5582, 'sum': -52, 'mean': -0.009315657470440702, 'SD': 0.9046571244275675, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.03305296077324875, 0.014421645832367342), 'nan_count': 0}\n"
     ]
    }
   ],
   "source": [
    "for c in LABELS.columns:\n",
    "    print(f'- {c}:', summary(LABELS[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belows are some demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- # Inst.: {'n': 77, 'sum': 5582, 'mean': 72.49350649350649, 'SD': 16.02270048911147, 'med': 74.0, 'range': (20, 110), 'conf.': (68.85679957559911, 76.13021341141386), 'nan_count': 0}\n",
      "- # Inst. - Scheduled: {'n': 76, 'sum': 3323, 'mean': 43.723684210526315, 'SD': 19.36291898394835, 'med': 43.5, 'range': (3, 83), 'conf.': (39.29906768359284, 48.14830073745979), 'nan_count': 0}\n",
      "- # Inst. - Voluntary: {'n': 77, 'sum': 2259, 'mean': 29.337662337662337, 'SD': 16.297893300742235, 'med': 27.0, 'range': (2, 74), 'conf.': (25.638494313245726, 33.03683036207895), 'nan_count': 0}\n",
      "- Samp. period: {'n': 5505, 'sum': 42240670.0, 'mean': 7673.146230699364, 'SD': 13193.471538029606, 'med': 3090.0, 'range': (1.0, 136446.0), 'conf.': (7324.548923384188, 8021.743538014541), 'nan_count': 0}\n",
      "- responseTime: {'n': 5582, 'sum': 8694314195328000, 'mean': 1557562557385.8833, 'SD': 590915040.4254278, 'med': 1557562969500.0, 'range': (1556582982000, 1558545246000), 'conf.': (1557547052362.8618, 1557578062408.9048), 'nan_count': 0}\n",
      "- scheduledTime: {'n': 5582, 'sum': 5175814282500000.0, 'mean': 1557572760306.9517, 'SD': 591697484.8543198, 'med': 1557565860000.0, 'range': (1556586120000.0, nan), 'conf.': (1557552635074.4736, 1557592885539.4297), 'nan_count': 2259}\n",
      "- valence: {'n': 5582, 'sum': 3665, 'mean': 0.6565747044070226, 'SD': 1.4184297545899174, 'med': 1.0, 'range': (-3, 3), 'conf.': (0.6193565182132938, 0.6937928906007513), 'nan_count': 0}\n",
      "- arousal: {'n': 5582, 'sum': -529, 'mean': -0.09476890003582945, 'SD': 1.6675313128774563, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.13852326339835566, -0.051014536673303246), 'nan_count': 0}\n",
      "- attention: {'n': 5582, 'sum': 2236, 'mean': 0.4005732712289502, 'SD': 1.6113242733571864, 'med': 1.0, 'range': (-3, 3), 'conf.': (0.3582937246879792, 0.4428528177699212), 'nan_count': 0}\n",
      "- stress: {'n': 5582, 'sum': -1450, 'mean': -0.25976352561805804, 'SD': 1.6154902647587075, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.30215238363050767, -0.21737466760560845), 'nan_count': 0}\n",
      "- duration: {'n': 5582, 'sum': 141955.0, 'mean': 26.390593047034766, 'SD': 18.060980770860386, 'med': 20.0, 'range': (5.0, nan), 'conf.': (25.90782735251826, 26.87335874155127), 'nan_count': 203}\n",
      "- disturbance: {'n': 5582, 'sum': -243, 'mean': -0.04353278394840559, 'SD': 1.7587124884936127, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.0896796506833856, 0.0026140827865744204), 'nan_count': 0}\n",
      "- change: {'n': 5582, 'sum': -52, 'mean': -0.009315657470440702, 'SD': 0.9046571244275675, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.03305296077324875, 0.014421645832367342), 'nan_count': 0}\n"
     ]
    }
   ],
   "source": [
    "inst = LABELS.groupby('pcode').count().iloc[:, -1]\n",
    "inst_sch = LABELS.loc[lambda x: ~x['scheduledTime'].isna(), :].groupby('pcode').count().iloc[:, -1]\n",
    "inst_vol = LABELS.loc[lambda x: x['scheduledTime'].isna(), :].groupby('pcode').count().iloc[:, -1]\n",
    "resp_time = LABELS.assign(\n",
    "    timestamp=lambda x: pd.to_datetime(x['responseTime'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    ")\n",
    "sam = np.concatenate([\n",
    "    (resp_time.loc[p, 'timestamp'].array - resp_time.loc[p, 'timestamp'].array.shift(1)).dropna().total_seconds()\n",
    "    for p in LABELS.index.unique()\n",
    "])\n",
    "\n",
    "print('- # Inst.:', summary(inst))\n",
    "print('- # Inst. - Scheduled:', summary(inst_sch))\n",
    "print('- # Inst. - Voluntary:', summary(inst_vol))\n",
    "print('- Samp. period:', summary(sam))\n",
    "for c in LABELS.columns:\n",
    "    print(f'- {c}:', summary(LABELS[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LABELS.loc[\n",
    "    :, lambda x: ~x.columns.isin(['responseTime', 'scheduledTime'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R -i data -w 16 -h 6 -u cm\n",
    "\n",
    "# data <- data %>% pivot_longer(\n",
    "#     cols = c('valence', 'arousal', 'attention', 'stress', 'duration', 'disturbance', 'change'),\n",
    "#     names_to = 'metric'\n",
    "# )\n",
    "\n",
    "# p_rest <- ggplot(\n",
    "#     data %>% filter(metric != 'duration'), aes(x=metric, y=value)\n",
    "# ) + geom_boxplot(\n",
    "# ) + geom_point(\n",
    "#     data = data %>% filter(\n",
    "#         metric != 'duration'\n",
    "#     ) %>% group_by(\n",
    "#         metric\n",
    "#     ) %>% summarise(\n",
    "#         mean = mean(value, na.rm=TRUE)\n",
    "#     ),\n",
    "#     mapping=aes(x=metric, y=mean),\n",
    "#     shape=21,\n",
    "#     stroke=1,\n",
    "#     size=2,\n",
    "#     fill='white'\n",
    "# ) + scale_x_discrete(\n",
    "#     name=NULL,\n",
    "#     limits=c('valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'),\n",
    "#     labels=c('Valence', 'Arousal', 'Stress', 'Attent.', 'Disturb.', 'Change'),\n",
    "# ) + scale_y_continuous(\n",
    "#     name='Response',\n",
    "#     breaks=-3:3\n",
    "# ) + THEME_DEFAULT\n",
    "\n",
    "# p_duration <- ggplot(\n",
    "#     data %>% filter(metric == 'duration'), aes(x=metric, y=value)\n",
    "# ) + geom_boxplot(\n",
    "# ) + geom_point(\n",
    "#     data = data %>% filter(\n",
    "#         metric == 'duration'\n",
    "#     ) %>% group_by(\n",
    "#         metric\n",
    "#     ) %>% summarise(\n",
    "#         mean = mean(value, na.rm=TRUE)\n",
    "#     ),\n",
    "#     mapping=aes(x=metric, y=mean),\n",
    "#     shape=21,\n",
    "#     stroke=1,\n",
    "#     size=2,\n",
    "#     fill='white'\n",
    "# )+ scale_x_discrete(\n",
    "#     name=NULL,\n",
    "#     limits=c('duration'),\n",
    "#     labels=c('Duration'),\n",
    "# ) + scale_y_continuous(\n",
    "#     name=NULL,\n",
    "#     breaks=seq(from=5, to=60, by=10)\n",
    "# ) + THEME_DEFAULT\n",
    "\n",
    "# p <- p_rest + p_duration + plot_layout(widths=c(4, 0.8))\n",
    "# ggsave('./fig/dist-labels.pdf', plot=p, width=16, height=6, unit='cm', device=cairo_pdf)\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each participant reported their labels multiple times (i.e., repeated measure), repeated measure correlation between affect labels were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LABELS.reset_index()[[\n",
    "    'pcode', 'valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R -i data \n",
    "\n",
    "# com <- combn(c('valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'), 2)\n",
    "\n",
    "# for(i in 1:ncol(com)) {\n",
    "#     a <- com[, i][1]\n",
    "#     b <- com[, i][2]\n",
    "#     r <- rmcorr(participant = 'pcode', measure1=a, measure2=b, dataset=data)\n",
    "#     cat(a, '-', b, ': R =', r$r, '(p =', r$p, ') \\n')\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def _load_data(\n",
    "    name: str\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    paths = [\n",
    "        (d, os.path.join(PATH_SENSOR, d, f'{name}.csv'))\n",
    "        for d in os.listdir(PATH_SENSOR)\n",
    "        if d.startswith('P')\n",
    "    ]\n",
    "    return pd.concat(\n",
    "        filter(\n",
    "            lambda x: len(x.index), \n",
    "            [\n",
    "                pd.read_csv(p).assign(pcode=pcode)\n",
    "                for pcode, p in paths\n",
    "                if os.path.exists(p)\n",
    "            ]\n",
    "        ), ignore_index=True\n",
    "    ).assign(\n",
    "        timestamp=lambda x: pd.to_datetime(x['timestamp'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    "    ).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from datetime import timedelta as td\n",
    "\n",
    "\n",
    "# STATS = []\n",
    "\n",
    "# for data_type in DATA_TYPES:\n",
    "#     dat = _load_data(data_type)\n",
    "#     inst = dat.groupby('pcode').count().iloc[:, -1]\n",
    "#     samp = np.concatenate([\n",
    "#         (dat.loc[(p,), :].index.array - dat.loc[(p,), :].index.array.shift(1)).dropna().total_seconds()\n",
    "#         for p in dat.index.get_level_values('pcode').unique()\n",
    "#     ])\n",
    "#     inst, samp = summary(inst), summary(samp)\n",
    "    \n",
    "#     print('#'*5, data_type, '#'*5)\n",
    "#     print('- # Inst.:', inst)\n",
    "#     print('- Samp. period:', samp)\n",
    "    \n",
    "#     for c in dat.columns:\n",
    "#         print(f'- {c}:', summary(dat[c]))\n",
    "        \n",
    "#     del dat\n",
    "#     gc.collect()\n",
    "    \n",
    "# STATS = pd.DataFrame(STATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label\n",
    "\n",
    "Because we intended to collected participants' responses to ESMs not voluntary responses, we screend out some responses as follows:\n",
    "* We first screen out ESM responses that does not have 'scheduledTime' (meaning that a given ESM was expired or participants voluntarily reported their affective states regardless of ESM delivery). \n",
    "* Since we will evaluate our model using LOSO, the small number of responses for each participant might lead to inappropriate performance evaluation. We emprically set the number of the minimum responses upon ESM delivery as 5 per day (i.e., a half of our guides), so that we excluded participants whose responses to ESM less than 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Non-voluntary response: 3323\n",
      "{'n': 76, 'sum': 3323, 'mean': 43.723684210526315, 'SD': 19.36291898394835, 'med': 43.5, 'range': (3, 83), 'conf.': (39.29906768359284, 48.14830073745979), 'nan_count': 0}\n",
      "# Response from participants with enough responses: 2619\n",
      "{'n': 47, 'sum': 2619, 'mean': 55.723404255319146, 'SD': 13.076201628480542, 'med': 52.0, 'range': (36, 83), 'conf.': (51.88408763344431, 59.56272087719398), 'nan_count': 0}\n",
      "# Participants whose responses to ESM delivery were less then 35\n",
      "pcode\n",
      "P04    34\n",
      "P07    24\n",
      "P11    22\n",
      "P14    11\n",
      "P16    30\n",
      "P17    13\n",
      "P18    32\n",
      "P20    31\n",
      "P22    23\n",
      "P24    10\n",
      "P25    30\n",
      "P29    32\n",
      "P34    22\n",
      "P36    29\n",
      "P37    31\n",
      "P38    33\n",
      "P41    31\n",
      "P43    24\n",
      "P44    23\n",
      "P46     4\n",
      "P54    13\n",
      "P56    31\n",
      "P58    29\n",
      "P62     3\n",
      "P63    34\n",
      "P64    30\n",
      "P68    11\n",
      "P73    31\n",
      "P74    33\n",
      "Name: change, dtype: int64 #participants = 29 / #response = 704\n"
     ]
    }
   ],
   "source": [
    "LABELS_VALID = LABELS.loc[\n",
    "    lambda x: ~x['scheduledTime'].isna(), :\n",
    "]\n",
    "print(f'# Non-voluntary response: {len(LABELS_VALID)}')\n",
    "print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "excl_pcode = LABELS_VALID.loc[\n",
    "    lambda x: ~x['scheduledTime'].isna()\n",
    "].groupby('pcode').count().iloc[:, -1].loc[lambda y: y < 35]\n",
    "\n",
    "LABELS_VALID = LABELS_VALID.loc[\n",
    "    lambda x:  ~x.index.get_level_values('pcode').isin(excl_pcode.index), :\n",
    "]\n",
    "print(f'# Response from participants with enough responses: {len(LABELS_VALID)}')\n",
    "print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "print('# Participants whose responses to ESM delivery were less then 35')\n",
    "print(excl_pcode, f'#participants = {len(excl_pcode)} / #response = {sum(excl_pcode)}')\n",
    "\n",
    "# LABELS_VALID # 47명 데이터 only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider binary classifications for valence, arousal, stress, and disturbance, in which a label value greater than 0 is \"HIGH\" (1) and the rest is \"LOW\" (0), at the arrival of ESM prompts (*scheduledTime*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>attention</th>\n",
       "      <th>attention_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P01</th>\n",
       "      <th>2019-05-08 10:26:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 11:13:00+09:00</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 15:56:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 16:41:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 17:23:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P80</th>\n",
       "      <th>2019-05-05 21:57:00+09:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06 15:06:00+09:00</th>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06 15:53:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06 19:39:00+09:00</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06 21:08:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 attention  attention_bin\n",
       "pcode timestamp                                          \n",
       "P01   2019-05-08 10:26:00+09:00          3              1\n",
       "      2019-05-08 11:13:00+09:00          2              1\n",
       "      2019-05-08 15:56:00+09:00          3              1\n",
       "      2019-05-08 16:41:00+09:00          3              1\n",
       "      2019-05-08 17:23:00+09:00          3              1\n",
       "...                                    ...            ...\n",
       "P80   2019-05-05 21:57:00+09:00         -3              0\n",
       "      2019-05-06 15:06:00+09:00         -2              0\n",
       "      2019-05-06 15:53:00+09:00          3              1\n",
       "      2019-05-06 19:39:00+09:00         -1              0\n",
       "      2019-05-06 21:08:00+09:00          3              1\n",
       "\n",
       "[2619 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LABELS_PROC = (\n",
    "    LABELS_VALID\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        timestamp=lambda x: pd.to_datetime(x['scheduledTime'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ),\n",
    "        attention_bin=lambda x: np.where(x['attention'] > 0, 1, 0)\n",
    "    )\n",
    "    .loc[:, ['pcode', 'timestamp', 'attention', 'attention_bin']]  # attention: 연속형, attention_bin: 이진분류된 데이터\n",
    "    .set_index(['pcode', 'timestamp'])\n",
    ")\n",
    "\n",
    "LABELS_PROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- attention_bin: {'n': 2619, 'cardinality': 2, 'value_count': '0:1312, 1:1307'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "inst = LABELS_PROC.groupby('pcode').count().iloc[:, -1]\n",
    "for c in [c for c in LABELS_PROC.columns if c.endswith('_bin')]:\n",
    "    print(f'- {c}:', summary(LABELS_PROC[c].astype(object)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each type of sensor data, we applied different preprocessing. Detailed decsription is provided in the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from typing import Dict, Union\n",
    "import pygeohash as geo\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "# SkinTemperature.csv\n",
    "def _proc_skin_temperature(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['temperature'].astype('float32')\n",
    "\n",
    "# # RRI.csv\n",
    "# def _proc_rri(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "#     return data['interval'].astype('float32')\n",
    "\n",
    "# HR.csv\n",
    "def _proc_hr(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['bpm'].astype('float32')\n",
    "    \n",
    "# EDA.csv\n",
    "def _proc_eda(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['resistance'].astype('float32')\n",
    "\n",
    "# HRV.csv\n",
    "def _proc_hrv(data: pd.DataFrame) -> Dict[str, pd.Series]:\n",
    "    return {\n",
    "        'ln_lf': data['ln_lf'].astype('float32'),\n",
    "        'ln_hf': data['ln_hf'].astype('float32')\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 16:26:07,044\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_process pid=1117)\u001b[0m [25-05-22 16:26:07] Begin to processing data: SkinTemperature\n",
      "\u001b[2m\u001b[36m(_process pid=1110)\u001b[0m [25-05-22 16:26:07] Begin to processing data: HR\n",
      "\u001b[2m\u001b[36m(_process pid=1108)\u001b[0m [25-05-22 16:26:07] Begin to processing data: EDA\n",
      "\u001b[2m\u001b[36m(_process pid=1113)\u001b[0m [25-05-22 16:26:07] Begin to processing data: HRV\n",
      "\u001b[2m\u001b[36m(_process pid=1113)\u001b[0m [25-05-22 16:26:08] Complete processing data: HRV\n",
      "\u001b[2m\u001b[36m(_process pid=1117)\u001b[0m [25-05-22 16:26:09] Complete processing data: SkinTemperature\n",
      "\u001b[2m\u001b[36m(_process pid=1110)\u001b[0m [25-05-22 16:26:16] Complete processing data: HR\n",
      "\u001b[2m\u001b[36m(_process pid=1108)\u001b[0m [25-05-22 16:26:54] Complete processing data: EDA\n",
      "[25-05-22 16:27:00] [SAVE] done in 5.5s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from functools import reduce\n",
    "import time\n",
    "\n",
    "FUNC_PROC = {\n",
    "    'EDA': _proc_eda,\n",
    "    'HR': _proc_hr,\n",
    "    'SkinTemperature': _proc_skin_temperature,\n",
    "    'HRV': _proc_hrv,\n",
    "}\n",
    "\n",
    "\n",
    "def _process(data_type: str):\n",
    "    log(f'Begin to processing data: {data_type}')\n",
    "    \n",
    "    abbrev = DATA_TYPES[data_type]\n",
    "    data_raw = _load_data(data_type)\n",
    "    data_proc = FUNC_PROC[data_type](data_raw)\n",
    "    result = dict()\n",
    "    \n",
    "    if type(data_proc) is dict:\n",
    "        for k, v in data_proc.items():\n",
    "            result[f'{abbrev}_{k}'] = v\n",
    "    else:\n",
    "        result[abbrev] = data_proc\n",
    "        \n",
    "    log(f'Complete processing data: {data_type}')\n",
    "    return result\n",
    "\n",
    "\n",
    "with on_ray(num_cpus=12):\n",
    "    jobs = []\n",
    "    \n",
    "    func = ray.remote(_process).remote\n",
    "    \n",
    "    for data_type in DATA_TYPES:\n",
    "        job = func(data_type)\n",
    "        jobs.append(job)\n",
    "\n",
    "    jobs = ray.get(jobs)\n",
    "    \n",
    "    # 메모리 최적화를 위해 추가 \n",
    "    combined_result = {}\n",
    "    for d in jobs:\n",
    "        combined_result |= d\n",
    "    \n",
    "    t0 = time.time()\n",
    "    dump(combined_result, os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "    log(f'[SAVE] done in {time.time() - t0:.1f}s')\n",
    "    \n",
    "    del jobs\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### EDA #####\n",
      "- # Inst.: {'n': 77, 'sum': 80150329, 'mean': 1040913.3636363636, 'SD': 306422.1210160014, 'med': 1046093.0, 'range': (314771, 1615971), 'conf.': (971364.0733618538, 1110462.6539108735), 'nan_count': 0}\n",
      "- Samp. period: {'n': 80150252, 'sum': 41213631.2559998, 'mean': 0.5142046372605267, 'SD': 140.54682607352436, 'med': 0.199, 'range': (0.001, 347546.153), 'conf.': (0.48343540259511497, 0.5449738719259384), 'nan_count': 0}\n",
      "- Values {'n': 80150329, 'sum': 4456726400000.0, 'mean': 55604.594, 'SD': 121898.18, 'med': 1385.0, 'range': (0.0, 340330.0), 'conf.': (55577.907185819015, 55631.280314180985), 'nan_count': 0}\n",
      "\n",
      "##### HRT #####\n",
      "- # Inst.: {'n': 77, 'sum': 13621023, 'mean': 176896.4025974026, 'SD': 52558.47787145981, 'med': 191711.0, 'range': (38545, 266374), 'conf.': (164967.0914179474, 188825.7137768578), 'nan_count': 0}\n",
      "- Samp. period: {'n': 13620946, 'sum': 40968427.92100001, 'mean': 3.007752025520108, 'SD': 362.9172458474607, 'med': 0.996, 'range': (0.001, 351677.643), 'conf.': (2.8150207922568877, 3.200483258783328), 'nan_count': 0}\n",
      "- Values {'n': 13621023, 'sum': 1029728450.0, 'mean': 75.598465, 'SD': 9.820566, 'med': 75.0, 'range': (35.0, 199.0), 'conf.': (75.59324965984483, 75.6036802717958), 'nan_count': 0}\n",
      "\n",
      "##### SKT #####\n",
      "- # Inst.: {'n': 77, 'sum': 535095, 'mean': 6949.285714285715, 'SD': 2044.9192742858738, 'med': 7010.0, 'range': (2095, 10770), 'conf.': (6485.145972273351, 7413.425456298079), 'nan_count': 0}\n",
      "- Samp. period: {'n': 535018, 'sum': 41212170.552, 'mean': 77.02950284289501, 'SD': 1719.1916269814037, 'med': 30.082, 'range': (0.006, 347555.636), 'conf.': (72.42281097588156, 81.63619470990847), 'nan_count': 0}\n",
      "- Values {'n': 535095, 'sum': 17310050.0, 'mean': 32.34949, 'SD': 2.1008396, 'med': 32.66, 'range': (0.0, 41.17), 'conf.': (32.34386218060751, 32.35512005816202), 'nan_count': 0}\n",
      "\n",
      "##### HRV_ln_lf #####\n",
      "- # Inst.: {'n': 77, 'sum': 55664, 'mean': 722.9090909090909, 'SD': 209.9439262115245, 'med': 730.0, 'range': (216, 1103), 'conf.': (675.2576647749669, 770.5605170432149), 'nan_count': 0}\n",
      "- Samp. period: {'n': 55587, 'sum': 41050800.0, 'mean': 738.4964110313563, 'SD': 5290.8837028180005, 'med': 300.0, 'range': (300.0, 347700.0), 'conf.': (694.5119631059084, 782.4808589568041), 'nan_count': 0}\n",
      "- Values {'n': 55664, 'sum': 418780.12, 'mean': 7.5233564, 'SD': 1.0702163, 'med': 7.6343374, 'range': (-7.8358183, 10.9134655), 'conf.': (7.51446561621677, 7.532247259149441), 'nan_count': 0}\n",
      "\n",
      "##### HRV_ln_hf #####\n",
      "- # Inst.: {'n': 77, 'sum': 55664, 'mean': 722.9090909090909, 'SD': 209.9439262115245, 'med': 730.0, 'range': (216, 1103), 'conf.': (675.2576647749669, 770.5605170432149), 'nan_count': 0}\n",
      "- Samp. period: {'n': 55587, 'sum': 41050800.0, 'mean': 738.4964110313563, 'SD': 5290.8837028180005, 'med': 300.0, 'range': (300.0, 347700.0), 'conf.': (694.5119631059084, 782.4808589568041), 'nan_count': 0}\n",
      "- Values {'n': 55664, 'sum': 437842.0, 'mean': 7.865802, 'SD': 2.579671, 'med': 8.428768, 'range': (-13.811026, 10.213345), 'conf.': (7.844371196202972, 7.887232426233552), 'nan_count': 0}\n",
      "\n",
      "# categorical data: 0/# numeric data: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "DATA = load(os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "#categorial, numeric 변수 수 계산\n",
    "N_NUMERIC, N_CATEGORICAL = 0, 0\n",
    "\n",
    "for k, v in DATA.items():\n",
    "    if v.dtype.kind.isupper() or v.dtype.kind == 'b': \n",
    "        N_CATEGORICAL = N_CATEGORICAL + 1\n",
    "    else:\n",
    "        N_NUMERIC = N_NUMERIC + 1\n",
    "        \n",
    "    inst = v.groupby('pcode').count()\n",
    "    sam = np.concatenate([\n",
    "        (v.loc[(p,)].index.array - v.loc[(p,)].index.array.shift(1)).dropna().total_seconds()\n",
    "        for p in v.index.get_level_values('pcode').unique()\n",
    "    ])\n",
    "    \n",
    "    print('#'*5, k, '#'*5, )\n",
    "    print('- # Inst.:', summary(inst))\n",
    "    print('- Samp. period:', summary(sam))\n",
    "    print('- Values', summary(v))\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "print(f'# categorical data: {N_CATEGORICAL}/# numeric data: {N_NUMERIC}')\n",
    "del DATA\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Callable, Union, Tuple, List, Optional, Iterable\n",
    "from datetime import timedelta as td\n",
    "from scipy import stats\n",
    "from scipy.interpolate import CubicSpline\n",
    "import ray\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# _extract: 한 명의 참가자로부터 feature 추출\n",
    "# data, label(timestamp별 정답값), label_values(라벨 클래스 목록), window_data, window_label, categories, const_features, resample\n",
    "# time window별 통합: 수치형 센서 - mean, std, skewness, kurtosis, median, 시계열 복잡도, 변화량 절댓값 합, 히스토그램 기반 엔트로피\n",
    "# 시간대별 패턴: 비정기적 설문조사 주기에 맞게 하루를 7개의 시간대로 분할, one-hot encoding \n",
    "# 최종 feature 예시: ESM#LIK#H24\n",
    "# extract: 여러 참가자에게 _extract함수 -> 통합\n",
    "\n",
    "# 최종 학습 데이터 형태: X(각 참가자, 각 시점에 대한 Feature, DataFrame), y(label, ndarray), group(LOSO시 각 행에 속한 참가자 ID, ndarray), t_norm(응답시간 timestamp를 정규화한 시간 정보), date_times(각 데이터 포인트으ㅢ 실제 timestamp)\n",
    "# X: PIF#AGE, ACC#AVG#H06, APP_CAT#DUR=COMMUNICATION#H01, ESM#HRN=MORNING  . . .\n",
    "# y: np.array([1, 0, 1, 1  . . .\n",
    "# group:  np.array(['P01', 'P01', 'P02' . . .\n",
    "# t_norm: np.array([0.0, 10800.0, 3600.0, 7200.0 . . .\n",
    "# date_times: np.array([\n",
    "#     Timestamp('2025-05-01 10:00:00'),\n",
    "#     Timestamp('2025-05-01 13:00:00'),\n",
    "#     Timestamp('2025-05-01 11:00:00'), . . .\n",
    "\n",
    "def _safe_na_check(_v):\n",
    "    _is_nan_inf = False\n",
    "    try:\n",
    "        _is_nan_inf = np.isnan(_v) or np.isinf(_v)\n",
    "    except:\n",
    "        _is_nan_inf = False\n",
    "    return _is_nan_inf or _v is None\n",
    "\n",
    "\n",
    "def _extract(\n",
    "        pid: str,\n",
    "        data: Dict[str, pd.Series],\n",
    "        label: pd.Series,\n",
    "        label_values: List[str],\n",
    "        window_data: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],\n",
    "        window_label: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],        \n",
    "        categories: Dict[str, Optional[List[any]]] = None,        \n",
    "        resample_s: Dict[str, float] = None\n",
    ") -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    _s = time.time()\n",
    "    log(f\"Begin feature extraction on {pid}'s data.\")\n",
    "\n",
    "    categories = categories or dict()\n",
    "    resample_s = resample_s or dict()\n",
    "\n",
    "    X, y, date_times = [], [], []\n",
    " \n",
    "    for timestamp in label.index:\n",
    "        row = dict()\n",
    "\n",
    "        label_cur = label.at[timestamp]\n",
    "        t = timestamp - td(milliseconds=1)\n",
    "\n",
    "        # Features from sensor data\n",
    "        for d_key, d_val in data.items():\n",
    "            is_numeric = d_key not in categories\n",
    "            cats = categories.get(d_key) or list()\n",
    "            d_val = d_val.sort_index()\n",
    "\n",
    "            if is_numeric or cats:\n",
    "                try:\n",
    "                    v = d_val.loc[:t].iloc[-1]\n",
    "                except (KeyError, IndexError):\n",
    "                    v = 0\n",
    "\n",
    "                if is_numeric:\n",
    "                    row[f'{d_key}#VAL'] = v\n",
    "                else:\n",
    "                    for c in cats:\n",
    "                        row[f'{d_key}#VAL={c}'] = v == c\n",
    "\n",
    "            # catogorial 데이터의 최근 상태 변화 시간\n",
    "            if not is_numeric:\n",
    "                try:\n",
    "                    v = d_val.loc[:t]\n",
    "                    row[f'{d_key}#DSC'] = (t - v.index[-1]).total_seconds() if len(v) else -1.0\n",
    "                    for c in cats:\n",
    "                        v_sub = v.loc[lambda x: x == c].index\n",
    "                        row[f'{d_key}#DSC={c}'] = (t - v_sub[-1]).total_seconds() if len(v_sub) else -1.0\n",
    "                except (KeyError, IndexError):\n",
    "                    row[f'{d_key}#DSC'] = -1.0\n",
    "                    for c in cats:\n",
    "                        row[f'{d_key}#DSC={c}'] = -1.0\n",
    "\n",
    "            # Time-window 기반 피처 (resampling 포함)\n",
    "            sample_rate = resample_s.get(d_key, 1)\n",
    "            if isinstance(sample_rate, (float, int)):\n",
    "                freq_str = f'{int(sample_rate * 1000)}ms'\n",
    "            else:\n",
    "                freq_str = sample_rate  # 이미 문자열일 경우 ('250ms' 등)\n",
    "\n",
    "            d_val_res = d_val.resample(freq_str, origin='start')\n",
    "\n",
    "            if is_numeric:\n",
    "                \"\"\" 보간 방식 추가 부분 \"\"\"\n",
    "                if d_key == \"interval\":\n",
    "                    interval_series = d_val.dropna()\n",
    "                    if len(interval_series) >= 4:\n",
    "                        ts = interval_series.index.view(np.int64) // 10**6\n",
    "                        cs = CubicSpline(ts, interval_series.values)\n",
    "                        full_ts = d_val.index.view(np.int64) // 10**6\n",
    "                        d_val[:] = cs(full_ts)\n",
    "                else: \n",
    "                    d_val_res = d_val_res.mean().interpolate(method='linear').dropna()\n",
    "            else:\n",
    "                d_val_res = d_val_res.ffill().dropna()\n",
    "\n",
    "            for w_key, w_val in window_data.items():\n",
    "                w_val = w_val(t) if isinstance(w_val, Callable) else w_val\n",
    "                try:\n",
    "                    v = d_val_res.loc[t - td(seconds=w_val):t]\n",
    "                    # numeric 데이터일 경우에만 변환\n",
    "                    if is_numeric:\n",
    "                        v_arr = v.values.astype(np.float64)\n",
    "                    else:\n",
    "                        v_arr = v\n",
    "                except (KeyError, IndexError):\n",
    "                    continue\n",
    "\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter('ignore')\n",
    "\n",
    "                    if is_numeric:\n",
    "                        hist, _ = np.histogram(v, bins='doane', density=False)\n",
    "                        std = np.sqrt(np.var(v, ddof=1)) if len(v) > 1 else 0\n",
    "                        v_norm = (v - np.mean(v)) / std if std != 0 else np.zeros(len(v))\n",
    "\n",
    "                        row[f'{d_key}#AVG#{w_key}'] = np.float32(np.mean(v_arr))\n",
    "                        row[f'{d_key}#STD#{w_key}'] = np.float32(std)\n",
    "                        row[f'{d_key}#SKW#{w_key}'] = np.float32(stats.skew(v_arr, bias=False))\n",
    "                        row[f'{d_key}#KUR#{w_key}'] = np.float32(stats.kurtosis(v_arr, bias=False))\n",
    "                        row[f'{d_key}#ASC#{w_key}'] = np.float32(np.sum(np.abs(np.diff(v_arr))))\n",
    "                        row[f'{d_key}#BEP#{w_key}'] = np.float32(stats.entropy(hist))\n",
    "                        row[f'{d_key}#MED#{w_key}'] = np.float32(np.median(v_arr))\n",
    "                        row[f'{d_key}#TSC#{w_key}'] = np.float32(np.sqrt(np.sum(np.power(np.diff(v_norm), 2))))\n",
    "                    else:\n",
    "                        cnt = v.value_counts()\n",
    "                        val, sup = cnt.index, cnt.values\n",
    "                        hist = {k: v for k, v in zip(val, sup)}\n",
    "\n",
    "                        row[f'{d_key}#ETP#{w_key}'] = stats.entropy(sup / len(v))\n",
    "                        row[f'{d_key}#ASC#{w_key}'] = np.sum(v.values[1:] != v.values[:-1])\n",
    "\n",
    "                        if len(cats) == 2:\n",
    "                            c = cats[0]\n",
    "                            row[f'{d_key}#DUR#{w_key}'] = hist[c] / len(v) if c in hist else 0\n",
    "                        else:\n",
    "                            for c in cats:\n",
    "                                row[f'{d_key}#DUR={c}#{w_key}'] = hist[c] / len(v) if c in hist else 0\n",
    "\n",
    "        # 시간 기반 피처\n",
    "        day_of_week = ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN'][t.isoweekday() - 1]\n",
    "        is_weekend = 'Y' if t.isoweekday() > 5 else 'N'\n",
    "        hour = t.hour\n",
    "\n",
    "        if 6 <= hour < 9:\n",
    "            hour_name = 'DAWN'\n",
    "        elif 9 <= hour < 12:\n",
    "            hour_name = 'MORNING'\n",
    "        elif 12 <= hour < 15:\n",
    "            hour_name = 'AFTERNOON'\n",
    "        elif 15 <= hour < 18:\n",
    "            hour_name = 'LATE_AFTERNOON'\n",
    "        elif 18 <= hour < 21:\n",
    "            hour_name = 'EVENING'\n",
    "        elif 21 <= hour < 24:\n",
    "            hour_name = 'NIGHT'\n",
    "        else:\n",
    "            hour_name = 'MIDNIGHT'\n",
    "\n",
    "        for d in ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']:\n",
    "            row[f'ESM#DOW={d}'] = d == day_of_week\n",
    "\n",
    "        for d in ['Y', 'N']:\n",
    "            row[f'ESM#WKD={d}'] = d == is_weekend\n",
    "\n",
    "        for d in ['DAWN', 'MORNING', 'AFTERNOON', 'LATE_AFTERNOON', 'EVENING', 'NIGHT', 'MIDNIGHT']:\n",
    "            row[f'ESM#HRN={d}'] = d == hour_name\n",
    "\n",
    "        # 응답 이력 기반 피처\n",
    "        for w_key, w_val in window_label.items():\n",
    "            w_val = w_val(t) if isinstance(w_val, Callable) else w_val\n",
    "            try:\n",
    "                v = label.loc[t - td(seconds=w_val):t]\n",
    "                if len(label_values) <= 2:\n",
    "                    row[f'ESM#LIK#{w_key}'] = np.sum(v == label_values[0]) / len(v) if len(v) > 0 else 0\n",
    "                else:\n",
    "                    for l in label_values:\n",
    "                        row[f'ESM#LIK={l}#{w_key}'] = np.sum(v == l) / len(v) if len(v) > 0 else 0\n",
    "            except (KeyError, IndexError):\n",
    "                if len(label_values) <= 2: \n",
    "                    row[f'ESM#LIK#{w_key}'] = 0\n",
    "                else:\n",
    "                    for l in label_values:\n",
    "                        row[f'ESM#LIK={l}#{w_key}'] = 0\n",
    "\n",
    "        row = {\n",
    "            k: 0.0 if _safe_na_check(v) else v\n",
    "            for k, v in row.items()\n",
    "        }\n",
    "        X.append(row)\n",
    "        y.append(label_cur)\n",
    "        date_times.append(timestamp)\n",
    "\n",
    "    log(f\"Complete feature extraction on {pid}'s data ({time.time() - _s:.2f} s).\")\n",
    "    X, y, group, date_times = pd.DataFrame(X), np.asarray(y), np.repeat(pid, len(y)), np.asarray(date_times)\n",
    "    return X, y, group, date_times\n",
    "\n",
    "\n",
    "def extract(\n",
    "        pids: Iterable[str],\n",
    "        data: Dict[str, pd.Series],\n",
    "        label: pd.Series,\n",
    "        label_values: List[str],\n",
    "        window_data: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],\n",
    "        window_label: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],        \n",
    "        categories: Dict[str, Optional[List[any]]] = None,        \n",
    "        resample_s: Dict[str, float] = None,\n",
    "        with_ray: bool=False\n",
    "):\n",
    "    if with_ray and not ray.is_initialized():\n",
    "        raise EnvironmentError('Ray should be initialized if \"with_ray\" is set as True.')\n",
    "\n",
    "    func = ray.remote(_extract).remote if with_ray else _extract\n",
    "    jobs = []\n",
    "\n",
    "    for pid in pids:\n",
    "        d = dict()\n",
    "        for k, v in data.items():\n",
    "            try:\n",
    "                d[k] = v.loc[(pid, )]\n",
    "            except (KeyError, IndexError):\n",
    "                pass\n",
    "\n",
    "        job = func(\n",
    "            pid=pid,\n",
    "            data=d,\n",
    "            label=label.loc[(pid, )],\n",
    "            label_values=label_values,\n",
    "            window_data=window_data,\n",
    "            window_label=window_label,\n",
    "            categories=categories,\n",
    "            resample_s=resample_s\n",
    "        )\n",
    "        jobs.append(job)\n",
    "\n",
    "    jobs = ray.get(jobs) if with_ray else jobs\n",
    "\n",
    "    X = pd.concat([x for x, _, _, _ in jobs], axis=0, ignore_index=True)\n",
    "    y = np.concatenate([x for _, x, _, _ in jobs], axis=0)\n",
    "    group = np.concatenate([x for _, _, x, _ in jobs], axis=0)\n",
    "    date_times = np.concatenate([x for _, _, _, x in jobs], axis=0)\n",
    "\n",
    "    t_s = date_times.min().normalize().timestamp()\n",
    "    t_norm = np.asarray(list(map(lambda x: x.timestamp() - t_s, date_times)))\n",
    "\n",
    "    C, DTYPE = X.columns, X.dtypes\n",
    "\n",
    "    X = X.fillna({\n",
    "        **{c: False for c in C[(DTYPE == object) | (DTYPE == bool)]},\n",
    "        **{c: 0.0 for c in C[(DTYPE != object) & (DTYPE != bool)]},\n",
    "    }).astype({\n",
    "        **{c: 'bool' for c in C[(DTYPE == object) | (DTYPE == bool)]},\n",
    "        **{c: 'float32' for c in C[(DTYPE != object) & (DTYPE != bool)]},\n",
    "    })\n",
    "\n",
    "    return X, y, group, t_norm, date_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_VALUES = [1, 0]\n",
    "\n",
    "WINDOW_DATA = {\n",
    "    'S30': 30,\n",
    "    'M01': 60,\n",
    "    'M05': 60 * 5,\n",
    "    'M10': 60 * 10,\n",
    "    'M30': 60 * 30,\n",
    "    'H01': 60 * 60,\n",
    "    # 'H02': 60 * 60 * 2, # 추가 \n",
    "    'H03': 60 * 60 * 3,\n",
    "    # 'H04': 60 * 60 * 4, # 추가 \n",
    "    # 'H05': 60 * 60 * 5, # 추가\n",
    "    'H06': 60 * 60 * 6\n",
    "}\n",
    "\n",
    "WINDOW_LABEL = {\n",
    "    'H06': 60 * 60 * 6,\n",
    "    'H12': 60 * 60 * 12,\n",
    "    'H24': 60 * 60 * 24,\n",
    "}\n",
    "\n",
    "RESAMPLE_s = {\n",
    "    'EDA': '250ms',\n",
    "}\n",
    "\n",
    "DATA = load(os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 16:33:25,957\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=6729)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P12's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6726)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P10's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6728)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P08's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P05's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6722)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P03's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6723)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P06's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6730)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P02's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P01's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6721)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P09's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6724)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P13's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6727)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P15's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6720)\u001b[0m [25-05-22 16:33:27] Begin feature extraction on P19's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:33:56] Complete feature extraction on P01's data (28.78 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:33:56] Begin feature extraction on P21's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6727)\u001b[0m [25-05-22 16:33:56] Complete feature extraction on P15's data (28.91 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6727)\u001b[0m [25-05-22 16:33:56] Begin feature extraction on P23's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6722)\u001b[0m [25-05-22 16:34:00] Complete feature extraction on P03's data (32.70 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6722)\u001b[0m [25-05-22 16:34:00] Begin feature extraction on P26's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6729)\u001b[0m [25-05-22 16:34:01] Complete feature extraction on P12's data (33.65 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6729)\u001b[0m [25-05-22 16:34:01] Begin feature extraction on P28's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6726)\u001b[0m [25-05-22 16:34:01] Complete feature extraction on P10's data (34.42 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6726)\u001b[0m [25-05-22 16:34:01] Begin feature extraction on P30's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6723)\u001b[0m [25-05-22 16:34:03] Complete feature extraction on P06's data (36.26 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6723)\u001b[0m [25-05-22 16:34:03] Begin feature extraction on P31's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6730)\u001b[0m [25-05-22 16:34:05] Complete feature extraction on P02's data (38.31 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6730)\u001b[0m [25-05-22 16:34:05] Begin feature extraction on P32's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:34:05] Complete feature extraction on P05's data (38.41 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:34:05] Begin feature extraction on P33's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6720)\u001b[0m [25-05-22 16:34:06] Complete feature extraction on P19's data (39.33 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6720)\u001b[0m [25-05-22 16:34:06] Begin feature extraction on P35's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6724)\u001b[0m [25-05-22 16:34:07] Complete feature extraction on P13's data (40.01 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6724)\u001b[0m [25-05-22 16:34:07] Begin feature extraction on P39's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6721)\u001b[0m [25-05-22 16:34:07] Complete feature extraction on P09's data (40.37 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6721)\u001b[0m [25-05-22 16:34:07] Begin feature extraction on P40's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6728)\u001b[0m [25-05-22 16:34:16] Complete feature extraction on P08's data (48.85 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6728)\u001b[0m [25-05-22 16:34:16] Begin feature extraction on P42's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:34:31] Complete feature extraction on P21's data (34.91 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:34:31] Begin feature extraction on P45's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6727)\u001b[0m [25-05-22 16:34:31] Complete feature extraction on P23's data (34.90 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6727)\u001b[0m [25-05-22 16:34:31] Begin feature extraction on P47's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:34:35] Complete feature extraction on P33's data (29.78 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:34:35] Begin feature extraction on P48's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6723)\u001b[0m [25-05-22 16:34:41] Complete feature extraction on P31's data (37.72 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6723)\u001b[0m [25-05-22 16:34:41] Begin feature extraction on P49's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6730)\u001b[0m [25-05-22 16:34:43] Complete feature extraction on P32's data (37.23 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6730)\u001b[0m [25-05-22 16:34:43] Begin feature extraction on P50's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6720)\u001b[0m [25-05-22 16:34:43] Complete feature extraction on P35's data (36.62 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6720)\u001b[0m [25-05-22 16:34:43] Begin feature extraction on P51's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6721)\u001b[0m [25-05-22 16:34:47] Complete feature extraction on P40's data (40.00 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6721)\u001b[0m [25-05-22 16:34:47] Begin feature extraction on P52's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6724)\u001b[0m [25-05-22 16:34:51] Complete feature extraction on P39's data (43.88 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6724)\u001b[0m [25-05-22 16:34:51] Begin feature extraction on P53's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6726)\u001b[0m [25-05-22 16:34:51] Complete feature extraction on P30's data (49.92 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6726)\u001b[0m [25-05-22 16:34:51] Begin feature extraction on P55's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6722)\u001b[0m [25-05-22 16:34:55] Complete feature extraction on P26's data (55.02 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6722)\u001b[0m [25-05-22 16:34:55] Begin feature extraction on P57's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:34:57] Complete feature extraction on P45's data (26.03 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:34:57] Begin feature extraction on P60's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6729)\u001b[0m [25-05-22 16:35:01] Complete feature extraction on P28's data (60.71 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6729)\u001b[0m [25-05-22 16:35:01] Begin feature extraction on P61's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:35:02] Complete feature extraction on P48's data (26.90 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:35:02] Begin feature extraction on P66's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6728)\u001b[0m [25-05-22 16:35:06] Complete feature extraction on P42's data (49.89 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6728)\u001b[0m [25-05-22 16:35:06] Begin feature extraction on P67's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6730)\u001b[0m [25-05-22 16:35:14] Complete feature extraction on P50's data (31.67 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6730)\u001b[0m [25-05-22 16:35:14] Begin feature extraction on P69's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6721)\u001b[0m [25-05-22 16:35:20] Complete feature extraction on P52's data (32.92 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6721)\u001b[0m [25-05-22 16:35:20] Begin feature extraction on P70's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6720)\u001b[0m [25-05-22 16:35:25] Complete feature extraction on P51's data (41.58 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6720)\u001b[0m [25-05-22 16:35:25] Begin feature extraction on P72's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6727)\u001b[0m [25-05-22 16:35:26] Complete feature extraction on P47's data (55.31 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6727)\u001b[0m [25-05-22 16:35:26] Begin feature extraction on P75's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6726)\u001b[0m [25-05-22 16:35:32] Complete feature extraction on P55's data (41.12 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6726)\u001b[0m [25-05-22 16:35:32] Begin feature extraction on P76's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6722)\u001b[0m [25-05-22 16:35:35] Complete feature extraction on P57's data (40.06 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6722)\u001b[0m [25-05-22 16:35:35] Begin feature extraction on P77's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6723)\u001b[0m [25-05-22 16:35:39] Complete feature extraction on P49's data (57.70 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6723)\u001b[0m [25-05-22 16:35:39] Begin feature extraction on P78's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:35:40] Complete feature extraction on P66's data (37.98 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:35:40] Begin feature extraction on P79's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:35:41] Complete feature extraction on P60's data (43.83 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:35:41] Begin feature extraction on P80's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=6724)\u001b[0m [25-05-22 16:35:41] Complete feature extraction on P53's data (49.94 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6721)\u001b[0m [25-05-22 16:35:47] Complete feature extraction on P70's data (26.90 s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=6728)\u001b[0m [25-05-22 16:35:53] Complete feature extraction on P67's data (46.90 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6729)\u001b[0m [25-05-22 16:35:53] Complete feature extraction on P61's data (52.07 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6722)\u001b[0m [25-05-22 16:36:02] Complete feature extraction on P77's data (27.11 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6719)\u001b[0m [25-05-22 16:36:03] Complete feature extraction on P79's data (22.42 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6730)\u001b[0m [25-05-22 16:36:05] Complete feature extraction on P69's data (50.34 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6725)\u001b[0m [25-05-22 16:36:05] Complete feature extraction on P80's data (24.02 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6720)\u001b[0m [25-05-22 16:36:06] Complete feature extraction on P72's data (41.20 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6723)\u001b[0m [25-05-22 16:36:08] Complete feature extraction on P78's data (29.17 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6727)\u001b[0m [25-05-22 16:36:08] Complete feature extraction on P75's data (41.73 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=6726)\u001b[0m [25-05-22 16:36:10] Complete feature extraction on P76's data (37.18 s).\n"
     ]
    }
   ],
   "source": [
    "with on_ray(num_cpus=12):\n",
    "    l = 'attention'\n",
    "\n",
    "    labels = LABELS_PROC[f'{l}_bin']\n",
    "    pids = labels.index.get_level_values('pcode').unique()\n",
    "\n",
    "    feat = extract(\n",
    "        pids=pids, \n",
    "        data=DATA,         \n",
    "        label=labels,\n",
    "        label_values=LABEL_VALUES,\n",
    "        window_data=WINDOW_DATA,\n",
    "        window_label=WINDOW_LABEL,\n",
    "        resample_s=RESAMPLE_s,\n",
    "        with_ray=True\n",
    "    )\n",
    "\n",
    "    dump(feat, os.path.join(PATH_INTERMEDIATE, f'{l}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# attention\n",
      "- Feature space: 344; Cat.: 16; Num.: 328\n",
      "- Label distribution: (array([0, 1]), array([1312, 1307]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# attention만 대상\n",
    "X, y, group, t, _ = load(os.path.join(PATH_INTERMEDIATE, 'attention.pkl'))\n",
    "\n",
    "print(f'# attention')\n",
    "print(f'- Feature space: {len(X.dtypes)}; Cat.: {np.sum(X.dtypes == bool)}; Num.: {np.sum(X.dtypes != bool)}')\n",
    "print(f'- Label distribution: {np.unique(y, return_counts=True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether the number of features is same as intented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_TIM: 16\n",
      "(N_VAL_NUM: 5)\n",
      "N_WIN_NUM: 320\n",
      "N_LBL: 3\n",
      "N_FEAT: 339\n"
     ]
    }
   ],
   "source": [
    "N_NUM, N_CAT_B, N_CAT_NB = 0, 0, 0 \n",
    "\n",
    "for k, v in DATA.items():\n",
    "    N_NUM = N_NUM + 1\n",
    "\n",
    "# Features relavant to delivery time\n",
    "N_TIM = 7 + 2 + 7\n",
    "print(f'N_TIM: {N_TIM}')\n",
    "        \n",
    "# Features relevant to latest value\n",
    "N_VAL_NUM = N_NUM\n",
    "print(f'(N_VAL_NUM: {N_VAL_NUM})')\n",
    "\n",
    "# Features from time-windows\n",
    "N_WIN_NUM = N_NUM * 8 * len(WINDOW_DATA)\n",
    "\n",
    "print(f'N_WIN_NUM: {N_WIN_NUM}')\n",
    "\n",
    "\n",
    "# Features from previous labels\n",
    "N_LBL = len(WINDOW_LABEL) * (1 if len(LABEL_VALUES) <= 2 else len(LABEL_VALUES))\n",
    "print(f'N_LBL: {N_LBL}')\n",
    "\n",
    "N_FEAT = N_TIM + N_WIN_NUM + N_LBL\n",
    "print(f'N_FEAT: {N_FEAT}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, features are extracted as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback as tb\n",
    "from contextlib import contextmanager\n",
    "from typing import Tuple, Dict, Union, Generator, List\n",
    "from dataclasses import dataclass\n",
    "# from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneGroupOut, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "import time\n",
    "import ray\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FoldResult:\n",
    "    name: str\n",
    "    estimator: BaseEstimator\n",
    "    X_train: pd.DataFrame\n",
    "    y_train: np.ndarray\n",
    "    X_test: pd.DataFrame\n",
    "    y_test: np.ndarray\n",
    "    categories: Dict[str, Dict[int, str]] = None\n",
    "\n",
    "\n",
    "def _split(\n",
    "        alg: str,\n",
    "        X: Union[pd.DataFrame, np.ndarray] = None,\n",
    "        y: np.ndarray = None,\n",
    "        groups: np.ndarray = None,\n",
    "        random_state: int = None,\n",
    "        n_splits: int = None,\n",
    "        n_repeats: int = None,\n",
    "        test_ratio: float = None\n",
    ") -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n",
    "    if alg == 'holdout':\n",
    "        splitter = StratifiedShuffleSplit(\n",
    "            n_splits=n_splits,\n",
    "            test_size=test_ratio,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif alg == 'kfold':\n",
    "        if n_repeats and n_repeats > 1:\n",
    "            splitter = RepeatedStratifiedKFold(\n",
    "                n_splits=n_splits,\n",
    "                n_repeats=n_repeats,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "        else:\n",
    "            splitter = StratifiedKFold(\n",
    "                n_splits=n_splits,\n",
    "                random_state=random_state,\n",
    "                shuffle=False if random_state is None else True,\n",
    "            )\n",
    "    elif alg == 'logo':\n",
    "        splitter = LeaveOneGroupOut()\n",
    "    else:\n",
    "        raise ValueError('\"alg\" should be one of \"holdout\", \"kfold\", \"logo\", or \"groupk\".')\n",
    "\n",
    "    split = splitter.split(X, y, groups)\n",
    "\n",
    "    for I_train, I_test in split:\n",
    "        yield I_train, I_test\n",
    "\n",
    "\n",
    "def _train(\n",
    "    dir_result: str,\n",
    "    name: str,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: np.ndarray,\n",
    "    C_cat: np.ndarray,\n",
    "    C_num: np.ndarray,\n",
    "    estimator: BaseEstimator,\n",
    "    normalize: bool = False,\n",
    "    select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "    oversample: bool = False,\n",
    "    random_state: int = None,\n",
    "    categories: Union[List, Dict[str, Dict[int, str]]] = None\n",
    "):\n",
    "    @contextmanager\n",
    "    def _log(task_type: str):\n",
    "        log(f'In progress: {task_type}.')\n",
    "        _t = time.time()\n",
    "        _err = None\n",
    "        _result = dict()\n",
    "        \n",
    "        try:\n",
    "            yield _result\n",
    "        except:\n",
    "            _err = tb.format_exc()\n",
    "        finally:\n",
    "            _e = time.time() - _t\n",
    "            if _err:\n",
    "                _msg = f'Failure: {task_type} ({_e:.2f}s). Keep running without this task. Caused by: \\n{_err}' \n",
    "            else:\n",
    "                _msg = f'Success: {task_type} ({_e:.2f}s).' \n",
    "                if _result:\n",
    "                    _r = '\\n'.join([f'- {k}: {v}' for k, v in _result.items()])\n",
    "                    _msg = f'{_msg}\\n{_r}'\n",
    "            log(_msg)\n",
    "    \n",
    "    if normalize:\n",
    "        with _log(f'[{name}] Normalizing numeric features'):\n",
    "            X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "            X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "            \n",
    "            scaler = StandardScaler().fit(X_train_N)\n",
    "            X_train_N = scaler.transform(X_train_N)\n",
    "            X_test_N = scaler.transform(X_test_N)\n",
    "         \n",
    "            X_train = pd.DataFrame(\n",
    "                np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            X_test = pd.DataFrame(\n",
    "                np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "           \n",
    "    if select:\n",
    "        if isinstance(select, SelectFromModel):\n",
    "            select = [select]\n",
    "            \n",
    "        for i, s in enumerate(select):\n",
    "            with _log(f'[{name}] {i+1}-th Feature selection') as r:\n",
    "                C = np.asarray(X_train.columns)\n",
    "                r['# Orig. Feat.'] = f'{len(C)} (# Cat. = {len(C_cat)}; # Num. = {len(C_num)})'\n",
    "                M = s.fit(X=X_train.values, y=y_train).get_support()\n",
    "                C_sel = C[M]\n",
    "                C_cat = C_cat[np.isin(C_cat, C_sel)]\n",
    "                C_num = C_num[np.isin(C_num, C_sel)]\n",
    "                \n",
    "                X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "                X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                r['# Sel. Feat.'] = f'{len(C_sel)} (# Cat. = {len(C_cat)}; # Num. = {len(C_num)})'\n",
    "\n",
    "    # if oversample:\n",
    "    #     with _log(f'[{name}] Oversampling') as r:\n",
    "    #         if len(C_cat):\n",
    "    #             M = np.isin(X_train.columns, C_cat)\n",
    "    #             sampler = SMOTENC(categorical_features=M, random_state=random_state)\n",
    "    #         else:\n",
    "    #             sampler = SMOTE(random_state=random_state)\n",
    "    #         X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    with _log(f'[{name}] Training'):\n",
    "        estimator = estimator.fit(X_train, y_train)\n",
    "        result = FoldResult(\n",
    "            name=name,\n",
    "            estimator=estimator,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            categories=categories\n",
    "        )\n",
    "        dump(result, os.path.join(dir_result, f'{name}.pkl'))\n",
    "    \n",
    "\n",
    "# def cross_val(\n",
    "#     X: pd.DataFrame,\n",
    "#     y: np.ndarray,\n",
    "#     groups: np.ndarray,\n",
    "#     path: str,\n",
    "#     name: str,\n",
    "#     estimator: BaseEstimator,\n",
    "#     categories: List[str] = None,\n",
    "#     normalize: bool = False,\n",
    "#     split: str = None,\n",
    "#     split_params: Dict[str, any] = None,\n",
    "#     select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "#     oversample: bool = False,\n",
    "#     random_state: int = None\n",
    "# ):\n",
    "\n",
    "#StratifiedKFold\n",
    "def cross_val(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    groups: np.ndarray,\n",
    "    path: str,\n",
    "    name: str,\n",
    "    estimator: BaseEstimator,\n",
    "    categories: List[str] = None,\n",
    "    normalize: bool = False,\n",
    "    split: str = None,\n",
    "    split_params: Dict[str, any] = None,\n",
    "    select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "    oversample: bool = False,\n",
    "    random_state: int = None\n",
    "):\n",
    "    if not os.path.exists(path):\n",
    "        raise ValueError('\"path\" does not exist.')\n",
    "    \n",
    "    if not split:\n",
    "        raise ValueError('\"split\" should be specified.')\n",
    "    \n",
    "    if not ray.is_initialized():\n",
    "        raise EnvironmentError('\"ray\" should be initialized.')\n",
    "    \n",
    "    jobs = []\n",
    "    func = ray.remote(_train).remote\n",
    "\n",
    "    categories = list() if categories is None else categories\n",
    "    C_cat = np.asarray(sorted(categories))\n",
    "    C_num = np.asarray(sorted(X.columns[~X.columns.isin(C_cat)]))\n",
    "\n",
    "    split_params = split_params or dict()\n",
    "    splitter = _split(alg=split, X=X, y=y, groups=groups, random_state=random_state, **split_params)\n",
    "\n",
    "    for idx_fold, (I_train, I_test) in enumerate(splitter):\n",
    "        if split == 'logo':\n",
    "            FOLD_NAME = str(np.unique(groups[I_test]).item(0))\n",
    "        else:\n",
    "            FOLD_NAME = str(idx_fold + 1)\n",
    "\n",
    "        X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "        X_test, y_test = X.iloc[I_test, :], y[I_test]\n",
    "\n",
    "        job = func(\n",
    "            dir_result=path,\n",
    "            name=f'{name}#{FOLD_NAME}',\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            C_cat=C_cat,\n",
    "            C_num=C_num,\n",
    "            categories=categories,\n",
    "            estimator=clone(estimator),\n",
    "            normalize=normalize,\n",
    "            select=select,\n",
    "            oversample=oversample,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        jobs.append(job)\n",
    "    ray.get(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor Modification on XGBClassifer\n",
    "This modification allows XGBClassifiers to automatically generate evaluation sets during pipeline (without passing any argument in \"fit\" function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) xgboost 공홈 주소 \n",
    "- https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier\n",
    "- https://xgboost.readthedocs.io/en/release_2.0.0/parameter.html\n",
    "\n",
    "### 참고) RF 공홈 주소 \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "<br> parameter 수정 시 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: xgboost\r\n",
      "Version: 1.7.1\r\n",
      "Summary: XGBoost Python Package\r\n",
      "Home-page: https://github.com/dmlc/xgboost\r\n",
      "Author: \r\n",
      "Author-email: \r\n",
      "License: Apache-2.0\r\n",
      "Location: /home/user01/miniconda3/envs/sci-data/lib/python3.9/site-packages\r\n",
      "Requires: numpy, scipy\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class EvXGBClassifier(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_size=None,\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=10,\n",
    "        random_state=None,\n",
    "        **kwargs\n",
    "        ):\n",
    "        self.random_state = random_state\n",
    "        self.eval_size = eval_size\n",
    "        self.eval_metric = eval_metric\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.model = XGBClassifier(\n",
    "            random_state=self.random_state,\n",
    "            eval_metric=self.eval_metric,\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.model.classes_\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return self.model.feature_importances_\n",
    "    \n",
    "    @property\n",
    "    def feature_names_in_(self):\n",
    "        return self.model.feature_names_in_\n",
    "\n",
    "    def fit(self, X: Union[pd.DataFrame, np.ndarray], y: np.ndarray):\n",
    "        if self.eval_size:\n",
    "            splitter = StratifiedShuffleSplit(random_state=self.random_state, test_size=self.eval_size)\n",
    "            I_train, I_eval = next(splitter.split(X, y))\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X.iloc[I_eval, :], y[I_eval]\n",
    "            else:\n",
    "                X_train, y_train = X[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X[I_eval, :], y[I_eval]\n",
    "                \n",
    "            self.model = self.model.fit(\n",
    "                X=X_train, y=y_train, \n",
    "                eval_set=[(X_eval, y_eval)],\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            self.model = self.model.fit(X=X, y=y, verbose=False)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, our feature data has a big-$p$, little-$N$ problem: # sample = 2,619 while # features = 3,356.\n",
    "Therefore, we need to choose important features only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 16:37:08,984\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P19] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P19] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P19] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P02] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P02] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P02] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P06] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P06] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P06] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P15] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P15] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P15] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P01] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P01] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P01] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P09] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P09] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P09] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P12] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P12] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P12] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P10] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P10] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P10] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P03] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P03] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P03] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P08] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P08] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P08] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P13] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P13] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P13] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P05] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P05] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P05] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P19] Training (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P21] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P21] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P21] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P21] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P45] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P45] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P45] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P02] Training (0.07s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P42] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P42] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P42] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P06] Training (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P23] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P23] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P23] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P23] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P47] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P47] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P47] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P15] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P30] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P30] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P30] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P30] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P50] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P01] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P32] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P32] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P32] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P32] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P52] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P09] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P26] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P26] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P26] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P26] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P48] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P48] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P48] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P12] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P31] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P31] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P31] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P31] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P51] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P10] Training (0.07s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P35] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P35] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P35] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P03] Training (0.07s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P33] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P33] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P33] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P08] Training (0.07s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P40] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P40] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P40] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P13] Training (0.07s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P39] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P39] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P39] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P05] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P28] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P28] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P28] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P28] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P49] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P49] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P49] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P50] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P50] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P51] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P51] Training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P45] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P67] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P67] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P67] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P42] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P61] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P61] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P61] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P61] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P47] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P66] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P66] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P66] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P50] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P72] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P72] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P72] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P52] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P52] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P52] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P76] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P76] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P76] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P48] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P69] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P69] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P69] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P51] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P75] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P75] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P75] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P35] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P53] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P53] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P53] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P53] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P77] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P77] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P77] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P33] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P55] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P55] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P55] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P55] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P78] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P78] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P78] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P40] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P60] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P60] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P60] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P60] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P79] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P79] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P79] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P39] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P57] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P57] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P57] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P57] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P80] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P80] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P80] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P49] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P70] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P70] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [dummy#P70] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P67] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P66] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P72] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P09] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P76] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P06] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P69] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P75] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P08] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P77] Training (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P05] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P05] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P05] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P78] Training (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P03] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P03] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P03] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P79] Training (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P02] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P02] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P02] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P80] Training (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P01] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P01] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P01] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [dummy#P70] Training (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P08] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P08] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P12] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P10] Normalizing numeric features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P13] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P13] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P13] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P13] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P13] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P19] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P19] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P19] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P19] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Sel. Feat.: 49 (# Cat. = 0; # Num. = 49)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P19] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P15] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P15] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P15] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P15] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Sel. Feat.: 42 (# Cat. = 0; # Num. = 42)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P15] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P09] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P09] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P09] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P09] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P06] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P06] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P06] 1-th Feature selection (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Sel. Feat.: 47 (# Cat. = 0; # Num. = 47)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P06] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P12] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P12] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P12] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P12] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P08] 1-th Feature selection (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P08] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P05] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Sel. Feat.: 41 (# Cat. = 0; # Num. = 41)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P05] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P03] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P03] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P02] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Sel. Feat.: 50 (# Cat. = 1; # Num. = 49)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P02] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P01] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P01] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P10] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P10] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] Success: [rf_ns#P10] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Sel. Feat.: 48 (# Cat. = 0; # Num. = 48)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:10] In progress: [rf_ns#P10] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P15] Training (0.40s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P23] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P23] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P23] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P12] Training (0.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P08] Training (0.44s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P31] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P05] Training (0.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P30] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P30] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P30] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P03] Training (0.43s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P21] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P21] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P21] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P21] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P21] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P01] Training (0.46s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P26] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P26] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P26] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P10] Training (0.42s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P28] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P28] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P28] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P32] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P31] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P31] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P13] Training (0.47s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P39] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P39] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P39] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P39] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P39] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P19] Training (0.49s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P42] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P42] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P42] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P23] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P23] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P09] Training (0.48s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P35] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P35] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P35] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P35] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 1; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P35] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P06] Training (0.50s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P40] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P40] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P40] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P40] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P40] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P32] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P32] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P32] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Sel. Feat.: 47 (# Cat. = 0; # Num. = 47)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P32] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P31] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Sel. Feat.: 39 (# Cat. = 0; # Num. = 39)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P31] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P30] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P30] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P02] Training (0.50s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P33] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P33] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P33] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P33] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P33] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P26] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Sel. Feat.: 48 (# Cat. = 0; # Num. = 48)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P26] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P28] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Sel. Feat.: 50 (# Cat. = 1; # Num. = 49)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P28] Training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P42] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P42] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P21] Training (0.40s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P45] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P45] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P45] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P39] Training (0.43s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P52] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P23] Training (0.48s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P49] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P49] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P49] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P35] Training (0.43s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P50] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P50] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P50] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P32] Training (0.42s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P47] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P47] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P47] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P47] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Sel. Feat.: 38 (# Cat. = 0; # Num. = 38)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P47] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P31] Training (0.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P48] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P48] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P48] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P30] Training (0.46s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P53] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P53] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P53] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P45] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Sel. Feat.: 48 (# Cat. = 0; # Num. = 48)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P45] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P33] Training (0.44s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P57] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P26] Training (0.48s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P51] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P51] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P51] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P28] Training (0.49s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P55] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P55] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P55] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P52] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P52] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P52] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P52] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P42] Training (0.47s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P61] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P61] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P61] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P49] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P49] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P50] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P50] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P40] Training (0.44s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P60] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P60] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P60] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P60] 1-th Feature selection (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P60] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P48] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P48] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P53] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Sel. Feat.: 49 (# Cat. = 0; # Num. = 49)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P53] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P57] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P57] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P57] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P57] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P51] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Sel. Feat.: 42 (# Cat. = 0; # Num. = 42)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P51] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P55] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Sel. Feat.: 50 (# Cat. = 0; # Num. = 50)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P55] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] Success: [rf_ns#P61] 1-th Feature selection (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Sel. Feat.: 48 (# Cat. = 0; # Num. = 48)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:11] In progress: [rf_ns#P61] Training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P45] Training (0.48s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P66] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P66] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P66] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P49] Training (0.43s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P67] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P67] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P67] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P67] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P67] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P50] Training (0.44s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P70] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P70] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P70] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P47] Training (0.48s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P69] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P69] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P69] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P69] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Sel. Feat.: 42 (# Cat. = 0; # Num. = 42)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P69] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P48] Training (0.47s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P72] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P72] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P72] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P66] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P66] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P51] Training (0.47s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P76] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P76] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P76] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P55] Training (0.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P75] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P75] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P75] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P61] Training (0.41s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P52] Training (0.49s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P78] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P78] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P78] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P78] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P78] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P77] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P77] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P77] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P77] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P77] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P70] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P70] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P60] Training (0.51s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P72] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Sel. Feat.: 41 (# Cat. = 0; # Num. = 41)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P72] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P53] Training (0.50s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P80] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P80] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P80] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P80] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P80] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P57] Training (0.49s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P79] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P79] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P79] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P79] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P79] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P76] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P76] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P75] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] In progress: [rf_ns#P75] Training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P78] Training (0.41s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P77] Training (0.44s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P67] Training (0.46s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P70] Training (0.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P69] Training (0.43s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P72] Training (0.42s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P66] Training (0.50s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P76] Training (0.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P75] Training (0.44s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P05] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P05] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P05] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P03] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P03] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P03] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P10] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P10] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P10] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P09] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P09] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P09] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P13] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P12] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P12] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P12] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P80] Training (0.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P02] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P02] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P02] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P15] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] Success: [rf_ns#P79] Training (0.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P01] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P01] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P01] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P06] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P06] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P06] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P08] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P08] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P08] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P01] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P01] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P19] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P05] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Sel. Feat.: 41 (# Cat. = 0; # Num. = 41)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P05] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P02] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Sel. Feat.: 50 (# Cat. = 1; # Num. = 49)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P02] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P03] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P03] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P10] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Sel. Feat.: 48 (# Cat. = 0; # Num. = 48)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P10] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P09] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P09] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P19] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P19] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P19] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Sel. Feat.: 49 (# Cat. = 0; # Num. = 49)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P19] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P13] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P13] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P13] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P13] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P12] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P12] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P15] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P15] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P15] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Sel. Feat.: 42 (# Cat. = 0; # Num. = 42)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P15] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P06] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Sel. Feat.: 47 (# Cat. = 0; # Num. = 47)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P06] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P08] 1-th Feature selection (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P08] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P05] Training (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P21] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P21] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P21] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P03] Training (0.20s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P12] Training (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P30] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P02] Training (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P28] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P28] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P28] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P15] Training (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P26] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P26] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P26] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P06] Training (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P23] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P23] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P23] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P31] Normalizing numeric features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P21] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P21] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P31] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P31] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P31] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Sel. Feat.: 39 (# Cat. = 0; # Num. = 39)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P31] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P10] Training (0.24s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P40] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P40] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P40] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P09] Training (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P33] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P33] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P33] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P33] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P33] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P19] Training (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P35] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P35] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P35] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P35] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 1; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P35] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P13] Training (0.20s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P39] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P39] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P39] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P39] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P39] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P30] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P30] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P30] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P30] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P28] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Sel. Feat.: 50 (# Cat. = 1; # Num. = 49)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P28] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P26] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Sel. Feat.: 48 (# Cat. = 0; # Num. = 48)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P26] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P01] Training (0.30s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P42] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P42] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P42] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P23] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P23] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] Success: [xgb_ns#P08] Training (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:12] In progress: [xgb_ns#P32] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P32] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P32] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P32] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Sel. Feat.: 47 (# Cat. = 0; # Num. = 47)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P32] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P21] Training (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P49] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P31] Training (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P48] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P48] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P48] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P40] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P40] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P30] Training (0.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P47] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P47] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P47] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P42] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P42] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P23] Training (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P45] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P45] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P45] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P45] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Sel. Feat.: 48 (# Cat. = 0; # Num. = 48)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P45] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P49] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P49] 1-th Feature selection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P49] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P49] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P48] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P48] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P40] Training (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P60] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P60] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P60] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P33] Training (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P51] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P51] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P51] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P51] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Sel. Feat.: 42 (# Cat. = 0; # Num. = 42)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P51] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P35] Training (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P53] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P53] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P53] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P53] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Sel. Feat.: 49 (# Cat. = 0; # Num. = 49)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P53] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P39] Training (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P57] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P57] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P57] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P47] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Sel. Feat.: 38 (# Cat. = 0; # Num. = 38)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P47] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P28] Training (0.21s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P52] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P52] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P52] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P52] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P52] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P26] Training (0.20s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P50] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P50] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P50] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P50] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P50] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P32] Training (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P55] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P55] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P55] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P55] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Sel. Feat.: 50 (# Cat. = 0; # Num. = 50)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P55] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P49] Training (0.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P67] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P67] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P67] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P60] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P60] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P57] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P57] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P47] Training (0.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P61] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P61] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P61] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P61] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m - # Sel. Feat.: 48 (# Cat. = 0; # Num. = 48)\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P61] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P52] Training (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P70] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P42] Training (0.25s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P66] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P66] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P66] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P45] Training (0.21s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P69] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P53] Training (0.14s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P67] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P67] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P48] Training (0.23s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P77] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P77] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P77] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P77] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8794)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P77] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P60] Training (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P79] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P79] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P79] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P51] Training (0.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P75] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P75] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P75] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P75] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8792)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P75] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P72] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P72] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P72] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P72] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m - # Sel. Feat.: 41 (# Cat. = 0; # Num. = 41)\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P72] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P57] Training (0.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P78] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P78] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P78] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P70] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P70] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P70] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8790)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P70] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P50] Training (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P76] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P76] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P76] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P76] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8791)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P76] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P66] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m - # Sel. Feat.: 45 (# Cat. = 0; # Num. = 45)\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P66] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P69] Normalizing numeric features (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P69] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P69] 1-th Feature selection (0.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m - # Sel. Feat.: 42 (# Cat. = 0; # Num. = 42)\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P69] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8797)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P67] Training (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P79] 1-th Feature selection (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m - # Sel. Feat.: 44 (# Cat. = 0; # Num. = 44)\n",
      "\u001b[2m\u001b[36m(_train pid=8800)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P79] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8801)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P72] Training (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P78] 1-th Feature selection (0.05s).\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m - # Sel. Feat.: 43 (# Cat. = 0; # Num. = 43)\n",
      "\u001b[2m\u001b[36m(_train pid=8795)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P78] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=8793)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P61] Training (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=8798)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P66] Training (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=8799)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P69] Training (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P55] Training (0.23s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P80] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P80] Normalizing numeric features (0.01s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P80] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] Success: [xgb_ns#P80] 1-th Feature selection (0.02s).\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Orig. Feat.: 344 (# Cat. = 16; # Num. = 328)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m - # Sel. Feat.: 46 (# Cat. = 0; # Num. = 46)\n",
      "\u001b[2m\u001b[36m(_train pid=8796)\u001b[0m [25-05-22 16:37:13] In progress: [xgb_ns#P80] Training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# from eli5.sklearn.permutation_importance import PermutationImportance\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "ESTIMATOR_DUMMY = DummyClassifier(strategy='prior')\n",
    "ESTIMATOR_RF = RandomForestClassifier(random_state=RANDOM_STATE, max_depth=5)\n",
    "ESTIMATOR_XGB = EvXGBClassifier(\n",
    "    random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss', \n",
    "    eval_size=0.2,\n",
    "    early_stopping_rounds=10, \n",
    "    objective='binary:logistic', \n",
    "    verbosity=0,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "SELECT_SVC = SelectFromModel(\n",
    "    estimator=LinearSVC(\n",
    "        penalty='l1',\n",
    "        loss='squared_hinge',\n",
    "        dual=False,\n",
    "        tol=1e-3,\n",
    "        C=1e-2,\n",
    "        max_iter=5000,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    threshold=1e-5\n",
    ")\n",
    "\n",
    "CLS = ['attention']\n",
    "SETTINGS = [\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_DUMMY),\n",
    "        oversample=False,\n",
    "        select=None,\n",
    "        name='dummy'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_ns'\n",
    "    ),\n",
    "    # dict(\n",
    "    #     estimator=clone(ESTIMATOR_RF),\n",
    "    #     oversample=True,\n",
    "    #     select=[clone(SELECT_SVC)],\n",
    "    #     name='rf_os'\n",
    "    # ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_ns'\n",
    "    ),\n",
    "    # dict(\n",
    "    #     estimator=clone(ESTIMATOR_XGB),\n",
    "    #     oversample=True,\n",
    "    #     select=[clone(SELECT_SVC)],\n",
    "    #     name='xgb_os'\n",
    "    # )\n",
    "]\n",
    "\n",
    "with on_ray(num_cpus=12):\n",
    "    for l, s in product(\n",
    "        CLS, SETTINGS\n",
    "    ):\n",
    "        p = os.path.join(PATH_INTERMEDIATE, f'{l}.pkl')\n",
    "        par_dir = os.path.join(PATH_INTERMEDIATE, 'eval', l)\n",
    "        os.makedirs(par_dir, exist_ok=True)\n",
    "        \n",
    "        X, y, groups, t, datetimes = load(p)\n",
    "        cats = X.columns[X.dtypes == bool]\n",
    "        cross_val(\n",
    "            X=X, y=y, groups=groups,\n",
    "            path=par_dir,\n",
    "            categories=cats,\n",
    "            normalize=True,\n",
    "            split='logo',\n",
    "            random_state=RANDOM_STATE,\n",
    "            **s\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "from itertools import product\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, \\\n",
    "    confusion_matrix, precision_recall_fscore_support, \\\n",
    "    roc_auc_score, matthews_corrcoef, average_precision_score, \\\n",
    "    log_loss, brier_score_loss\n",
    "import scipy.stats.mstats as ms\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    y_proba: np.ndarray,\n",
    "    classes: np.ndarray\n",
    ") -> Dict[str, any]:\n",
    "    R = {}\n",
    "    n_classes = len(classes)\n",
    "    is_multiclass = n_classes > 2\n",
    "    is_same_y = len(np.unique(y_true)) == 1\n",
    "    R['inst'] = len(y_true)\n",
    "    \n",
    "    for c in classes:\n",
    "        R[f'inst_{c}'] = np.sum(y_true == c)\n",
    "        \n",
    "    if not is_multiclass:\n",
    "        _, cnt = np.unique(y_true, return_counts=True)\n",
    "        \n",
    "        if len(cnt) > 1:\n",
    "            R['class_ratio'] = cnt[0] / cnt[1]\n",
    "        else:\n",
    "            R['class_ratio'] = np.nan\n",
    "\n",
    "    C = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=classes)\n",
    "    for (i1, c1), (i2, c2) in product(enumerate(classes), enumerate(classes)):\n",
    "        R[f'true_{c1}_pred_{c2}'] = C[i1, i2]\n",
    "\n",
    "    # Threshold Measure\n",
    "    R['acc'] = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['bac'] = balanced_accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
    "    R['mcc'] = matthews_corrcoef(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    if is_multiclass:\n",
    "        for avg in ('macro', 'micro'):\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true,\n",
    "                y_pred=y_pred,\n",
    "                labels=classes,\n",
    "                average=avg, \n",
    "                zero_division=0\n",
    "            )\n",
    "            R[f'pre_{avg}'] = pre\n",
    "            R[f'rec_{avg}'] = rec\n",
    "            R[f'f1_{avg}'] = f1\n",
    "    else:\n",
    "        pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true=y_true, y_pred=y_pred, pos_label=c, average='macro', zero_division=0\n",
    "        )\n",
    "        R[f'pre_macro'] = pre\n",
    "        R[f'rec_macro'] = rec\n",
    "        R[f'f1_macro'] = f1\n",
    "        \n",
    "        for c in classes:\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true, y_pred=y_pred, pos_label=c, average='binary', zero_division=0\n",
    "            )\n",
    "            R[f'pre_{c}'] = pre\n",
    "            R[f'rec_{c}'] = rec\n",
    "            R[f'f1_{c}'] = f1\n",
    "\n",
    "    # Ranking Measure\n",
    "    if is_multiclass:\n",
    "        for avg, mc in product(('macro', 'micro'), ('ovr', 'ovo')):\n",
    "            R[f'roauc_{avg}_{mc}'] = roc_auc_score(\n",
    "                y_true=y_true, y_score=y_proba,\n",
    "                average=avg, multi_class=mc, labels=classes\n",
    "            ) if not is_same_y else np.nan\n",
    "    else:\n",
    "        R[f'roauc'] = roc_auc_score(\n",
    "            y_true=y_true, y_score=y_proba[:, 1], average=None\n",
    "        ) if not is_same_y else np.nan\n",
    "        for i, c in enumerate(classes):\n",
    "            R[f'prauc_{c}'] = average_precision_score(\n",
    "                y_true=y_true, y_score=y_proba[:, i], pos_label=c, average=None\n",
    "            ) \n",
    "            R[f'prauc_ref_{c}'] = np.sum(y_true == c) / len(y_true)\n",
    "\n",
    "    # Probability Measure\n",
    "    R['log_loss'] = log_loss(y_true=y_true, y_pred=y_proba, labels=classes, normalize=True)\n",
    "\n",
    "    if not is_multiclass:\n",
    "        R[f'brier_loss'] = brier_score_loss(\n",
    "            y_true=y_true, y_prob=y_proba[:, 1], pos_label=classes[1]\n",
    "        )\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>split</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_inst</th>\n",
       "      <th>test_inst_0</th>\n",
       "      <th>test_inst_1</th>\n",
       "      <th>test_class_ratio</th>\n",
       "      <th>test_true_0_pred_0</th>\n",
       "      <th>test_true_0_pred_1</th>\n",
       "      <th>...</th>\n",
       "      <th>train_pre_1</th>\n",
       "      <th>train_rec_1</th>\n",
       "      <th>train_f1_1</th>\n",
       "      <th>train_roauc</th>\n",
       "      <th>train_prauc_0</th>\n",
       "      <th>train_prauc_ref_0</th>\n",
       "      <th>train_prauc_1</th>\n",
       "      <th>train_prauc_ref_1</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>train_brier_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>P01</td>\n",
       "      <td>344</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503296</td>\n",
       "      <td>0.503296</td>\n",
       "      <td>0.496704</td>\n",
       "      <td>0.496704</td>\n",
       "      <td>0.693125</td>\n",
       "      <td>0.249989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>P02</td>\n",
       "      <td>344</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493769</td>\n",
       "      <td>0.493769</td>\n",
       "      <td>0.506231</td>\n",
       "      <td>0.506231</td>\n",
       "      <td>0.693070</td>\n",
       "      <td>0.249961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>P03</td>\n",
       "      <td>344</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669594</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.496699</td>\n",
       "      <td>0.496699</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.693125</td>\n",
       "      <td>0.249989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>P04</td>\n",
       "      <td>596</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>1.096774</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669423</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.496892</td>\n",
       "      <td>0.496892</td>\n",
       "      <td>0.503108</td>\n",
       "      <td>0.503108</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>0.249990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>P05</td>\n",
       "      <td>344</td>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.501947</td>\n",
       "      <td>0.501947</td>\n",
       "      <td>0.498053</td>\n",
       "      <td>0.498053</td>\n",
       "      <td>0.693140</td>\n",
       "      <td>0.249996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P76</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738621</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.841823</td>\n",
       "      <td>0.842560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.829981</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.556641</td>\n",
       "      <td>0.184988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P77</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823659</td>\n",
       "      <td>0.870342</td>\n",
       "      <td>0.846357</td>\n",
       "      <td>0.914113</td>\n",
       "      <td>0.913049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.905657</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.437927</td>\n",
       "      <td>0.135335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P78</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741018</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.752280</td>\n",
       "      <td>0.813847</td>\n",
       "      <td>0.813060</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.785466</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.590832</td>\n",
       "      <td>0.200311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P79</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857036</td>\n",
       "      <td>0.881447</td>\n",
       "      <td>0.869070</td>\n",
       "      <td>0.933583</td>\n",
       "      <td>0.931840</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.928242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.404589</td>\n",
       "      <td>0.121713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P80</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759431</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>0.789493</td>\n",
       "      <td>0.858174</td>\n",
       "      <td>0.860937</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.851016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.174130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label     alg split  n_feature  test_inst  test_inst_0  test_inst_1  \\\n",
       "0    attention   dummy   P01        344         40           14           26   \n",
       "1    attention   dummy   P02        344         51           44            7   \n",
       "2    attention   dummy   P03        344         44           33           11   \n",
       "3    attention   dummy   P04        596         65           34           31   \n",
       "4    attention   dummy   P05        344         51           23           28   \n",
       "..         ...     ...   ...        ...        ...          ...          ...   \n",
       "370  attention  xgb_os   P76         39         65           45           20   \n",
       "371  attention  xgb_os   P77         38         44           24           20   \n",
       "372  attention  xgb_os   P78         37         50           39           11   \n",
       "373  attention  xgb_os   P79         40         36           13           23   \n",
       "374  attention  xgb_os   P80         44         47           14           33   \n",
       "\n",
       "     test_class_ratio  test_true_0_pred_0  test_true_0_pred_1  ...  \\\n",
       "0            0.538462                  14                   0  ...   \n",
       "1            6.285714                   0                  44  ...   \n",
       "2            3.000000                   0                  33  ...   \n",
       "3            1.096774                   0                  34  ...   \n",
       "4            0.821429                  23                   0  ...   \n",
       "..                ...                 ...                 ...  ...   \n",
       "370          2.250000                  26                  19  ...   \n",
       "371          1.200000                  18                   6  ...   \n",
       "372          3.545455                  26                  13  ...   \n",
       "373          0.565217                   5                   8  ...   \n",
       "374          0.424242                   7                   7  ...   \n",
       "\n",
       "     train_pre_1  train_rec_1  train_f1_1  train_roauc  train_prauc_0  \\\n",
       "0       0.000000     0.000000    0.000000     0.500000       0.503296   \n",
       "1       0.506231     1.000000    0.672182     0.500000       0.493769   \n",
       "2       0.503301     1.000000    0.669594     0.500000       0.496699   \n",
       "3       0.503108     1.000000    0.669423     0.500000       0.496892   \n",
       "4       0.000000     0.000000    0.000000     0.500000       0.501947   \n",
       "..           ...          ...         ...          ...            ...   \n",
       "370     0.738621     0.832168    0.782609     0.841823       0.842560   \n",
       "371     0.823659     0.870342    0.846357     0.914113       0.913049   \n",
       "372     0.741018     0.763889    0.752280     0.813847       0.813060   \n",
       "373     0.857036     0.881447    0.869070     0.933583       0.931840   \n",
       "374     0.759431     0.822034    0.789493     0.858174       0.860937   \n",
       "\n",
       "     train_prauc_ref_0  train_prauc_1  train_prauc_ref_1  train_log_loss  \\\n",
       "0             0.503296       0.496704           0.496704        0.693125   \n",
       "1             0.493769       0.506231           0.506231        0.693070   \n",
       "2             0.496699       0.503301           0.503301        0.693125   \n",
       "3             0.496892       0.503108           0.503108        0.693128   \n",
       "4             0.501947       0.498053           0.498053        0.693140   \n",
       "..                 ...            ...                ...             ...   \n",
       "370           0.500000       0.829981           0.500000        0.556641   \n",
       "371           0.500000       0.905657           0.500000        0.437927   \n",
       "372           0.500000       0.785466           0.500000        0.590832   \n",
       "373           0.500000       0.928242           0.500000        0.404589   \n",
       "374           0.500000       0.851016           0.500000        0.531469   \n",
       "\n",
       "     train_brier_loss  \n",
       "0            0.249989  \n",
       "1            0.249961  \n",
       "2            0.249989  \n",
       "3            0.249990  \n",
       "4            0.249996  \n",
       "..                ...  \n",
       "370          0.184988  \n",
       "371          0.135335  \n",
       "372          0.200311  \n",
       "373          0.121713  \n",
       "374          0.174130  \n",
       "\n",
       "[375 rows x 60 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "RESULTS_EVAL = []\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "\n",
    "for l in ['attention']:\n",
    "    dir_l = os.path.join(DIR_EVAL, l)\n",
    "    if not os.path.exists(dir_l):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(dir_l):\n",
    "        model, pid = f[:f.index('.pkl')].split('#')\n",
    "        res = load(os.path.join(dir_l, f))\n",
    "        X, y = res.X_test, res.y_test\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        y_proba = res.estimator.predict_proba(X)\n",
    "        ev_test = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_proba=y_proba,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "\n",
    "        X, y = res.X_train, res.y_train\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        y_proba = res.estimator.predict_proba(X)\n",
    "        ev_train = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_proba=y_proba,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "\n",
    "        RESULTS_EVAL.append({\n",
    "            'label': l,\n",
    "            'alg': model,\n",
    "            'split': pid,\n",
    "            'n_feature': len(X.columns),\n",
    "            **{\n",
    "                f'test_{k}': v for k, v in ev_test.items()\n",
    "            },\n",
    "            **{\n",
    "                f'train_{k}': v for k, v in ev_train.items()\n",
    "            }\n",
    "        })\n",
    "    \n",
    "RESULTS_EVAL = pd.DataFrame(RESULTS_EVAL)\n",
    "RESULTS_EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>value_count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>med</th>\n",
       "      <th>range</th>\n",
       "      <th>conf.</th>\n",
       "      <th>nan_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>split</td>\n",
       "      <td>75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>P01:1, P61:1, P58:1, P57:1, P56:1, P55:1, P54:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>n_feature</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32856.000000</td>\n",
       "      <td>438.080000</td>\n",
       "      <td>122.710576</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>(344, 596)</td>\n",
       "      <td>(409.846860599272, 466.31313940072795)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4463.000000</td>\n",
       "      <td>59.506667</td>\n",
       "      <td>13.658354</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>(36, 85)</td>\n",
       "      <td>(56.36416483599302, 62.64916849734031)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst_0</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2237.000000</td>\n",
       "      <td>29.826667</td>\n",
       "      <td>13.334950</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>(6, 78)</td>\n",
       "      <td>(26.758573229376672, 32.89476010395666)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst_1</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2226.000000</td>\n",
       "      <td>29.680000</td>\n",
       "      <td>14.263126</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>(2, 65)</td>\n",
       "      <td>(26.398352793484577, 32.96164720651542)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>train_prauc_ref_0</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>train_prauc_1</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.248342</td>\n",
       "      <td>0.856645</td>\n",
       "      <td>0.031361</td>\n",
       "      <td>0.856278</td>\n",
       "      <td>(0.7854664269538834, 0.9289256147090365)</td>\n",
       "      <td>(0.8494290183467972, 0.8638601069573031)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>train_prauc_ref_1</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>train_log_loss</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.321991</td>\n",
       "      <td>0.510960</td>\n",
       "      <td>0.041423</td>\n",
       "      <td>0.512505</td>\n",
       "      <td>(0.404588937695216, 0.5908317958082949)</td>\n",
       "      <td>(0.5014294073437864, 0.5204903453504963)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>train_brier_loss</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.441849</td>\n",
       "      <td>0.165891</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>0.167061</td>\n",
       "      <td>(0.12171293036002707, 0.2003106461681063)</td>\n",
       "      <td>(0.16187707697915932, 0.16990556400000278)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label     alg             metric   n  cardinality  \\\n",
       "0    attention   dummy              split  75         75.0   \n",
       "1    attention   dummy          n_feature  75          NaN   \n",
       "2    attention   dummy          test_inst  75          NaN   \n",
       "3    attention   dummy        test_inst_0  75          NaN   \n",
       "4    attention   dummy        test_inst_1  75          NaN   \n",
       "..         ...     ...                ...  ..          ...   \n",
       "285  attention  xgb_os  train_prauc_ref_0  75          NaN   \n",
       "286  attention  xgb_os      train_prauc_1  75          NaN   \n",
       "287  attention  xgb_os  train_prauc_ref_1  75          NaN   \n",
       "288  attention  xgb_os     train_log_loss  75          NaN   \n",
       "289  attention  xgb_os   train_brier_loss  75          NaN   \n",
       "\n",
       "                                           value_count           sum  \\\n",
       "0    P01:1, P61:1, P58:1, P57:1, P56:1, P55:1, P54:...           NaN   \n",
       "1                                                  NaN  32856.000000   \n",
       "2                                                  NaN   4463.000000   \n",
       "3                                                  NaN   2237.000000   \n",
       "4                                                  NaN   2226.000000   \n",
       "..                                                 ...           ...   \n",
       "285                                                NaN     37.500000   \n",
       "286                                                NaN     64.248342   \n",
       "287                                                NaN     37.500000   \n",
       "288                                                NaN     38.321991   \n",
       "289                                                NaN     12.441849   \n",
       "\n",
       "           mean          SD         med  \\\n",
       "0           NaN         NaN         NaN   \n",
       "1    438.080000  122.710576  344.000000   \n",
       "2     59.506667   13.658354   57.000000   \n",
       "3     29.826667   13.334950   29.000000   \n",
       "4     29.680000   14.263126   28.000000   \n",
       "..          ...         ...         ...   \n",
       "285    0.500000    0.000000    0.500000   \n",
       "286    0.856645    0.031361    0.856278   \n",
       "287    0.500000    0.000000    0.500000   \n",
       "288    0.510960    0.041423    0.512505   \n",
       "289    0.165891    0.017447    0.167061   \n",
       "\n",
       "                                         range  \\\n",
       "0                                          NaN   \n",
       "1                                   (344, 596)   \n",
       "2                                     (36, 85)   \n",
       "3                                      (6, 78)   \n",
       "4                                      (2, 65)   \n",
       "..                                         ...   \n",
       "285                                 (0.5, 0.5)   \n",
       "286   (0.7854664269538834, 0.9289256147090365)   \n",
       "287                                 (0.5, 0.5)   \n",
       "288    (0.404588937695216, 0.5908317958082949)   \n",
       "289  (0.12171293036002707, 0.2003106461681063)   \n",
       "\n",
       "                                          conf.  nan_count  \n",
       "0                                           NaN        NaN  \n",
       "1        (409.846860599272, 466.31313940072795)        0.0  \n",
       "2        (56.36416483599302, 62.64916849734031)        0.0  \n",
       "3       (26.758573229376672, 32.89476010395666)        0.0  \n",
       "4       (26.398352793484577, 32.96164720651542)        0.0  \n",
       "..                                          ...        ...  \n",
       "285                                  (nan, nan)        0.0  \n",
       "286    (0.8494290183467972, 0.8638601069573031)        0.0  \n",
       "287                                  (nan, nan)        0.0  \n",
       "288    (0.5014294073437864, 0.5204903453504963)        0.0  \n",
       "289  (0.16187707697915932, 0.16990556400000278)        0.0  \n",
       "\n",
       "[290 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SUMMARY_EVAL = []\n",
    "\n",
    "for row in RESULTS_EVAL.groupby(\n",
    "    ['label', 'alg']\n",
    ").agg(summary).reset_index().itertuples():\n",
    "    for k, v in row._asdict().items():\n",
    "        if type(v) is dict:\n",
    "            r = dict(\n",
    "                label=row.label,\n",
    "                alg=row.alg,\n",
    "                metric=k,\n",
    "                **v\n",
    "            )\n",
    "            SUMMARY_EVAL.append(r)\n",
    "\n",
    "SUMMARY_EVAL = pd.DataFrame(SUMMARY_EVAL)    \n",
    "SUMMARY_EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows metrics of our interest only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"13\" halign=\"left\">mean_sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1_0</th>\n",
       "      <th>test_f1_1</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_inst_0</th>\n",
       "      <th>test_inst_1</th>\n",
       "      <th>train_class_ratio</th>\n",
       "      <th>train_f1_0</th>\n",
       "      <th>train_f1_1</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_inst_0</th>\n",
       "      <th>train_inst_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">attention</th>\n",
       "      <th>dummy</th>\n",
       "      <td>438.08 (122.711)</td>\n",
       "      <td>0.368 (0.15)</td>\n",
       "      <td>0.242 (0.279)</td>\n",
       "      <td>0.278 (0.294)</td>\n",
       "      <td>0.26 (0.084)</td>\n",
       "      <td>29.827 (13.335)</td>\n",
       "      <td>29.68 (14.263)</td>\n",
       "      <td>0.998 (0.017)</td>\n",
       "      <td>0.312 (0.336)</td>\n",
       "      <td>0.357 (0.336)</td>\n",
       "      <td>0.335 (0.001)</td>\n",
       "      <td>1819.773 (698.833)</td>\n",
       "      <td>1828.36 (716.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ns</th>\n",
       "      <td>63.533 (24.405)</td>\n",
       "      <td>0.624 (0.108)</td>\n",
       "      <td>0.533 (0.224)</td>\n",
       "      <td>0.547 (0.218)</td>\n",
       "      <td>0.54 (0.082)</td>\n",
       "      <td>29.827 (13.335)</td>\n",
       "      <td>29.68 (14.263)</td>\n",
       "      <td>0.998 (0.017)</td>\n",
       "      <td>0.828 (0.131)</td>\n",
       "      <td>0.845 (0.118)</td>\n",
       "      <td>0.836 (0.125)</td>\n",
       "      <td>1819.773 (698.833)</td>\n",
       "      <td>1828.36 (716.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_os</th>\n",
       "      <td>60.733 (26.534)</td>\n",
       "      <td>0.615 (0.112)</td>\n",
       "      <td>0.548 (0.214)</td>\n",
       "      <td>0.525 (0.225)</td>\n",
       "      <td>0.536 (0.093)</td>\n",
       "      <td>29.827 (13.335)</td>\n",
       "      <td>29.68 (14.263)</td>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>1836.373 (711.253)</td>\n",
       "      <td>1836.373 (711.253)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_ns</th>\n",
       "      <td>63.533 (24.405)</td>\n",
       "      <td>0.596 (0.102)</td>\n",
       "      <td>0.52 (0.202)</td>\n",
       "      <td>0.525 (0.215)</td>\n",
       "      <td>0.522 (0.079)</td>\n",
       "      <td>29.827 (13.335)</td>\n",
       "      <td>29.68 (14.263)</td>\n",
       "      <td>0.998 (0.017)</td>\n",
       "      <td>0.781 (0.028)</td>\n",
       "      <td>0.795 (0.026)</td>\n",
       "      <td>0.788 (0.026)</td>\n",
       "      <td>1819.773 (698.833)</td>\n",
       "      <td>1828.36 (716.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_os</th>\n",
       "      <td>60.733 (26.534)</td>\n",
       "      <td>0.598 (0.099)</td>\n",
       "      <td>0.528 (0.203)</td>\n",
       "      <td>0.515 (0.221)</td>\n",
       "      <td>0.522 (0.075)</td>\n",
       "      <td>29.827 (13.335)</td>\n",
       "      <td>29.68 (14.263)</td>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.785 (0.03)</td>\n",
       "      <td>0.794 (0.029)</td>\n",
       "      <td>0.789 (0.029)</td>\n",
       "      <td>1836.373 (711.253)</td>\n",
       "      <td>1836.373 (711.253)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean_sd                                \\\n",
       "metric                   n_feature       test_acc      test_f1_0   \n",
       "label     alg                                                      \n",
       "attention dummy   438.08 (122.711)   0.368 (0.15)  0.242 (0.279)   \n",
       "          rf_ns    63.533 (24.405)  0.624 (0.108)  0.533 (0.224)   \n",
       "          rf_os    60.733 (26.534)  0.615 (0.112)  0.548 (0.214)   \n",
       "          xgb_ns   63.533 (24.405)  0.596 (0.102)   0.52 (0.202)   \n",
       "          xgb_os   60.733 (26.534)  0.598 (0.099)  0.528 (0.203)   \n",
       "\n",
       "                                                                 \\\n",
       "metric                test_f1_1  test_f1_macro      test_inst_0   \n",
       "label     alg                                                     \n",
       "attention dummy   0.278 (0.294)   0.26 (0.084)  29.827 (13.335)   \n",
       "          rf_ns   0.547 (0.218)   0.54 (0.082)  29.827 (13.335)   \n",
       "          rf_os   0.525 (0.225)  0.536 (0.093)  29.827 (13.335)   \n",
       "          xgb_ns  0.525 (0.215)  0.522 (0.079)  29.827 (13.335)   \n",
       "          xgb_os  0.515 (0.221)  0.522 (0.075)  29.827 (13.335)   \n",
       "\n",
       "                                                                   \\\n",
       "metric               test_inst_1 train_class_ratio     train_f1_0   \n",
       "label     alg                                                       \n",
       "attention dummy   29.68 (14.263)     0.998 (0.017)  0.312 (0.336)   \n",
       "          rf_ns   29.68 (14.263)     0.998 (0.017)  0.828 (0.131)   \n",
       "          rf_os   29.68 (14.263)         1.0 (0.0)    0.997 (0.0)   \n",
       "          xgb_ns  29.68 (14.263)     0.998 (0.017)  0.781 (0.028)   \n",
       "          xgb_os  29.68 (14.263)         1.0 (0.0)   0.785 (0.03)   \n",
       "\n",
       "                                                                    \\\n",
       "metric               train_f1_1 train_f1_macro        train_inst_0   \n",
       "label     alg                                                        \n",
       "attention dummy   0.357 (0.336)  0.335 (0.001)  1819.773 (698.833)   \n",
       "          rf_ns   0.845 (0.118)  0.836 (0.125)  1819.773 (698.833)   \n",
       "          rf_os     0.997 (0.0)    0.997 (0.0)  1836.373 (711.253)   \n",
       "          xgb_ns  0.795 (0.026)  0.788 (0.026)  1819.773 (698.833)   \n",
       "          xgb_os  0.794 (0.029)  0.789 (0.029)  1836.373 (711.253)   \n",
       "\n",
       "                                      \n",
       "metric                  train_inst_1  \n",
       "label     alg                         \n",
       "attention dummy     1828.36 (716.43)  \n",
       "          rf_ns     1828.36 (716.43)  \n",
       "          rf_os   1836.373 (711.253)  \n",
       "          xgb_ns    1828.36 (716.43)  \n",
       "          xgb_os  1836.373 (711.253)  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUB_SUMMARY_EVAL = SUMMARY_EVAL.loc[\n",
    "    lambda x: x['metric'].isin(\n",
    "        ['n_feature', 'train_class_ratio', 'train_inst_0', 'train_inst_1', 'test_inst_0', 'test_inst_1', 'test_acc', 'test_f1_0' ,'test_f1_1', 'test_f1_macro', 'train_f1_0' ,'train_f1_1', 'train_f1_macro',]\n",
    "    )\n",
    "].round(3).assign(\n",
    "    mean_sd=lambda x: x['mean'].astype(str).str.cat(' (' + x['SD'].astype(str) + ')', sep='')\n",
    ").pivot(\n",
    "    index=['label', 'alg'], columns=['metric'], values=['mean_sd']\n",
    ")\n",
    "SUB_SUMMARY_EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAHHCAYAAABEJtrOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCY0lEQVR4nO3deVhUZfsH8O9BZFiEAVxYFFExUVxQcXnNDdJUNCR5zTXFtSx31NSfuZuWlgtKoabimksqpVbmGm5ZariUkhAq7jsIyiLz/P4w5nUEdIaZgZk530/Xua7O9pz7TBP33M95zjmSEEKAiIiIzJJVSQdARERERcdETkREZMaYyImIiMwYEzkREZEZYyInIiIyY0zkREREZoyJnIiIyIwxkRMREZkxJnIiIiIzxkRuYS5evIh27dpBqVRCkiTExsYatP1Lly5BkiTExMQYtF1zFhgYiMDAwJIOw2xUqVIF/fr1K7FjT5s2rdiPe/DgQUiShG+//bbYj02Wj4ncCJKSkvD++++jWrVqsLW1hZOTE5o3b45FixbhyZMnRj12eHg4zp49i08++QRr165Fo0aNjHq84tSvXz9IkgQnJ6cCP8eLFy9CkiRIkoTPP/9c5/avX7+OadOmIT4+3gDRloyXncOGDRuwcOHCYonj6NGjmDZtGh4+fFgsxyOSM+uSDsDS7Nq1C++88w4UCgX69u2LOnXqIDs7G4cPH8a4cePw559/YtmyZUY59pMnT3Ds2DFMmjQJw4YNM8oxvL298eTJE5QuXdoo7b+KtbU1Hj9+jB07dqBbt24a69avXw9bW1tkZmYWqe3r169j+vTpqFKlCurXr6/1fj///HORjmcMLzuHDRs24Ny5cxg1apTR4zh69CimT5+Ofv36wdnZWWNdQkICrKxYQxAZChO5ASUnJ6NHjx7w9vbG/v374eHhoV43dOhQJCYmYteuXUY7/p07dwAg3x9OQ5IkCba2tkZr/1UUCgWaN2+Ob775Jl8i37BhAzp16oStW7cWSyyPHz+Gvb09bGxsiuV4lkKhUJR0CESWRZDBDBkyRAAQR44c0Wr7nJwcMWPGDFGtWjVhY2MjvL29xcSJE0VmZqbGdt7e3qJTp07i0KFDonHjxkKhUIiqVauK1atXq7eZOnWqAKAxeXt7CyGECA8PV//78/L2ed7PP/8smjdvLpRKpXBwcBA1atQQEydOVK9PTk4WAMSqVas09tu3b59o0aKFsLe3F0qlUnTu3Fn89ddfBR7v4sWLIjw8XCiVSuHk5CT69esnMjIyXvl5hYeHCwcHBxETEyMUCoV48OCBet1vv/0mAIitW7cKAGLevHnqdffu3RNjxowRderUEQ4ODsLR0VF06NBBxMfHq7c5cOBAvs/v+fNs3bq1qF27tjhx4oRo2bKlsLOzEyNHjlSva926tbqtvn37CoVCke/827VrJ5ydncW1a9fUyxITE0ViYuIrz13fc2jdunWh3w8hhMjMzBRTpkwRPj4+wsbGRlSqVEmMGzcu33cRgBg6dKjYvn27qF27trCxsRF+fn7ixx9/VG9T0HcRgEhOThZCPPs+h4eHa7SblJQkunbtKlxcXISdnZ1o2rSp2Llzp8Y2eee3adMmMWvWLFGxYkWhUCjEG2+8IS5evPjKzzDv2FOnTn3pNrdu3RLlypUTrVu3FiqVSr384sWLwt7eXnTr1k1j+yVLloiqVasKW1tb0bhxYxEXF5fvO5EX+8aNG8XEiROFm5ubsLe3FyEhIeLKlStaxf48bT4vIYSIjIwUfn5+ws7OTjg7O4uAgACxfv16nY9Hpo2J3IAqVqwoqlWrpvX24eHhAoDo2rWriIqKEn379hUAxNtvv62xnbe3t/D19RVubm7i//7v/8SSJUtEw4YNhSRJ4ty5c0IIIU6fPi0WLFggAIiePXuKtWvXiu3bt6uPo00iP3funLCxsRGNGjUSixYtEtHR0WLs2LGiVatW6m0KSuR79uwR1tbWokaNGmLu3Lli+vTpoly5csLFxUX9x/v54zVo0ECEhYWJL7/8UgwaNEgAEB999JFWn5eDg4NIS0sTtra2YsWKFep1o0aNEjVr1lTH93wi//3334WPj4+YMGGCWLp0qZgxY4aoWLGiUCqV6qR68+ZNMWPGDAFAvPfee2Lt2rVi7dq1IikpSQjxLFm7u7uL8uXLi+HDh4ulS5eK2NhY9brn/2g/ePBAVKpUSTRu3Fg8ffpUCCFEdHS0ACDWrl2rcU7e3t4F/rd5kb7n8PPPP4v69euLcuXKqZfnfT9yc3NFu3bthL29vRg1apRYunSpGDZsmLC2thahoaEacQAQ/v7+wsPDQ8ycOVMsXLhQVKtWTdjb24u7d+8KIZ59F3v27CkAiAULFqiPl56erj7n5xP5zZs3hZubm3B0dBSTJk0S8+fPF/7+/sLKykps27ZNvV1eMmzQoIEICAgQCxYsENOmTRP29vaiSZMmr/wM8479qkQuhBBbtmwRAMSiRYvUn1Hz5s2Fm5ub+jyFEOLLL78UAETLli1FZGSkiIiIEK6ursLHx6fARF63bl1Rr149MX/+fDFhwgRha2sratSoIR4/fqxV/EJo/3ktW7ZM/fdl6dKlYtGiRWLgwIFixIgRWh+LzAMTuYGkpqYKAPn+8BUmPj5eABCDBg3SWD527FgBQOzfv1+9zNvbWwAQcXFx6mW3b98WCoVCjBkzRr2soCQmhPaJPO+HwJ07dwqNu6BEXr9+fVGhQgVx79499bLTp08LKysr0bdv33zHGzBggEabXbp0EWXLli30mM+fh4ODgxBCiK5du4o2bdoIIZ79kXV3dxfTp08v8DPIzMwUubm5+c5DoVCIGTNmqJf9/vvvBfY2CCHUFW10dHSB657/oy2EELt37xYAxKxZs8Q///wjypQpk+8HmhDaJ3JDnEOnTp0KPNbatWuFlZWVOHTokMbyvB8fz/cwARA2NjYavQinT58WAMTixYvVy+bNm6dRhT/vxUQ+atQoAUDj+I8ePRJVq1YVVapUUZ93XjKsVauWyMrKUm+7aNEiAUCcPXs237EKOrY2iVwIIXr27Cns7e3F33//rT6fvB9vQgiRlZUlypYtKxo3bixycnLUy2NiYgSAAhN5xYoVRVpamnr55s2bNX4waEPbzys0NFTUrl1b63bJfHHEiYGkpaUBABwdHbXa/ocffgAAREREaCwfM2YMAOS7lu7n54eWLVuq58uXLw9fX1/8888/RY75RXnX1r/77juoVCqt9rlx4wbi4+PRr18/uLq6qpfXq1cPb775pvo8nzdkyBCN+ZYtW+LevXvqz1AbvXr1wsGDB3Hz5k3s378fN2/eRK9evQrcVqFQqAdX5ebm4t69eyhTpgx8fX1x6tQprY+pUCjQv39/rbZt164d3n//fcyYMQNhYWGwtbXF0qVL82136dIlXLp0SatjG+IcCrJlyxbUqlULNWvWxN27d9XTG2+8AQA4cOCAxvZt27aFj4+Per5evXpwcnIq8nfxhx9+QJMmTdCiRQv1sjJlyuC9997DpUuX8Ndff2ls379/f41xCXn/Xxjy/wUAWLJkCZRKJbp27YrJkyejT58+CA0NVa8/ceIE7t27h8GDB8Pa+n/DjXr37g0XF5cC2+zbt6/G34iuXbvCw8OjwP9PCqPt5+Xs7IyrV6/i999/17ptMk9M5Abi5OQEAHj06JFW21++fBlWVlaoXr26xnJ3d3c4Ozvj8uXLGssrV66crw0XFxc8ePCgiBHn1717dzRv3hyDBg2Cm5sbevTogc2bN780qefF6evrm29drVq1cPfuXWRkZGgsf/Fc8v7o6XIuHTt2hKOjIzZt2oT169ejcePG+T7LPCqVCgsWLMBrr70GhUKBcuXKoXz58jhz5gxSU1O1PmbFihV1Gtj2+eefw9XVFfHx8YiMjESFChW03vdFhjqHgly8eBF//vknypcvrzHVqFEDAHD79m2N7Q39Xbx8+XKh35+89S87flG+P9pwdXVFZGQkzpw5A6VSicjISI31eXG9+L2ztrZGlSpVCmzztdde05iXJAnVq1fX6sfc88fV5vMaP348ypQpgyZNmuC1117D0KFDceTIEa2PQ+aDidxAnJyc4OnpiXPnzum0nyRJWm1XqlSpApcLIYp8jNzcXI15Ozs7xMXFYe/evejTpw/OnDmD7t27480338y3rT70OZc8CoUCYWFhWL16NbZv315oNQ4As2fPRkREBFq1aoV169Zh9+7d2LNnD2rXrq11zwPw7PPRxR9//KFOgmfPntVp3xcZ6hwKolKpULduXezZs6fA6cMPP9TY3hD//fRRnMffvXs3gGc/Eq5evWrw9o2pVq1aSEhIwMaNG9GiRQts3boVLVq0wNSpU0s6NDIw3n5mQG+99RaWLVuGY8eOoVmzZi/d1tvbGyqVChcvXlT/kgaAW7du4eHDh/D29jZYXC4uLgU+mOPFSgcArKys0KZNG7Rp0wbz58/H7NmzMWnSJBw4cABt27Yt8DyAZ/cGv+jChQsoV64cHBwc9D+JAvTq1QsrV66ElZUVevToUeh23377LYKCgrBixQqN5Q8fPkS5cuXU89r+qNJGRkYG+vfvDz8/P7z++uuYO3cuunTpgsaNGxepPUOcQ2HrfHx8cPr0abRp08Zgn4Eu7Xh7exf6/clbXxJ++uknfP311/joo4+wfv16hIeH4/jx4+pu9Ly4EhMTERQUpN7v6dOnuHTpEurVq5evzYsXL2rMCyGQmJhY4LaF0eXzcnBwQPfu3dG9e3dkZ2cjLCwMn3zyCSZOnFiit5GSYbEiN6CPPvoIDg4OGDRoEG7dupVvfVJSEhYtWgTgWdcwgHxP2po/fz4AoFOnTgaLy8fHB6mpqThz5ox62Y0bN7B9+3aN7e7fv59v37yHimRlZRXYtoeHB+rXr4/Vq1dr/Fg4d+4cfv75Z/V5GkNQUBBmzpyJJUuWwN3dvdDtSpUqla9a27JlC65du6axLO8HhyGeRjZ+/HhcuXIFq1evxvz581GlShWEh4fn+xyTkpKQlJT0yvYMcQ4ODg4FdsN369YN165dw/Lly/Ote/LkSb5LI9rQ5bPs2LEjfvvtNxw7dky9LCMjA8uWLUOVKlXg5+en8/H19fDhQwwaNAhNmjTB7Nmz8fXXX+PUqVOYPXu2eptGjRqhbNmyWL58OZ4+fapevn79+kK7+desWaNx+e3bb7/FjRs3EBwcrHVs2n5e9+7d09jPxsYGfn5+EEIgJydH6+OR6WNFbkA+Pj7YsGEDunfvjlq1amk82e3o0aPYsmWL+hnT/v7+CA8Px7Jly/Dw4UO0bt0av/32G1avXo23335b4xe+vnr06IHx48ejS5cuGDFiBB4/foyvvvoKNWrU0BgoNWPGDMTFxaFTp07w9vbG7du38eWXX6JSpUoaA2teNG/ePAQHB6NZs2YYOHAgnjx5gsWLF0OpVBr1udZWVlb4+OOPX7ndW2+9hRkzZqB///54/fXXcfbsWaxfvx7VqlXT2M7HxwfOzs6Ijo6Go6MjHBwc0LRpU1StWlWnuPbv348vv/wSU6dORcOGDQEAq1atQmBgICZPnoy5c+eqt23Tpg0AvPIaqSHOISAgAJs2bUJERAQaN26MMmXKICQkBH369MHmzZsxZMgQHDhwAM2bN0dubi4uXLiAzZs3Y/fu3To/6jcgIAAAMGnSJPTo0QOlS5dGSEhIgb0zEyZMwDfffIPg4GCMGDECrq6uWL16NZKTk7F169YSeQrcyJEjce/ePezduxelSpVChw4dMGjQIMyaNQuhoaHw9/eHjY0Npk2bhuHDh+ONN95At27dcOnSJcTExMDHx6fAXglXV1e0aNEC/fv3x61bt7Bw4UJUr14dgwcP1jo2bT+vdu3awd3dHc2bN4ebmxvOnz+PJUuWoFOnTloPyiUzUXID5i3X33//LQYPHiyqVKkibGxshKOjo2jevLlYvHixxgM2cnJyxPTp00XVqlVF6dKlhZeX10sfCPOiF297Kuz2MyGePeilTp06wsbGRvj6+op169blu/1s3759IjQ0VHh6egobGxvh6ekpevbsKf7+++98x3jx9qa9e/eK5s2bCzs7O+Hk5CRCQkIKfSDMi7e3rVq1qtBblZ73/O1nhSns9rMxY8YIDw8PYWdnJ5o3by6OHTtW4G1j3333nfDz8xPW1tYFPhCmIM+3k5aWJry9vUXDhg01bkkSQojRo0cLKysrcezYMfUyXW4/0/cc0tPTRa9evYSzs3O+B8JkZ2eLzz77TNSuXVsoFArh4uIiAgICxPTp00Vqaqp6O/z7QJgXFfSQl5kzZ4qKFSsKKysrrR8I4+zsLGxtbUWTJk0KfSDMli1bNJYX9p0siDa3n3333XcCgPjiiy80luf9t/X39xfZ2dnq5ZGRkcLb21soFArRpEkTceTIEREQECA6dOiQL/ZvvvlGTJw4UVSoUEHY2dmJTp06icuXL78y7hdp83ktXbpUtGrVSpQtW1YoFArh4+Mjxo0bp/HfkyyDJEQxjVAhIipheW9eM2ZPkUqlQvny5REWFlbg5QoiQ+M1ciKiIsrMzMw3dmHNmjW4f/8+X21LxYbXyImIiujXX3/F6NGj8c4776Bs2bI4deoUVqxYgTp16uCdd97Rqa0nT5688pkArq6ufEkP5cNETkRURFWqVIGXlxciIyNx//59uLq6om/fvvj00091TribNm165ZMDDxw4wEqf8uE1ciIiE3Djxg38+eefL90mICCg0Me/knwxkRMREZkxDnYjIiIyY2Z9jVylUuH69etwdHQ06OM1iYioeAgh8OjRI3h6ehr14T+ZmZnIzs7Wux0bGxuTe7ytWSfy69evw8vLq6TDICIiPaWkpKBSpUpGaTszMxN2jmWBp4/1bsvd3R3JyckmlczNOpHnPWbQptFISNaKEo6GyDjObfmopEMgMppHjx6hoV9Voz42Njs7G3j6GAq/cKCUHrfv5Wbj5l+rkZ2dzURuKHnd6ZK1gomcLJbjv++6J7JkxXJ51NoWkh6JXEimOazMrBM5ERGR1iQA+vxgMNGhWEzkREQkD5LVs0mf/U2QaUZFREREWmFFTkRE8iBJenatm2bfOhM5ERHJA7vWiYiIyNSwIiciInlg1zoREZE507Nr3UQ7sU0zKiIiItIKK3IiIpIHdq0TERGZMY5aJyIiIlPDipyIiOSBXetERERmzEK71pnIiYhIHiy0IjfNnxdERESkFVbkREQkD+xaJyIiMmOSpGciZ9c6ERERGRgrciIikgcr6dmkz/4miImciIjkwUKvkZtmVERERKQVVuRERCQPFnofORM5ERHJA7vWiYiIyNSwIiciInlg1zoREZEZs9CudSZyIiKSBwutyE3z5wURERFphRU5ERHJA7vWiYiIzBi71omIiMjUsCInIiKZ0LNr3URrXyZyIiKSB3atExERkalhRU5ERPIgSXqOWjfNipyJnIiI5MFCbz8zzaiIiIhIK6zIiYhIHix0sBsTORERyYOFdq0zkRMRkTxYaEVumj8viIiISCusyImISB7YtU5ERGTG2LVOREREpoYVORERyYIkSZAssCJnIiciIlmw1ETOrnUiIiIzxoqciIjkQfp30md/E8RETkREssCudSIiItJaXFwcQkJC4OnpCUmSEBsbq7E+74fFi9O8efN0Og4TORERyUJhiVOXSRcZGRnw9/dHVFRUgetv3LihMa1cuRKSJOG///2vTsdh1zoREclCcXetBwcHIzg4uND17u7uGvPfffcdgoKCUK1aNZ2Ow0RORESyYMrXyG/duoVdu3Zh9erVOu/LRE5ERKSDtLQ0jXmFQgGFQqFXm6tXr4ajoyPCwsJ03pfXyImISB4kA0wAvLy8oFQq1dOcOXP0Dm3lypXo3bs3bG1tdd6XFTkREcmCobrWU1JS4OTkpF6sbzV+6NAhJCQkYNOmTUXan4mciIhIB05OThqJXF8rVqxAQEAA/P39i7Q/EzkREcnCs7eY6lOR67Z5eno6EhMT1fPJycmIj4+Hq6srKleuDODZ9fYtW7bgiy++KHJYTORERCQLEvTsWtcxk584cQJBQUHq+YiICABAeHg4YmJiAAAbN26EEAI9e/YsclRM5EREREYQGBgIIcRLt3nvvffw3nvv6XUcJnIiIpIFU76PXB9M5EREJA8W+vYz3kdORERkxliRExGRPOjZtS7YtU5ERFRy9L1Grt+Id+NhIiciIlmw1ETOa+RERERmjBU5ERHJg4WOWmciJyIiWWDXOhEREZkcVuRERCQLllqRM5ETEZEsWGoiZ9c6ERGRGWNFTkREsmCpFTkTORERyYOF3n7GrnUiIiIzxoqciIhkgV3rREREZoyJnIiIyIxZaiLnNXIiIiIzxoqciIjkwUJHrTORExGRLLBrnYiIiEwOK3IZe72eN4Z3bwH/Gh7wKOeE3h9vwA9HLqjXPzgwo8D9pkTvxuJNRwpcd/qb0ajs7pJv+dexxzFu0S7DBE6kpeOnk7Dsm/04+/dV3L6XhqWzBqB9y7oAgJynufj86x9w8NfzuHLjHhwdbNEioAbGv/8W3MopC20zat1e7I47g6Qrt2GrKI2Gdapgwvsh8KlcobhOi4rIUityk0jkUVFRmDdvHm7evAl/f38sXrwYTZo0KemwLJ69rQ3OJd3Euh9PYd3MnvnW+4bN1Zhv2/Q1LB4Xiu/j/iq0zTeGLEUpq/919NSqWgGxX/RD7ME/DRc4kZYeP8lGreoV8U7HphgyeZXGuieZ2fjz76sY3vdN1KpeEamPHmP64u0Y9H9fY8eyMYW2efx0Evp0aQH/ml54mqvCvOW70HdsNPasHg97O4WxT4n0IEHPRG6iF8lLPJFv2rQJERERiI6ORtOmTbFw4UK0b98eCQkJqFCBv3CNae9vF7H3t4uFrr/9IF1jvmPzmjgUfwmXbzwodJ97qY815kf1aol/rt3DkdOX9IqVqCiC/lMLQf+pVeA6pzJ2WDf/A41lM0b+F6FDFuDarQeo6Ja/ZwkA1sx7X2P+84m9EBA6GWf/voqm/j6GCZxIByV+jXz+/PkYPHgw+vfvDz8/P0RHR8Pe3h4rV64s6dDoOeVdHNDuPzWw7oeTWu9T2roUur1ZD+t//MOIkREZzqOMJ5AkCU5l7LTfJ/0JAMDZ0d5YYZGB5HWt6zOZohJN5NnZ2Th58iTatm2rXmZlZYW2bdvi2LFjJRgZvahn+wZIf5yFHXHntd6nU4uaUJaxxYafmMjJ9GVm5eDTpTvRuU0DODrYarWPSqXCjCWxaFS3KnyreRg5QtKbZIDJBJVo1/rdu3eRm5sLNzc3jeVubm64cOFCvu2zsrKQlZWlnk9LSzN6jPRM7+AG2LL3DLJynmq9z7sdA7D3eCJu3ntkxMiI9JfzNBfDpq2GEAKzIt7Rer/JC7YiIfkGvl08wojREb1ciXet62LOnDlQKpXqycvLq6RDkoVmdb1Ro3J5rNWhW93LTYnAhtWwRod9iEpCztNcDJ26GldvPcC6Lz7QuhqfsnAr9h/7CxsXDoVHBWfjBkkGwa51IyhXrhxKlSqFW7duaSy/desW3N3d820/ceJEpKamqqeUlJTiClXW3u3YEH8kXMO5pFuv3vhfvTo0xJ2HGfj52N9GjIxIP3lJ/NK1O1g//wO4KB1euY8QAlMWbsXuQ2exYeGH8PIoWwyRkiEwkRuBjY0NAgICsG/fPvUylUqFffv2oVmzZvm2VygUcHJy0pio6BxsbVDHxx11fJ79aPL2cEEdH3dUqvC/e2gd7RUIbV0ba3cVXFnHftEPg9/WvFVQkiT07tAAG3fHI1elMt4JEL1CxuMs/HnxGv68eA0AkHLjHv68eA3Xbj1AztNcfDAlBmcTUrDw43eRm6vC7XtpuH0vDdnPXULqNfpLrN52SD0/ecFWbN9zAosmvwsHO4V6n8ys7GI/P9KNJOk/maISv/0sIiIC4eHhaNSoEZo0aYKFCxciIyMD/fv3L+nQLF59X0/sXDhAPT97aDAAYMNPf2DoZ9sBAGFv1IEkAVv3ny2wjaqeLnB9oYoJDKgGL3dnrPvxlJEiJ9LOmYQU9BwVpZ6fFfUdAOC/HRpjVL8O2HvkHACg48DPNfb7ZuFQNGtQHQBw+fpd3E/NUK9b992zhyH1GBmlsc+8CT3xTjCff0HFTxJCiJIOYsmSJeoHwtSvXx+RkZFo2rTpK/dLS0uDUqmE4j8fQbLmgxjIMl3aNbmkQyAymkdpaXjNqxxSU1ON1sualyuqDf8WVopXXz4pjCorA/8s7mrUWIuixCtyABg2bBiGDRtW0mEQEZEl07d73ES71s1q1DoRERFpMomKnIiIyNj40hQiIiIzpu/IcxPN4+xaJyIiMmesyImISBasrCRYWRW9rBZ67GtMTORERCQL7FonIiIik8OKnIiIZIGj1omIiMyYpXatM5ETEZEsWGpFzmvkREREZowVORERyYKlVuRM5EREJAuWeo2cXetERERGEBcXh5CQEHh6ekKSJMTGxubb5vz58+jcuTOUSiUcHBzQuHFjXLlyRafjMJETEZEsSJDU3etFmnR8j2lGRgb8/f0RFRVV4PqkpCS0aNECNWvWxMGDB3HmzBlMnjwZtra2Oh2HXetERCQLxd21HhwcjODg4ELXT5o0CR07dsTcuXPVy3x8fHSOixU5ERFRMVOpVNi1axdq1KiB9u3bo0KFCmjatGmB3e+vwkRORESyoFe3+nMj3tPS0jSmrKwsnWO5ffs20tPT8emnn6JDhw74+eef0aVLF4SFheGXX37RqS0mciIikoW8rnV9JgDw8vKCUqlUT3PmzNE5FpVKBQAIDQ3F6NGjUb9+fUyYMAFvvfUWoqOjdWqL18iJiIh0kJKSAicnJ/W8QqHQuY1y5crB2toafn5+Gstr1aqFw4cP69QWEzkREcmCoR4I4+TkpJHIi8LGxgaNGzdGQkKCxvK///4b3t7eOrXFRE5ERLJQ3KPW09PTkZiYqJ5PTk5GfHw8XF1dUblyZYwbNw7du3dHq1atEBQUhJ9++gk7duzAwYMHdToOEzkREclCcT+i9cSJEwgKClLPR0REAADCw8MRExODLl26IDo6GnPmzMGIESPg6+uLrVu3okWLFjodh4mciIjICAIDAyGEeOk2AwYMwIABA/Q6DhM5ERHJg55d6zo+2K3YMJETEZEsWOrbz3gfORERkRljRU5ERLJgqa8xZSInIiJZYNc6ERERmRxW5EREJAvsWiciIjJj7FonIiIik8OKnIiIZMFSK3ImciIikgVeIyciIjJjllqR8xo5ERGRGWNFTkREssCudSIiIjPGrnUiIiIyOazIiYhIFiTo2bVusEgMi4mciIhkwUqSYKVHJtdnX2Ni1zoREZEZY0VORESywFHrREREZsxSR60zkRMRkSxYSc8mffY3RbxGTkREZMZYkRMRkTxIenaPm2hFzkRORESyYKmD3di1TkREZMZYkRMRkSxI//6jz/6miImciIhkgaPWiYiIyOSwIiciIlmQ9QNhvv/+e60b7Ny5c5GDISIiMhZLHbWuVSJ/++23tWpMkiTk5ubqEw8RERHpQKtErlKpjB0HERGRUVnqa0z1ukaemZkJW1tbQ8VCRERkNJbata7zqPXc3FzMnDkTFStWRJkyZfDPP/8AACZPnowVK1YYPEAiIiJDyBvsps9kinRO5J988gliYmIwd+5c2NjYqJfXqVMHX3/9tUGDIyIiopfTOZGvWbMGy5YtQ+/evVGqVCn1cn9/f1y4cMGgwRERERlKXte6PpMp0vka+bVr11C9evV8y1UqFXJycgwSFBERkaFZ6mA3nStyPz8/HDp0KN/yb7/9Fg0aNDBIUERERKQdnSvyKVOmIDw8HNeuXYNKpcK2bduQkJCANWvWYOfOncaIkYiISG8S9HuluGnW40WoyENDQ7Fjxw7s3bsXDg4OmDJlCs6fP48dO3bgzTffNEaMREREerPUUetFuo+8ZcuW2LNnj6FjISIiIh0V+YEwJ06cwPnz5wE8u24eEBBgsKCIiIgMzVJfY6pzIr969Sp69uyJI0eOwNnZGQDw8OFDvP7669i4cSMqVapk6BiJiIj0ZqlvP9P5GvmgQYOQk5OD8+fP4/79+7h//z7Onz8PlUqFQYMGGSNGIiIiKoTOFfkvv/yCo0ePwtfXV73M19cXixcvRsuWLQ0aHBERkSGZaFGtF50TuZeXV4EPfsnNzYWnp6dBgiIiIjI0dq3/a968eRg+fDhOnDihXnbixAmMHDkSn3/+uUGDIyIiMpS8wW76TKZIq0Tu4uICV1dXuLq6on///oiPj0fTpk2hUCigUCjQtGlTnDp1CgMGDDB2vERERGYhLi4OISEh8PT0hCRJiI2N1Vjfr1+/fPepd+jQQefjaNW1vnDhQp0bJiIiMiXF3bWekZEBf39/DBgwAGFhYQVu06FDB6xatUo9r1AodI5Lq0QeHh6uc8NERESmpLgf0RocHIzg4OCXbqNQKODu7l70oKDHA2EAIDMzE9nZ2RrLnJyc9AqIiIjIlKWlpWnM511mLoqDBw+iQoUKcHFxwRtvvIFZs2ahbNmyOrWh82C3jIwMDBs2DBUqVICDgwNcXFw0JiIiIlOU9xpTfSbg2d1bSqVSPc2ZM6dI8XTo0AFr1qzBvn378Nlnn+GXX35BcHAwcnNzdWpH54r8o48+woEDB/DVV1+hT58+iIqKwrVr17B06VJ8+umnujZHRERULCRJv/vI8/ZNSUnR6H0uajXeo0cP9b/XrVsX9erVg4+PDw4ePIg2bdpo3Y7OFfmOHTvw5Zdf4r///S+sra3RsmVLfPzxx5g9ezbWr1+va3NERERmxcnJSWMqaiJ/UbVq1VCuXDkkJibqtJ/Oifz+/fuoVq0agGcnc//+fQBAixYtEBcXp2tzRERExcLUX2N69epV3Lt3Dx4eHjrtp3Mir1atGpKTkwEANWvWxObNmwE8q9TzXqJCRERkavK61vWZdJGeno74+HjEx8cDAJKTkxEfH48rV64gPT0d48aNw6+//opLly5h3759CA0NRfXq1dG+fXudjqNzIu/fvz9Onz4NAJgwYQKioqJga2uL0aNHY9y4cbo2R0REZJFOnDiBBg0aoEGDBgCAiIgINGjQAFOmTEGpUqVw5swZdO7cGTVq1MDAgQMREBCAQ4cO6dxVr/Ngt9GjR6v/vW3btrhw4QJOnjyJ6tWro169ero2R0REVCyeH3le1P11ERgYCCFEoet3795d5Fiep9d95ADg7e0Nb29vQ8RCRERkNIYatW5qtErkkZGRWjc4YsSIIgdDRERkLJb69jOtEvmCBQu0akySJCZyIiKiYqRVIs8bpW6qruyaxEfDksVyaTyspEMgMhqRm/3qjQzECkUY4f3C/qZI72vkRERE5sBSu9ZN9QcGERERaYEVORERyYIkAVZyHbVORERk7qz0TOT67GtM7FonIiIyY0VK5IcOHcK7776LZs2a4dq1awCAtWvX4vDhwwYNjoiIyFBM/aUpRaVzIt+6dSvat28POzs7/PHHH8jKygIApKamYvbs2QYPkIiIyBDyutb1mUyRzol81qxZiI6OxvLly1G6dGn18ubNm+PUqVMGDY6IiIheTufBbgkJCWjVqlW+5UqlEg8fPjRETERERAZnqc9a17kid3d3R2JiYr7lhw8fRrVq1QwSFBERkaHlvf1Mn8kU6ZzIBw8ejJEjR+L48eOQJAnXr1/H+vXrMXbsWHzwwQfGiJGIiEhvVgaYTJHOXesTJkyASqVCmzZt8PjxY7Rq1QoKhQJjx47F8OHDjREjERERFULnRC5JEiZNmoRx48YhMTER6enp8PPzQ5kyZYwRHxERkUFY6jXyIj/ZzcbGBn5+foaMhYiIyGisoN91biuYZibXOZEHBQW99Kb4/fv36xUQERERaU/nRF6/fn2N+ZycHMTHx+PcuXMIDw83VFxEREQGxa71fy1YsKDA5dOmTUN6erreARERERkDX5ryCu+++y5WrlxpqOaIiIhICwZ7jemxY8dga2trqOaIiIgM6tn7yIteVltM13pYWJjGvBACN27cwIkTJzB58mSDBUZERGRIvEb+L6VSqTFvZWUFX19fzJgxA+3atTNYYERERPRqOiXy3Nxc9O/fH3Xr1oWLi4uxYiIiIjI4DnYDUKpUKbRr145vOSMiIrMjGeAfU6TzqPU6dergn3/+MUYsRERERpNXkeszmSKdE/msWbMwduxY7Ny5Ezdu3EBaWprGRERERMVH62vkM2bMwJgxY9CxY0cAQOfOnTUe1SqEgCRJyM3NNXyUREREerLUa+RaJ/Lp06djyJAhOHDggDHjISIiMgpJkl76rhBt9jdFWidyIQQAoHXr1kYLhoiIiHSj0+1npvprhIiI6FVk37UOADVq1HhlMr9//75eARERERkDn+yGZ9fJX3yyGxEREZUcnRJ5jx49UKFCBWPFQkREZDRWkqTXS1P02deYtE7kvD5ORETmzFKvkWv9QJi8UetERERkOrSuyFUqlTHjICIiMi49B7uZ6KPWdX+NKRERkTmyggQrPbKxPvsaExM5ERHJgqXefqbzS1OIiIjIdLAiJyIiWbDUUetM5EREJAuWeh85u9aJiIjMGCtyIiKSBUsd7MZETkREsmAFPbvWTfT2M3atExERmTEmciIikoW8rnV9Jl3ExcUhJCQEnp6ekCQJsbGxhW47ZMgQSJKEhQsX6nxeTORERCQLVgaYdJGRkQF/f39ERUW9dLvt27fj119/haenp45HeIbXyImIiIwgODgYwcHBL93m2rVrGD58OHbv3o1OnToV6ThM5EREJAuSJOn1Su68fdPS0jSWKxQKKBQKndtTqVTo06cPxo0bh9q1axc5LnatExGRLEgGmADAy8sLSqVSPc2ZM6dI8Xz22WewtrbGiBEjin5SYEVOREQyYagnu6WkpMDJyUm9vCjV+MmTJ7Fo0SKcOnVKr14CgBU5ERGRTpycnDSmoiTyQ4cO4fbt26hcuTKsra1hbW2Ny5cvY8yYMahSpYpObbEiJyIi2TCVR7r06dMHbdu21VjWvn179OnTB/3799epLSZyIiKSheJ+RGt6ejoSExPV88nJyYiPj4erqysqV66MsmXLamxfunRpuLu7w9fXV6fjMJETEREZwYkTJxAUFKSej4iIAACEh4cjJibGYMdhIiciIlkw1O1n2goMDIQQQuvtL126pGNEzzCRExGRLBTl6Wwv7m+KTDUuIiIi0gIrciIikoXi7lovLkzkREQkC88/na2o+5sidq0TERGZMVbkREQkC+xaJyIiMmOWOmqdiZyIiGTBUityU/2BQURERFpgRU5ERLJgqaPWmciJiEgWivulKcWFXetERERmjBU5ERHJghUkWOnRQa7PvsbERE5ERLLArnUiIiIyOazIiYhIFqR//9Fnf1PERE5ERLLArnUiIiIyOazIiYhIFiQ9R62za52IiKgEWWrXOhM5ERHJgqUmcl4jJyIiMmOsyImISBZ4+xkREZEZs5KeTfrsb4rYtU5ERGTGWJETEZEssGudiIjIjHHUOhEREZkcVuRERCQLEvTrHjfRgpyJnIiI5IGj1omIiMjksCKXsSOnErF47V6cvnAFN++mYd28wegU6K9ev2N/PFZtO4z4C1fwIPUx4tZNQF3fSi9t8633F+LIqcR8y99sXhubF35g8HMgKszrDXwwvE9b+NesDI/ySvQeuww//HJGvd7BzgZTh4WiY+t6cFU64PL1e1i26Res2nb4pe2GtmmA/xvSCZU9yuKflDuYtjgWe47+ZezTIQOw1FHrJVqRx8XFISQkBJ6enpAkCbGxsSUZjuw8fpKFOjUqYt5H3Qtcn5GZjf/4+2DasLe1bnPt3MG48ONs9XR04ySUKmWFt9s0MFDURNqxt1Pg3N/XMG7upgLXzxr9X7Rp5of3p6xB026zEL3xIOaOewfBreoW2maTelXx9ax+WPfdMbR+91Ps+uU01n3+Hmr5eBjrNMiA8kat6zOZohKtyDMyMuDv748BAwYgLCysJEORpTeb18abzWsXur5HxyYAgCvX72ndpovSQWN+288nYW9rg9C2TORUvPYe/Qt7X1IpN61XFd/sOo4jpy4CAFZvP4J+XZqjoZ83fow7W+A+7/cIxL5j57F43T4AwOzoXQhsUhOD32mNiE83Gv4kyKAk6DdgzUTzeMlW5MHBwZg1axa6dOlSkmGQEa39/ijC3mwIBztFSYdCpOH4mWQEt6oLj/JKAECLgNfgU7kCDhw/X+g+TepWxcHfL2gs2//reTSuW8WYoRK9lFldI8/KykJWVpZ6Pi0trQSjoVc5+eclnE+6gcWTe5d0KET5jJ+3BQv/ryf++uET5DzNhUqlwshPvsHRP5IK3adCWSfcufdIY9md+49QoayTscMlA7CCBCs9+setTLQmN6tEPmfOHEyfPr2kwyAtrf3uGPyqeyKgdpWSDoUon/e6t0ajulXQMyIaKTfu4/UG1THvo264eTcVv/yWUNLhkRGwa90ETJw4EampqeopJSWlpEOiQmQ8ycK2n0+iT+dmJR0KUT62itKY/GEIPl6wDT8dOoc/E69j+ZY4bN9zCsPebVPofrfvpaF8WUeNZeVdHXH7HnsHqeSYVSJXKBRwcnLSmMg0fbf3D2TnPEW34MYlHQpRPqWtS8GmtDVUQmgsV6lUL+16/e1sMlo39tVYFtS0Jn4/e8kYYZKhSQaYTJBZda2TYaU/zkJyyh31/OXr93A24SqclfbwcnfFg9QMXL35ADfupgIALl6+BeDZdUK3cs9+RA2ZugYe5ZWYOixUo+213x97dn+uc5liOhsiTQ52NqjqVV497+1ZFnVqVMTD1Me4eusBDp+8iBkj3saTzByk3LyP5g2ro3vHJvh44Tb1Pl9N64Mbd1IxI+p7AMDSjQexc+koDO39Bn4+/CfC2gWgfq3KGDX7m2I/P9Kdpd5HXqKJPD09HYmJ/3t4SHJyMuLj4+Hq6orKlSuXYGTyEH/+MkKGRKrnJy149gesZ6em+HJaH/wYdxZDZ6xTrx84aRUAYPzgYEx4rxMA4OrN+/kqmIuXbuHX+CRsWzLU2KdAVKj6tbyxc+lI9fzsiP8CADbs/BVDp6/DwEkrMWVoKJbNDIeLkz1Sbt7HrK92YuXW/z0QppK7q0bV/tuZZAz+OAaTPngLkz8MwT8pd/Du2GU4n3Sj+E6M6AWSEC/0LRWjgwcPIigoKN/y8PBwxMTEvHL/tLQ0KJVK3LqXym52slgujYeVdAhERiNys5F1djlSU433dzwvV+yLv4IyjkU/RvqjNLSpX9mosRZFiVbkgYGBKMHfEUREJCMctU5EREQmh4PdiIhIHiy0JGciJyIiWeCodSIiIjOm7xvMTPXtZ7xGTkREZMaYyImISBaK+8FucXFxCAkJgaenJyRJQmxsrMb6adOmoWbNmnBwcICLiwvatm2L48eP63xeTORERCQPxZzJMzIy4O/vj6ioqALX16hRA0uWLMHZs2dx+PBhVKlSBe3atcOdO3cK3L4wvEZORERkBMHBwQgODi50fa9evTTm58+fjxUrVuDMmTNo06bwl/e8iImciIhkwVCj1tPSNN92p1AooFAo9IotOzsby5Ytg1KphL+/v077smudiIhkIW/Uuj4TAHh5eUGpVKqnOXPmFDmmnTt3okyZMrC1tcWCBQuwZ88elCtXTqc2WJETERHpICUlReNZ6/pU40FBQYiPj8fdu3exfPlydOvWDcePH0eFChW0boMVORERyYKhxro5OTlpTPokcgcHB1SvXh3/+c9/sGLFClhbW2PFihU6tcGKnIiI5MEMHtGqUqmQlZWl0z5M5EREREaQnp6OxMRE9XxycjLi4+Ph6uqKsmXL4pNPPkHnzp3h4eGBu3fvIioqCteuXcM777yj03GYyImISBaK+1nrJ06cQFBQkHo+IiICABAeHo7o6GhcuHABq1evxt27d1G2bFk0btwYhw4dQu3atXU6DhM5ERHJQnE/az0wMBBCiELXb9u2rejBPIeJnIiIZMEMLpEXCUetExERmTFW5EREJA8WWpIzkRMRkSwU92C34sKudSIiIjPGipyIiGShuEetFxcmciIikgULvUTOrnUiIiJzxoqciIjkwUJLciZyIiKSBY5aJyIiIpPDipyIiGSBo9aJiIjMmIVeImciJyIimbDQTM5r5ERERGaMFTkREcmCpY5aZyInIiJ50HOwm4nmcXatExERmTNW5EREJAsWOtaNiZyIiGTCQjM5u9aJiIjMGCtyIiKSBY5aJyIiMmOW+ohWdq0TERGZMVbkREQkCxY61o2JnIiIZMJCMzkTORERyYKlDnbjNXIiIiIzxoqciIhkQYKeo9YNFolhMZETEZEsWOglcnatExERmTNW5EREJAuW+kAYJnIiIpIJy+xcZ9c6ERGRGWNFTkREssCudSIiIjNmmR3r7FonIiIya6zIiYhIFti1TkREZMYs9VnrTORERCQPFnqRnNfIiYiIzBgrciIikgULLciZyImISB4sdbAbu9aJiIjMGCtyIiKSBY5aJyIiMmcWepGcXetERERmjBU5ERHJgoUW5KzIiYhIHvJGresz6SIuLg4hISHw9PSEJEmIjY1Vr8vJycH48eNRt25dODg4wNPTE3379sX169d1Pi8mciIiIiPIyMiAv78/oqKi8q17/PgxTp06hcmTJ+PUqVPYtm0bEhIS0LlzZ52Pw651IiKSCf1GrevauR4cHIzg4OAC1ymVSuzZs0dj2ZIlS9CkSRNcuXIFlStX1vo4TORERCQLhnogTFpamsZyhUIBhUKhR2TPpKamQpIkODs767Qfu9aJiIh04OXlBaVSqZ7mzJmjd5uZmZkYP348evbsCScnJ532ZUVORESkg5SUFI1kq281npOTg27dukEIga+++krn/ZnIiYhIFgzVte7k5KRz1VyYvCR++fJl7N+/v0jtMpETEZEsmNojWvOS+MWLF3HgwAGULVu2SO0wkRMRERlBeno6EhMT1fPJycmIj4+Hq6srPDw80LVrV5w6dQo7d+5Ebm4ubt68CQBwdXWFjY2N1sdhIiciIlko7teYnjhxAkFBQer5iIgIAEB4eDimTZuG77//HgBQv359jf0OHDiAwMBArY/DRE5ERLJQ3I9oDQwMhBCi0PUvW6cL3n5GRERkxliRExGRPFjoW1OYyImISBZMbdS6obBrnYiIyIyxIiciIlko7lHrxYWJnIiIZMFCL5EzkRMRkUxYaCbnNXIiIiIzxoqciIhkwVJHrTORExGRLHCwmwnKe7zdo7S0Eo6EyHhEbnZJh0BkNHnfb0M9rvRl0vTMFfrubyxmncgfPXoEAKhe1auEIyEiIn08evQISqXSKG3b2NjA3d0drxkgV7i7u+v0ZrLiIIni+BlkJCqVCtevX4ejoyMkU+3zsDBpaWnw8vJCSkoKnJycSjocIoPi97v4CSHw6NEjeHp6wsrKeOOvMzMzkZ2tf++WjY0NbG1tDRCR4Zh1RW5lZYVKlSqVdBiy5OTkxD90ZLH4/S5exqrEn2dra2tyCdhQePsZERGRGWMiJyIiMmNM5KQThUKBqVOnQqFQlHQoRAbH7zeZI7Me7EZERCR3rMiJiIjMGBM5ERGRGWMiJyIiMmNM5ERERGaMiZy0FhUVhSpVqsDW1hZNmzbFb7/9VtIhERlEXFwcQkJC4OnpCUmSEBsbW9IhEWmNiZy0smnTJkRERGDq1Kk4deoU/P390b59e9y+fbukQyPSW0ZGBvz9/REVFVXSoRDpjLefkVaaNm2Kxo0bY8mSJQCePefey8sLw4cPx4QJE0o4OiLDkSQJ27dvx9tvv13SoRBphRU5vVJ2djZOnjyJtm3bqpdZWVmhbdu2OHbsWAlGRkRETOT0Snfv3kVubi7c3Nw0lru5ueHmzZslFBUREQFM5ERERGaNiZxeqVy5cihVqhRu3bqlsfzWrVtwd3cvoaiIiAhgIict2NjYICAgAPv27VMvU6lU2LdvH5o1a1aCkRERkXVJB0DmISIiAuHh4WjUqBGaNGmChQsXIiMjA/379y/p0Ij0lp6ejsTERPV8cnIy4uPj4erqisqVK5dgZESvxtvPSGtLlizBvHnzcPPmTdSvXx+RkZFo2rRpSYdFpLeDBw8iKCgo3/Lw8HDExMQUf0BEOmAiJyIiMmO8Rk5ERGTGmMiJiIjMGBM5ERGRGWMiJyIiMmNM5ERERGaMiZyIiMiMMZETERGZMSZyIj3169dP493VgYGBGDVqVLHHcfDgQUiShIcPHxa6jSRJiI2N1brNadOmoX79+nrFdenSJUiShPj4eL3aIaKCMZGTRerXrx8kSYIkSbCxsUH16tUxY8YMPH361OjH3rZtG2bOnKnVttokXyKil+Gz1slidejQAatWrUJWVhZ++OEHDB06FKVLl8bEiRPzbZudnQ0bGxuDHNfV1dUg7RARaYMVOVkshUIBd3d3eHt744MPPkDbtm3x/fffA/hfd/gnn3wCT09P+Pr6AgBSUlLQrVs3ODs7w9XVFaGhobh06ZK6zdzcXERERMDZ2Rlly5bFRx99hBefcvxi13pWVhbGjx8PLy8vKBQKVK9eHStWrMClS5fUz/d2cXGBJEno168fgGdvl5szZw6qVq0KOzs7+Pv749tvv9U4zg8//IAaNWrAzs4OQUFBGnFqa/z48ahRowbs7e1RrVo1TJ48GTk5Ofm2W7p0Kby8vGBvb49u3bohNTVVY/3XX3+NWrVqwdbWFjVr1sSXX36pcyxEVDRM5CQbdnZ2yM7OVs/v27cPCQkJ2LNnD3bu3ImcnBy0b98ejo6OOHToEI4cOYIyZcqgQ4cO6v2++OILxMTEYOXKlTh8+DDu37+P7du3v/S4ffv2xTfffIPIyEicP38eS5cuRZkyZeDl5YWtW7cCABISEnDjxg0sWrQIADBnzhysWbMG0dHR+PPPPzF69Gi8++67+OWXXwA8+8ERFhaGkJAQxMfHY9CgQZgwYYLOn4mjoyNiYmLw119/YdGiRVi+fDkWLFigsU1iYiI2b96MHTt24KeffsIff/yBDz/8UL1+/fr1mDJlCj755BOcP38es2fPxuTJk7F69Wqd4yGiIhBEFig8PFyEhoYKIYRQqVRiz549QqFQiLFjx6rXu7m5iaysLPU+a9euFb6+vkKlUqmXZWVlCTs7O7F7924hhBAeHh5i7ty56vU5OTmiUqVK6mMJIUTr1q3FyJEjhRBCJCQkCABiz549BcZ54MABAUA8ePBAvSwzM1PY29uLo0ePamw7cOBA0bNnTyGEEBMnThR+fn4a68ePH5+vrRcBENu3by90/bx580RAQIB6furUqaJUqVLi6tWr6mU//vijsLKyEjdu3BBCCOHj4yM2bNig0c7MmTNFs2bNhBBCJCcnCwDijz/+KPS4RFR0vEZOFmvnzp0oU6YMcnJyoFKp0KtXL0ybNk29vm7duhrXxU+fPo3ExEQ4OjpqtJOZmYmkpCSkpqbixo0bGq9utba2RqNGjfJ1r+eJj49HqVKl0Lp1a63jTkxMxOPHj/Hmm29qLM/OzkaDBg0AAOfPn8/3CtlmzZppfYw8mzZtQmRkJJKSkpCeno6nT5/CyclJY5vKlSujYsWKGsdRqVRISEiAo6MjkpKSMHDgQAwePFi9zdOnT6FUKnWOh4h0x0ROFisoKAhfffUVbGxs4OnpCWtrza+7g4ODxnx6ejoCAgKwfv36fG2VL1++SDHY2dnpvE96ejoAYNeuXRoJFHh23d9Qjh07ht69e2P69Olo3749lEolNm7ciC+++ELnWJcvX57vh0WpUqUMFisRFY6JnCyWg4MDqlevrvX2DRs2xKZNm1ChQoV8VWkeDw8PHD9+HK1atQLwrPI8efIkGjZsWOD2devWhUqlwi+//IK2bdvmW5/XI5Cbm6te5ufnB4VCgStXrhRaydeqVUs9cC/Pr7/++uqTfM7Ro0fh7e2NSZMmqZddvnw533ZXrlzB9evX4enpqT6OlZUVfH194ebmBk9PT/zzzz/o3bu3TscnIsPgYDeif/Xu3RvlypVDaGgoDh06hOTkZBw8eBAjRozA1atXAQAjR47Ep59+itjYWFy4cAEffvjhS+8Br1KlCsLDwzFgwADExsaq29y8eTMAwNvbG5IkYefOnbhz5w7S09Ph6OiIsWPHYvTo0Vi9ejWSkpJw6tQpLF68WD2AbMiQIbh48SLGjRuHhIQEbNiwATExMTqd72uvvYYrV65g48aNSEpKQmRkZIED92xtbREeHo7Tp0/j0KFDGDFiBLp16wZ3d3cAwPTp0zFnzhxERkbi77//xtmzZ7Fq1SrMnz9fp3iIqGiYyIn+ZW9vj7i4OFSuXBlhYWGoVasWBg4ciMzMTHWFPmbMGPTp0wfh4eFo1qwZHB0d0aVLl5e2+9VXX6Fr16748MMPUbNmTQwePBgZGRkAgIoVK2L69OmYMGEC3NzcMGzYMADAzJkzMXnyZMyZMwe1atVChw4dsGvXLlStWhXAs+vWW7duRWxsLPz9/REdHY3Zs2frdL6dO3fG6NGjMWzYMNSvXx9Hjx7F5MmT821XvXp1hIWFoWPHjmjXrh3q1auncXvZoEGD8PXXX2PVqlWoW7cuWrdujZiYGHWsRGRckihslA4RERGZPFbkREREZoyJnIiIyIwxkRMREZkxJnIiIiIzxkRORERkxpjIiYiIzBgTORERkRljIiciIjJjTORERERmjImciIjIjDGRExERmTEmciIiIjP2/5Uh3ws311NAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# 수치: split 별 예측한 class(0,1)의 평균 및 표준편차\n",
    "\n",
    "# confusion matrix 관련 metric만 필터링\n",
    "cm_metrics = ['true_0_pred_0', 'true_0_pred_1', 'true_1_pred_0', 'true_1_pred_1']\n",
    "cm_data = SUMMARY_EVAL[SUMMARY_EVAL['metric'].isin([f'test_{m}' for m in cm_metrics])]\n",
    "\n",
    "# label, alg 단위로 시각화\n",
    "for (label, alg), group in cm_data.groupby(['label', 'alg']):\n",
    "    try:\n",
    "        cm = np.array([\n",
    "            [\n",
    "                group.loc[group['metric'] == 'test_true_0_pred_0', 'mean'].values[0],\n",
    "                group.loc[group['metric'] == 'test_true_0_pred_1', 'mean'].values[0],\n",
    "            ],\n",
    "            [\n",
    "                group.loc[group['metric'] == 'test_true_1_pred_0', 'mean'].values[0],\n",
    "                group.loc[group['metric'] == 'test_true_1_pred_1', 'mean'].values[0],\n",
    "            ]\n",
    "        ])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "        disp.plot(cmap='Blues', values_format='.1f')\n",
    "        plt.title(f'Confusion Matrix: {label} | {alg}')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"[{label}, {alg}] error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# metric 분리\n",
    "cm_metrics = ['true_0_pred_0', 'true_0_pred_1', 'true_1_pred_0', 'true_1_pred_1']\n",
    "f1_metrics = ['f1_macro', 'f1_micro']\n",
    "cm_metrics = [f'test_{m}' for m in cm_metrics]\n",
    "f1_metrics = [f'test_{m}' for m in f1_metrics]\n",
    "\n",
    "# pivot\n",
    "mean_cm_df = SUMMARY_EVAL[SUMMARY_EVAL['metric'].isin(cm_metrics)].pivot(index=['label', 'alg'], columns='metric', values='mean')\n",
    "std_cm_df = SUMMARY_EVAL[SUMMARY_EVAL['metric'].isin(cm_metrics)].pivot(index=['label', 'alg'], columns='metric', values='SD')\n",
    "f1_df = SUMMARY_EVAL[SUMMARY_EVAL['metric'].isin(f1_metrics)].pivot(index=['label', 'alg'], columns='metric', values='mean')\n",
    "\n",
    "# 시각화\n",
    "for idx in mean_cm_df.index:\n",
    "    try:\n",
    "        mean_cm = np.array([\n",
    "            [mean_cm_df.loc[idx, 'test_true_0_pred_0'], mean_cm_df.loc[idx, 'test_true_0_pred_1']],\n",
    "            [mean_cm_df.loc[idx, 'test_true_1_pred_0'], mean_cm_df.loc[idx, 'test_true_1_pred_1']]\n",
    "        ])\n",
    "        std_cm = np.array([\n",
    "            [std_cm_df.loc[idx, 'test_true_0_pred_0'], std_cm_df.loc[idx, 'test_true_0_pred_1']],\n",
    "            [std_cm_df.loc[idx, 'test_true_1_pred_0'], std_cm_df.loc[idx, 'test_true_1_pred_1']]\n",
    "        ])\n",
    "        annotations = np.empty_like(mean_cm, dtype=object)\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                annotations[i, j] = f\"{mean_cm[i, j]:.1f}±{std_cm[i, j]:.1f}\"\n",
    "\n",
    "        # f1 score 값\n",
    "        macro_f1 = f1_df.loc[idx, 'test_f1_macro']\n",
    "        micro_f1 = f1_df.loc[idx, 'test_f1_micro'] if 'test_f1_micro' in f1_df.columns else None\n",
    "\n",
    "        # 플롯\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(mean_cm, annot=annotations, fmt='', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "        plt.title(f'Confusion Matrix: {idx[0]} | {idx[1]} (mean ± std)')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.ylabel('True label')\n",
    "\n",
    "        # 텍스트로 F1 표시\n",
    "        f1_text = f\"Macro F1: {macro_f1:.3f}\"\n",
    "        if micro_f1 is not None:\n",
    "            f1_text += f\" | Micro F1: {micro_f1:.3f}\"\n",
    "        plt.figtext(0.5, -0.05, f1_text, ha='center', fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {idx} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_per_split(results_eval, label_filter=None, alg_filter=None):\n",
    "    df = results_eval.copy()\n",
    "    \n",
    "    # 필터링\n",
    "    if label_filter:\n",
    "        df = df[df['label'] == label_filter]\n",
    "    if alg_filter:\n",
    "        df = df[df['alg'] == alg_filter]\n",
    "    \n",
    "    # split 단위로 출력\n",
    "    for row in df.itertuples():\n",
    "        cm = np.array([\n",
    "            [getattr(row, 'test_true_0_pred_0'), getattr(row, 'test_true_0_pred_1')],\n",
    "            [getattr(row, 'test_true_1_pred_0'), getattr(row, 'test_true_1_pred_1')]\n",
    "        ])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "        disp.plot(cmap='Blues', values_format='d')\n",
    "        plt.title(f\"Split: {row.split} | Label: {row.label}, Alg: {row.alg}\")\n",
    "        plt.show()\n",
    "# plot_confusion_per_split(RESULTS_EVAL, label_filter='attention', alg_filter='xgb_ns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_per_split(results_eval, label, alg):\n",
    "    df = results_eval[(results_eval['label'] == label) & (results_eval['alg'] == alg)]\n",
    "    f1_0 = df['test_f1_0']\n",
    "    f1_1 = df['test_f1_1']\n",
    "    splits = df['split']\n",
    "\n",
    "    plt.plot(splits, f1_0, label='F1 Class 0', marker='o')\n",
    "    plt.plot(splits, f1_1, label='F1 Class 1', marker='x')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Split')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title(f'F1-score per split: {label} | {alg}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_f1_per_split(RESULTS_EVAL, label='attention', alg='xgb_ns')\n",
    "plot_f1_per_split(RESULTS_EVAL, label='attention', alg='rf_ns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_splits = RESULTS_EVAL[\n",
    "    (RESULTS_EVAL['label'] == 'attention') &\n",
    "    (RESULTS_EVAL['alg'] == 'xgb_ns') &\n",
    "    (RESULTS_EVAL['test_f1_1'] < 0.2)\n",
    "]\n",
    "print(worst_splits[['split', 'test_inst_0', 'test_inst_1', 'test_f1_1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional\n",
    "\n",
    "\n",
    "def feature_importance(\n",
    "    estimator\n",
    "):\n",
    "    if not hasattr(estimator, 'feature_names_in_') or not hasattr(estimator, 'feature_importances_'):\n",
    "        return None\n",
    "    \n",
    "    names = estimator.feature_names_in_\n",
    "    importances = estimator.feature_importances_\n",
    "    \n",
    "    return names, importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "IMPORTANCE_EVAL = defaultdict(list)\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "\n",
    "for l in ['attention']:\n",
    "    dir_l = os.path.join(DIR_EVAL, l)\n",
    "    if not os.path.exists(dir_l):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(dir_l):\n",
    "        res = load(os.path.join(dir_l, f))\n",
    "\n",
    "        f_norm = f[:f.index('.pkl')]\n",
    "        alg = f_norm[:f.rindex('#')]\n",
    "        \n",
    "        feat_imp = feature_importance(res.estimator)\n",
    "        if not feat_imp:\n",
    "            continue\n",
    "            \n",
    "        names, importance = feat_imp\n",
    "        new_names = []\n",
    "        for n in names:\n",
    "            for c in res.categories:\n",
    "                n = n.replace(f'{c}_', f'{c}=')\n",
    "            new_names.append(n)\n",
    "        \n",
    "        d = pd.DataFrame(\n",
    "            importance.reshape(1, -1),\n",
    "            columns=new_names\n",
    "        )\n",
    "        IMPORTANCE_EVAL[(l, alg)].append(d)\n",
    "        \n",
    "\n",
    "IMPORTANCE_SUMMARY = []\n",
    "\n",
    "for (l, alg), v in IMPORTANCE_EVAL.items():\n",
    "    new_v = pd.concat(\n",
    "        v, axis=0\n",
    "    ).fillna(0.0).mean().reset_index().set_axis(\n",
    "        ['feature', 'importance'], axis=1\n",
    "    ).assign(\n",
    "        label=l,\n",
    "        alg=alg\n",
    "    )\n",
    "    IMPORTANCE_SUMMARY.append(new_v)\n",
    "    \n",
    "IMPORTANCE_SUMMARY = pd.concat(IMPORTANCE_SUMMARY, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%R -i IMPORTANCE_SUMMARY -w 26 -h 16 -u cm\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(patchwork)\n",
    "\n",
    "data <- IMPORTANCE_SUMMARY %>% filter(label == 'attention')\n",
    "\n",
    "p_label <- ggplot() + geom_text(\n",
    "    aes(x = .5, y = .5),\n",
    "    label = 'Attention',\n",
    "    family = 'ssp',\n",
    "    fontface = 'bold',\n",
    "    size = 4\n",
    ") + theme_void()\n",
    "\n",
    "p_rf <- ggplot(\n",
    "    data %>% filter(alg == 'rf_os') %>% top_n(n = 10, wt = importance),\n",
    "    aes(x = reorder(feature, -importance), y = importance)\n",
    ") + geom_col() +\n",
    "    THEME_DEFAULT + theme(\n",
    "        axis.text.x = element_text(angle = 90, size = 10, hjust = 1, vjust = .5),\n",
    "        axis.title.x = element_blank(),\n",
    "        axis.title.y = element_blank()\n",
    "    ) + labs(subtitle = 'Random Forest')\n",
    "\n",
    "p_xgb <- ggplot(\n",
    "    data %>% filter(alg == 'xgb_os') %>% top_n(n = 10, wt = importance),\n",
    "    aes(x = reorder(feature, -importance), y = importance)\n",
    ") + geom_col() +\n",
    "    THEME_DEFAULT + theme(\n",
    "        axis.text.x = element_text(angle = 90, size = 10, hjust = 1, vjust = .5),\n",
    "        axis.title.x = element_blank(),\n",
    "        axis.title.y = element_blank()\n",
    "    ) + labs(subtitle = 'XGBoost')\n",
    "\n",
    "p <- p_label / (p_rf | p_xgb) + plot_layout(heights = c(1.1, 10))\n",
    "\n",
    "ggsave('./fig/imp_attention.pdf', plot = p, width = 26, height = 16, unit = 'cm', device = cairo_pdf)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
