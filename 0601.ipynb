{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import os\n",
    "\n",
    "\n",
    "DEFAULT_TZ = pytz.FixedOffset(540)  # GMT+09:00; Asia/Seoul\n",
    "\n",
    "PATH_DATA = './data'\n",
    "PATH_ESM = os.path.join(PATH_DATA, 'EsmResponse.csv')\n",
    "PATH_PARTICIPANT = os.path.join(PATH_DATA, 'UserInfo.csv')\n",
    "PATH_SENSOR = os.path.join(PATH_DATA, 'Sensor')\n",
    "\n",
    "PATH_INTERMEDIATE = './intermediate'\n",
    "\n",
    "DATA_TYPES = {\n",
    "    'EDA': 'EDA',\n",
    "    'HR': 'HRT',\n",
    "    'RRI': 'RRI',\n",
    "    'SkinTemperature': 'SKT',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import cloudpickle\n",
    "import ray\n",
    "from datetime import datetime\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "\n",
    "def load(path: str):\n",
    "    with open(path, mode='rb') as f:\n",
    "        return cloudpickle.load(f)\n",
    "    \n",
    "def dump(obj, path: str):\n",
    "    with open(path, mode='wb') as f:\n",
    "        cloudpickle.dump(obj, f)\n",
    "    \n",
    "def log(msg: any):\n",
    "    print('[{}] {}'.format(datetime.now().strftime('%y-%m-%d %H:%M:%S'), msg))\n",
    "\n",
    "def summary(x):\n",
    "    x = np.asarray(x)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        n = len(x)\n",
    "        # Here, uppercase np.dtype.kind corresponds to non-numeric data.\n",
    "        # Also, we view the boolean data as dichotomous categorical data.\n",
    "        if x.dtype.kind.isupper() or x.dtype.kind == 'b': \n",
    "            cnt = pd.Series(x).value_counts(dropna=False)\n",
    "            card = len(cnt)\n",
    "            cnt = cnt[:20]                \n",
    "            cnt_str = ', '.join([f'{u}:{c}' for u, c in zip(cnt.index, cnt)])\n",
    "            if card > 30:\n",
    "                cnt_str = f'{cnt_str}, ...'\n",
    "            return {\n",
    "                'n': n,\n",
    "                'cardinality': card,\n",
    "                'value_count': cnt_str\n",
    "            }\n",
    "        else: \n",
    "            x_nan = x[np.isnan(x)]\n",
    "            x_norm = x[~np.isnan(x)]\n",
    "            \n",
    "            tot = np.sum(x_norm)\n",
    "            m = np.mean(x_norm)\n",
    "            me = np.median(x_norm)\n",
    "            s = np.std(x_norm, ddof=1)\n",
    "            l, u = np.min(x_norm), np.max(x)\n",
    "            conf_l, conf_u = st.t.interval(0.95, len(x_norm) - 1, loc=m, scale=st.sem(x_norm))\n",
    "            n_nan = len(x_nan)\n",
    "            \n",
    "            return {\n",
    "                'n': n,\n",
    "                'sum': tot,\n",
    "                'mean': m,\n",
    "                'SD': s,\n",
    "                'med': me,\n",
    "                'range': (l, u),\n",
    "                'conf.': (conf_l, conf_u),\n",
    "                'nan_count': n_nan\n",
    "            }\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def on_ray(*args, **kwargs):\n",
    "    try:\n",
    "        if ray.is_initialized():\n",
    "            ray.shutdown()\n",
    "        ray.init(*args, **kwargs)\n",
    "        yield None\n",
    "    finally:\n",
    "        ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R\n",
    "\n",
    "# library(tidyverse)\n",
    "# library(ggforce)\n",
    "# library(ggpubr)\n",
    "# library(showtext)\n",
    "# library(rmcorr)\n",
    "# library(patchwork)\n",
    "\n",
    "# # font_add_google(\n",
    "# #     name='Source Serif Pro',\n",
    "# #     family='ssp',\n",
    "# #     db_cache=FALSE\n",
    "# # )\n",
    "\n",
    "# showtext_auto()\n",
    "\n",
    "# THEME_DEFAULT <- theme_bw(\n",
    "#     base_size=10,\n",
    "#     base_family='ssp',\n",
    "# ) + theme(\n",
    "#         axis.title.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         axis.title.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         axis.text.x=element_text(colour='grey20', size=10),\n",
    "#         axis.text.y=element_text(colour='grey20', size=10),\n",
    "#         strip.text.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         strip.text.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         legend.background=element_blank(),\n",
    "#         legend.title=element_text(colour='grey20', size=10, face='bold'),\n",
    "#         legend.text=element_text(colour='grey20', size=10),\n",
    "#         legend.position='top',\n",
    "#         legend.box.spacing= unit(0, 'cm'),\n",
    "#         plot.subtitle=element_text(colour='grey20', size=10, hjust=.5),\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participationStartDate</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>PSS</th>\n",
       "      <th>PHQ</th>\n",
       "      <th>GHQ</th>\n",
       "      <th>particpationStartDateTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P02</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P03</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P04</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P05</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-05-08 00:00:00+09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      participationStartDate  age gender  openness  conscientiousness  \\\n",
       "pcode                                                                   \n",
       "P01               2019-05-08   27      M        11                 11   \n",
       "P02               2019-05-08   21      M        14                  5   \n",
       "P03               2019-05-08   24      F        10                 15   \n",
       "P04               2019-05-08   23      M        12                 11   \n",
       "P05               2019-05-08   27      F        10                 11   \n",
       "\n",
       "       neuroticism  extraversion  agreeableness  PSS  PHQ  GHQ  \\\n",
       "pcode                                                            \n",
       "P01              3             4             13   13    0    1   \n",
       "P02             12            14              5   27    6   18   \n",
       "P03              8             7             11   18    2    6   \n",
       "P04              8             6             11   20    1    9   \n",
       "P05             13            10              6   25   14    9   \n",
       "\n",
       "      particpationStartDateTime  \n",
       "pcode                            \n",
       "P01   2019-05-08 00:00:00+09:00  \n",
       "P02   2019-05-08 00:00:00+09:00  \n",
       "P03   2019-05-08 00:00:00+09:00  \n",
       "P04   2019-05-08 00:00:00+09:00  \n",
       "P05   2019-05-08 00:00:00+09:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "PARTICIPANTS = pd.read_csv(PATH_PARTICIPANT).set_index('pcode').assign(\n",
    "    particpationStartDateTime=lambda x: pd.to_datetime(\n",
    "        x['participationStartDate'], format='%Y-%m-%d'\n",
    "    ).dt.tz_localize(DEFAULT_TZ)\n",
    ")\n",
    "PARTICIPANTS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belows are some demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- participationStartDate: {'n': 77, 'cardinality': 3, 'value_count': '2019-05-08:27, 2019-05-16:25, 2019-04-30:25'}\n",
      "- age: {'n': 77, 'sum': 1686, 'mean': 21.896103896103895, 'SD': 3.8613619617422406, 'med': 21.0, 'range': (17, 38), 'conf.': (21.01968223607122, 22.77252555613657), 'nan_count': 0}\n",
      "- gender: {'n': 77, 'cardinality': 2, 'value_count': 'M:53, F:24'}\n",
      "- openness: {'n': 77, 'sum': 787, 'mean': 10.220779220779221, 'SD': 2.8956563505732467, 'med': 11.0, 'range': (3, 15), 'conf.': (9.563545847995773, 10.87801259356267), 'nan_count': 0}\n",
      "- conscientiousness: {'n': 77, 'sum': 820, 'mean': 10.64935064935065, 'SD': 2.3662441579221882, 'med': 11.0, 'range': (5, 15), 'conf.': (10.112279104782713, 11.186422193918586), 'nan_count': 0}\n",
      "- neuroticism: {'n': 77, 'sum': 618, 'mean': 8.025974025974026, 'SD': 2.6900108881310953, 'med': 8.0, 'range': (3, 14), 'conf.': (7.4154164477308075, 8.636531604217245), 'nan_count': 0}\n",
      "- extraversion: {'n': 77, 'sum': 703, 'mean': 9.12987012987013, 'SD': 3.0015375417426937, 'med': 9.0, 'range': (3, 15), 'conf.': (8.448604674559745, 9.811135585180514), 'nan_count': 0}\n",
      "- agreeableness: {'n': 77, 'sum': 805, 'mean': 10.454545454545455, 'SD': 2.526415468527935, 'med': 11.0, 'range': (5, 15), 'conf.': (9.881119481845285, 11.027971427245625), 'nan_count': 0}\n",
      "- PSS: {'n': 77, 'sum': 1294, 'mean': 16.805194805194805, 'SD': 7.178254737745983, 'med': 16.0, 'range': (3, 32), 'conf.': (15.175930831569763, 18.434458778819845), 'nan_count': 0}\n",
      "- PHQ: {'n': 77, 'sum': 380, 'mean': 4.935064935064935, 'SD': 4.609308837152732, 'med': 4.0, 'range': (0, 19), 'conf.': (3.888880158116967, 5.981249712012904), 'nan_count': 0}\n",
      "- GHQ: {'n': 77, 'sum': 780, 'mean': 10.12987012987013, 'SD': 5.894579689829796, 'med': 10.0, 'range': (1, 27), 'conf.': (8.791964652957894, 11.467775606782364), 'nan_count': 0}\n",
      "- particpationStartDateTime: {'n': 77, 'cardinality': 3, 'value_count': '2019-05-08 00:00:00+09:00:27, 2019-05-16 00:00:00+09:00:25, 2019-04-30 00:00:00+09:00:25'}\n"
     ]
    }
   ],
   "source": [
    "for c in PARTICIPANTS.columns:\n",
    "    print(f'- {c}:', summary(PARTICIPANTS[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels (via ESM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responseTime</th>\n",
       "      <th>scheduledTime</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>attention</th>\n",
       "      <th>stress</th>\n",
       "      <th>duration</th>\n",
       "      <th>disturbance</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557278103000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557278986000</td>\n",
       "      <td>1.557279e+12</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557281772000</td>\n",
       "      <td>1.557282e+12</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557287138000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>1557291117000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        responseTime  scheduledTime  valence  arousal  attention  stress  \\\n",
       "pcode                                                                      \n",
       "P01    1557278103000            NaN        0        0          0      -1   \n",
       "P01    1557278986000   1.557279e+12       -3        3          3       3   \n",
       "P01    1557281772000   1.557282e+12       -3       -2          2       2   \n",
       "P01    1557287138000            NaN        2       -1          2       0   \n",
       "P01    1557291117000            NaN        3        3          3      -3   \n",
       "\n",
       "       duration  disturbance  change  \n",
       "pcode                                 \n",
       "P01        20.0            3      -2  \n",
       "P01         5.0           -1      -3  \n",
       "P01        15.0            3      -2  \n",
       "P01        15.0            1      -1  \n",
       "P01        20.0            1       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "LABELS = pd.read_csv(PATH_ESM).set_index(\n",
    "    ['pcode']\n",
    ")\n",
    "LABELS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- responseTime: {'n': 5582, 'sum': 8694314195328000, 'mean': 1557562557385.8833, 'SD': 590915040.4254278, 'med': 1557562969500.0, 'range': (1556582982000, 1558545246000), 'conf.': (1557547052362.8618, 1557578062408.9048), 'nan_count': 0}\n",
      "- scheduledTime: {'n': 5582, 'sum': 5175814282500000.0, 'mean': 1557572760306.9517, 'SD': 591697484.8543198, 'med': 1557565860000.0, 'range': (1556586120000.0, nan), 'conf.': (1557552635074.4736, 1557592885539.4297), 'nan_count': 2259}\n",
      "- valence: {'n': 5582, 'sum': 3665, 'mean': 0.6565747044070226, 'SD': 1.4184297545899174, 'med': 1.0, 'range': (-3, 3), 'conf.': (0.6193565182132938, 0.6937928906007513), 'nan_count': 0}\n",
      "- arousal: {'n': 5582, 'sum': -529, 'mean': -0.09476890003582945, 'SD': 1.6675313128774563, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.13852326339835566, -0.051014536673303246), 'nan_count': 0}\n",
      "- attention: {'n': 5582, 'sum': 2236, 'mean': 0.4005732712289502, 'SD': 1.6113242733571864, 'med': 1.0, 'range': (-3, 3), 'conf.': (0.3582937246879792, 0.4428528177699212), 'nan_count': 0}\n",
      "- stress: {'n': 5582, 'sum': -1450, 'mean': -0.25976352561805804, 'SD': 1.6154902647587075, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.30215238363050767, -0.21737466760560845), 'nan_count': 0}\n",
      "- duration: {'n': 5582, 'sum': 141955.0, 'mean': 26.390593047034766, 'SD': 18.060980770860386, 'med': 20.0, 'range': (5.0, nan), 'conf.': (25.90782735251826, 26.87335874155127), 'nan_count': 203}\n",
      "- disturbance: {'n': 5582, 'sum': -243, 'mean': -0.04353278394840559, 'SD': 1.7587124884936127, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.0896796506833856, 0.0026140827865744204), 'nan_count': 0}\n",
      "- change: {'n': 5582, 'sum': -52, 'mean': -0.009315657470440702, 'SD': 0.9046571244275675, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.03305296077324875, 0.014421645832367342), 'nan_count': 0}\n"
     ]
    }
   ],
   "source": [
    "for c in LABELS.columns:\n",
    "    print(f'- {c}:', summary(LABELS[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belows are some demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- # Inst.: {'n': 77, 'sum': 5582, 'mean': 72.49350649350649, 'SD': 16.02270048911147, 'med': 74.0, 'range': (20, 110), 'conf.': (68.85679957506535, 76.13021341194762), 'nan_count': 0}\n",
      "- # Inst. - Scheduled: {'n': 76, 'sum': 3323, 'mean': 43.723684210526315, 'SD': 19.36291898394835, 'med': 43.5, 'range': (3, 83), 'conf.': (39.29906768289902, 48.14830073815361), 'nan_count': 0}\n",
      "- # Inst. - Voluntary: {'n': 77, 'sum': 2259, 'mean': 29.337662337662337, 'SD': 16.297893300742235, 'med': 27.0, 'range': (2, 74), 'conf.': (25.6384943127028, 33.03683036262187), 'nan_count': 0}\n",
      "- Samp. period: {'n': 5505, 'sum': 42240670.0, 'mean': 7673.146230699364, 'SD': 13193.471538029606, 'med': 3090.0, 'range': (1.0, 136446.0), 'conf.': (7324.548923384188, 8021.743538014541), 'nan_count': 0}\n",
      "- responseTime: {'n': 5582, 'sum': 8694314195328000, 'mean': 1557562557385.8833, 'SD': 590915040.4254278, 'med': 1557562969500.0, 'range': (1556582982000, 1558545246000), 'conf.': (1557547052362.8618, 1557578062408.9048), 'nan_count': 0}\n",
      "- scheduledTime: {'n': 5582, 'sum': 5175814282500000.0, 'mean': 1557572760306.9517, 'SD': 591697484.8543198, 'med': 1557565860000.0, 'range': (1556586120000.0, nan), 'conf.': (1557552635074.4736, 1557592885539.4297), 'nan_count': 2259}\n",
      "- valence: {'n': 5582, 'sum': 3665, 'mean': 0.6565747044070226, 'SD': 1.4184297545899174, 'med': 1.0, 'range': (-3, 3), 'conf.': (0.6193565182132938, 0.6937928906007513), 'nan_count': 0}\n",
      "- arousal: {'n': 5582, 'sum': -529, 'mean': -0.09476890003582945, 'SD': 1.6675313128774563, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.13852326339835566, -0.051014536673303246), 'nan_count': 0}\n",
      "- attention: {'n': 5582, 'sum': 2236, 'mean': 0.4005732712289502, 'SD': 1.6113242733571864, 'med': 1.0, 'range': (-3, 3), 'conf.': (0.3582937246879792, 0.4428528177699212), 'nan_count': 0}\n",
      "- stress: {'n': 5582, 'sum': -1450, 'mean': -0.25976352561805804, 'SD': 1.6154902647587075, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.30215238363050767, -0.21737466760560845), 'nan_count': 0}\n",
      "- duration: {'n': 5582, 'sum': 141955.0, 'mean': 26.390593047034766, 'SD': 18.060980770860386, 'med': 20.0, 'range': (5.0, nan), 'conf.': (25.90782735251826, 26.87335874155127), 'nan_count': 203}\n",
      "- disturbance: {'n': 5582, 'sum': -243, 'mean': -0.04353278394840559, 'SD': 1.7587124884936127, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.0896796506833856, 0.0026140827865744204), 'nan_count': 0}\n",
      "- change: {'n': 5582, 'sum': -52, 'mean': -0.009315657470440702, 'SD': 0.9046571244275675, 'med': 0.0, 'range': (-3, 3), 'conf.': (-0.03305296077324875, 0.014421645832367342), 'nan_count': 0}\n"
     ]
    }
   ],
   "source": [
    "inst = LABELS.groupby('pcode').count().iloc[:, -1]\n",
    "inst_sch = LABELS.loc[lambda x: ~x['scheduledTime'].isna(), :].groupby('pcode').count().iloc[:, -1]\n",
    "inst_vol = LABELS.loc[lambda x: x['scheduledTime'].isna(), :].groupby('pcode').count().iloc[:, -1]\n",
    "resp_time = LABELS.assign(\n",
    "    timestamp=lambda x: pd.to_datetime(x['responseTime'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    ")\n",
    "sam = np.concatenate([\n",
    "    (resp_time.loc[p, 'timestamp'].array - resp_time.loc[p, 'timestamp'].array.shift(1)).dropna().total_seconds()\n",
    "    for p in LABELS.index.unique()\n",
    "])\n",
    "\n",
    "print('- # Inst.:', summary(inst))\n",
    "print('- # Inst. - Scheduled:', summary(inst_sch))\n",
    "print('- # Inst. - Voluntary:', summary(inst_vol))\n",
    "print('- Samp. period:', summary(sam))\n",
    "for c in LABELS.columns:\n",
    "    print(f'- {c}:', summary(LABELS[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LABELS.loc[\n",
    "    :, lambda x: ~x.columns.isin(['responseTime', 'scheduledTime'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R -i data -w 16 -h 6 -u cm\n",
    "\n",
    "# data <- data %>% pivot_longer(\n",
    "#     cols = c('valence', 'arousal', 'attention', 'stress', 'duration', 'disturbance', 'change'),\n",
    "#     names_to = 'metric'\n",
    "# )\n",
    "\n",
    "# p_rest <- ggplot(\n",
    "#     data %>% filter(metric != 'duration'), aes(x=metric, y=value)\n",
    "# ) + geom_boxplot(\n",
    "# ) + geom_point(\n",
    "#     data = data %>% filter(\n",
    "#         metric != 'duration'\n",
    "#     ) %>% group_by(\n",
    "#         metric\n",
    "#     ) %>% summarise(\n",
    "#         mean = mean(value, na.rm=TRUE)\n",
    "#     ),\n",
    "#     mapping=aes(x=metric, y=mean),\n",
    "#     shape=21,\n",
    "#     stroke=1,\n",
    "#     size=2,\n",
    "#     fill='white'\n",
    "# ) + scale_x_discrete(\n",
    "#     name=NULL,\n",
    "#     limits=c('valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'),\n",
    "#     labels=c('Valence', 'Arousal', 'Stress', 'Attent.', 'Disturb.', 'Change'),\n",
    "# ) + scale_y_continuous(\n",
    "#     name='Response',\n",
    "#     breaks=-3:3\n",
    "# ) + THEME_DEFAULT\n",
    "\n",
    "# p_duration <- ggplot(\n",
    "#     data %>% filter(metric == 'duration'), aes(x=metric, y=value)\n",
    "# ) + geom_boxplot(\n",
    "# ) + geom_point(\n",
    "#     data = data %>% filter(\n",
    "#         metric == 'duration'\n",
    "#     ) %>% group_by(\n",
    "#         metric\n",
    "#     ) %>% summarise(\n",
    "#         mean = mean(value, na.rm=TRUE)\n",
    "#     ),\n",
    "#     mapping=aes(x=metric, y=mean),\n",
    "#     shape=21,\n",
    "#     stroke=1,\n",
    "#     size=2,\n",
    "#     fill='white'\n",
    "# )+ scale_x_discrete(\n",
    "#     name=NULL,\n",
    "#     limits=c('duration'),\n",
    "#     labels=c('Duration'),\n",
    "# ) + scale_y_continuous(\n",
    "#     name=NULL,\n",
    "#     breaks=seq(from=5, to=60, by=10)\n",
    "# ) + THEME_DEFAULT\n",
    "\n",
    "# p <- p_rest + p_duration + plot_layout(widths=c(4, 0.8))\n",
    "# ggsave('./fig/dist-labels.pdf', plot=p, width=16, height=6, unit='cm', device=cairo_pdf)\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each participant reported their labels multiple times (i.e., repeated measure), repeated measure correlation between affect labels were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LABELS.reset_index()[[\n",
    "    'pcode', 'valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R -i data \n",
    "\n",
    "# com <- combn(c('valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'), 2)\n",
    "\n",
    "# for(i in 1:ncol(com)) {\n",
    "#     a <- com[, i][1]\n",
    "#     b <- com[, i][2]\n",
    "#     r <- rmcorr(participant = 'pcode', measure1=a, measure2=b, dataset=data)\n",
    "#     cat(a, '-', b, ': R =', r$r, '(p =', r$p, ') \\n')\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def _load_data(\n",
    "    name: str\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    paths = [\n",
    "        (d, os.path.join(PATH_SENSOR, d, f'{name}.csv'))\n",
    "        for d in os.listdir(PATH_SENSOR)\n",
    "        if d.startswith('P')\n",
    "    ]\n",
    "    return pd.concat(\n",
    "        filter(\n",
    "            lambda x: len(x.index), \n",
    "            [\n",
    "                pd.read_csv(p).assign(pcode=pcode)\n",
    "                for pcode, p in paths\n",
    "                if os.path.exists(p)\n",
    "            ]\n",
    "        ), ignore_index=True\n",
    "    ).assign(\n",
    "        timestamp=lambda x: pd.to_datetime(x['timestamp'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    "    ).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from datetime import timedelta as td\n",
    "\n",
    "\n",
    "# STATS = []\n",
    "\n",
    "# for data_type in DATA_TYPES:\n",
    "#     dat = _load_data(data_type)\n",
    "#     inst = dat.groupby('pcode').count().iloc[:, -1]\n",
    "#     samp = np.concatenate([\n",
    "#         (dat.loc[(p,), :].index.array - dat.loc[(p,), :].index.array.shift(1)).dropna().total_seconds()\n",
    "#         for p in dat.index.get_level_values('pcode').unique()\n",
    "#     ])\n",
    "#     inst, samp = summary(inst), summary(samp)\n",
    "    \n",
    "#     print('#'*5, data_type, '#'*5)\n",
    "#     print('- # Inst.:', inst)\n",
    "#     print('- Samp. period:', samp)\n",
    "    \n",
    "#     for c in dat.columns:\n",
    "#         print(f'- {c}:', summary(dat[c]))\n",
    "        \n",
    "#     del dat\n",
    "#     gc.collect()\n",
    "    \n",
    "# STATS = pd.DataFrame(STATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label\n",
    "\n",
    "Because we intended to collected participants' responses to ESMs not voluntary responses, we screend out some responses as follows:\n",
    "* We first screen out ESM responses that does not have 'scheduledTime' (meaning that a given ESM was expired or participants voluntarily reported their affective states regardless of ESM delivery). \n",
    "* Since we will evaluate our model using LOSO, the small number of responses for each participant might lead to inappropriate performance evaluation. We emprically set the number of the minimum responses upon ESM delivery as 5 per day (i.e., a half of our guides), so that we excluded participants whose responses to ESM less than 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from participants with enough responses: 2619\n",
      "{'n': 47, 'sum': 2619, 'mean': 55.723404255319146, 'SD': 13.076201628480542, 'med': 52.0, 'range': (36, 83), 'conf.': (51.88408762653044, 59.562720884107854), 'nan_count': 0}\n",
      "# Participants whose responses to ESM delivery were less then 35\n",
      "# participants = 29 / #response = 704\n"
     ]
    }
   ],
   "source": [
    "LABELS_VALID = LABELS.loc[\n",
    "    lambda x: ~x['scheduledTime'].isna(), :\n",
    "]\n",
    "# print(LABELS_VALID)\n",
    "# print(f'# Non-voluntary response: {len(LABELS_VALID)}')\n",
    "# print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "excl_pcode = LABELS_VALID.loc[\n",
    "    lambda x: ~x['scheduledTime'].isna()\n",
    "].groupby('pcode').count().iloc[:, -1].loc[lambda y: y < 35]\n",
    "\n",
    "LABELS_VALID = LABELS_VALID.loc[\n",
    "    lambda x:  ~x.index.get_level_values('pcode').isin(excl_pcode.index), :\n",
    "]\n",
    "print(f'# Response from participants with enough responses: {len(LABELS_VALID)}')\n",
    "print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "print('# Participants whose responses to ESM delivery were less then 35')\n",
    "# print(excl_pcode, f'#participants = {len(excl_pcode)} / #response = {sum(excl_pcode)}')\n",
    "print(f'# participants = {len(excl_pcode)} / #response = {sum(excl_pcode)}')\n",
    "\n",
    "# LABELS_VALID # 참여자: 47명, 응답 2619개\n",
    "# 35개의 응답 보다 작은 참여자: 29명 (47/2619 -> 29/704)\n",
    "\n",
    "# 연구는 47명으로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider binary classifications for valence, arousal, stress, and disturbance, in which a label value greater than 0 is \"HIGH\" (1) and the rest is \"LOW\" (0), at the arrival of ESM prompts (*scheduledTime*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>attention</th>\n",
       "      <th>attention_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P01</th>\n",
       "      <th>2019-05-08 10:26:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 11:13:00+09:00</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 15:56:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 16:41:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 17:23:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P80</th>\n",
       "      <th>2019-05-05 21:57:00+09:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06 15:06:00+09:00</th>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06 15:53:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06 19:39:00+09:00</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06 21:08:00+09:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 attention  attention_bin\n",
       "pcode timestamp                                          \n",
       "P01   2019-05-08 10:26:00+09:00          3              1\n",
       "      2019-05-08 11:13:00+09:00          2              1\n",
       "      2019-05-08 15:56:00+09:00          3              1\n",
       "      2019-05-08 16:41:00+09:00          3              1\n",
       "      2019-05-08 17:23:00+09:00          3              1\n",
       "...                                    ...            ...\n",
       "P80   2019-05-05 21:57:00+09:00         -3              0\n",
       "      2019-05-06 15:06:00+09:00         -2              0\n",
       "      2019-05-06 15:53:00+09:00          3              1\n",
       "      2019-05-06 19:39:00+09:00         -1              0\n",
       "      2019-05-06 21:08:00+09:00          3              1\n",
       "\n",
       "[2619 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LABELS_PROC = (\n",
    "    LABELS_VALID\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        timestamp=lambda x: pd.to_datetime(x['scheduledTime'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ),\n",
    "        attention_bin=lambda x: np.where(x['attention'] > 0, 1, 0)\n",
    "    )\n",
    "    .loc[:, ['pcode', 'timestamp', 'attention', 'attention_bin']]  # attention: 연속형, attention_bin: 이진분류된 데이터\n",
    "    .set_index(['pcode', 'timestamp'])\n",
    ")\n",
    "\n",
    "LABELS_PROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 attention_bin\n",
      "pcode timestamp                               \n",
      "P01   2019-05-08 10:16:00+09:00              1\n",
      "      2019-05-08 10:17:00+09:00              1\n",
      "      2019-05-08 10:18:00+09:00              1\n",
      "      2019-05-08 10:19:00+09:00              1\n",
      "      2019-05-08 10:20:00+09:00              1\n",
      "      2019-05-08 10:21:00+09:00              1\n",
      "      2019-05-08 10:22:00+09:00              1\n",
      "      2019-05-08 10:23:00+09:00              1\n",
      "      2019-05-08 10:24:00+09:00              1\n",
      "      2019-05-08 10:25:00+09:00              1\n",
      "- attention_bin: {'n': 54999, 'cardinality': 2, 'value_count': '0:27552, 1:27447'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/2547955742.py:19: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# 10분 범위 설정\n",
    "TIME_DELTA = timedelta(minutes=10)\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "rows = []\n",
    "\n",
    "# 각 pcode별로 반복\n",
    "for pcode, group in LABELS_PROC.groupby(level='pcode'):\n",
    "    group = group.reset_index()\n",
    "\n",
    "    # 각 attention_bin이 있는 행에 대해\n",
    "    for _, row in group.iterrows():\n",
    "        ts = row['timestamp']\n",
    "        bin_val = row['attention_bin']\n",
    "\n",
    "        # ±10분 범위 내 timestamp 생성\n",
    "        timestamps = pd.date_range(ts - TIME_DELTA, ts + TIME_DELTA, freq='T', tz=DEFAULT_TZ)\n",
    "\n",
    "        for t in timestamps:\n",
    "            rows.append((pcode, t, bin_val))\n",
    "\n",
    "# 확장된 데이터프레임 생성\n",
    "LABELS_PROC = pd.DataFrame(rows, columns=['pcode', 'timestamp', 'attention_bin'])\n",
    "\n",
    "# 중복 제거 및 인덱스 정렬\n",
    "LABELS_PROC = (\n",
    "    LABELS_PROC\n",
    "    .drop_duplicates(subset=['pcode', 'timestamp'], keep='last')\n",
    "    .set_index(['pcode', 'timestamp'])\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# 확인 출력\n",
    "print(LABELS_PROC.head(10))\n",
    "\n",
    "# 이후 코드에 변수명 통일\n",
    "inst = LABELS_PROC.groupby('pcode').count().iloc[:, -1]\n",
    "\n",
    "for c in [c for c in LABELS_PROC.columns if c.endswith('_bin')]:\n",
    "    print(f'- {c}:', summary(LABELS_PROC[c].astype(object)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- attention_bin: {'n': 54999, 'cardinality': 2, 'value_count': '0:27552, 1:27447'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "inst = LABELS_PROC.groupby('pcode').count().iloc[:, -1]\n",
    "for c in [c for c in LABELS_PROC.columns if c.endswith('_bin')]:\n",
    "    print(f'- {c}:', summary(LABELS_PROC[c].astype(object)))\n",
    "\n",
    "# 총 응답으로 볼 때, attention의 0, 1 클래스는 balanced\n",
    "# 데이터셋으르 합칠 경우, oversampling 필요 없을 듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 평균 및 표준편차:\n",
      "  - ratio_0: 평균 = 0.500, 표준편차 = 0.206\n",
      "  - ratio_1: 평균 = 0.500, 표준편차 = 0.206\n",
      "  - imbalance_ratio: 평균 = 0.665, 표준편차 = 0.121\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inst = LABELS_PROC.groupby('pcode').count().iloc[:, -1]\n",
    "\n",
    "for c in [col for col in LABELS_PROC.columns if col.endswith('_bin')]:\n",
    "    counts = LABELS_PROC.groupby('pcode')[c].value_counts().unstack(fill_value=0)\n",
    "    ratios = counts.div(counts.sum(axis=1), axis=0)\n",
    "    stats = pd.DataFrame({\n",
    "        'n_total': counts.sum(axis=1),\n",
    "        'n_class_0': counts.get(0, 0),\n",
    "        'n_class_1': counts.get(1, 0),\n",
    "        'ratio_0': ratios.get(0, 0),\n",
    "        'ratio_1': ratios.get(1, 0),\n",
    "        'imbalance_ratio': counts.max(axis=1) / counts.sum(axis=1)\n",
    "    })\n",
    "    print(\"클래스별 평균 및 표준편차:\")\n",
    "    for col in ['ratio_0', 'ratio_1', 'imbalance_ratio']:\n",
    "        mean = stats[col].mean()\n",
    "        std = stats[col].std()\n",
    "        print(f\"  - {col}: 평균 = {mean:.3f}, 표준편차 = {std:.3f}\")\n",
    "\n",
    "# imbalance_ratio: 각 참가자의 샘플의 다수 클래스 비율\n",
    "# 값이 0.5에 가까우면 균형된 데이터\n",
    "# 문제: 전체 데이터에서는 균형, 개별 참가자 단위로는 불균형 -> LOGO시 문제 발생 가능성.\n",
    "# 해결: class_weight='balanced', oversampling, 불균형 참가자 제거, Leave-Multiple-Groups-Out\n",
    "# 평가지표? F1, ROC-AUC가 불균형에 민감한지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each type of sensor data, we applied different preprocessing. Detailed decsription is provided in the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Union\n",
    "\n",
    "# IQR -> 이상치 제거\n",
    "def _remove_outliers_iqr(series: pd.Series) -> pd.Series:\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return series.clip(lower=lower, upper=upper)\n",
    "\n",
    "# 로그 정규화 + Z-score\n",
    "def _log_normalize(series: pd.Series) -> pd.Series:\n",
    "    series = series.clip(lower=1)\n",
    "    log_vals = np.log1p(series)\n",
    "    return (log_vals - log_vals.mean()) / log_vals.std()\n",
    "\n",
    "# SkinTemperature.csv\n",
    "def _proc_skin_temperature(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    temp = data['temperature'].astype('float32')\n",
    "    temp = _remove_outliers_iqr(temp)\n",
    "    return (temp - temp.mean()) / temp.std()\n",
    "\n",
    "# RRI.csv\n",
    "def _proc_rri(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    rri = data['interval'].astype('float32')\n",
    "    rri = _remove_outliers_iqr(rri)\n",
    "    return (rri - rri.mean()) / rri.std()\n",
    "\n",
    "# HR.csv\n",
    "def _proc_hr(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    hr = data['bpm'].astype('float32')\n",
    "    hr = _remove_outliers_iqr(hr)\n",
    "    return (hr - hr.mean()) / hr.std()\n",
    "\n",
    "# EDA.csv\n",
    "def _proc_eda(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    eda = data['resistance'].astype('float32')\n",
    "    eda = _remove_outliers_iqr(eda)\n",
    "    return _log_normalize(eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 20:16:04,203\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_process pid=20425)\u001b[0m [25-06-01 20:16:05] Begin to processing data: SkinTemperature\n",
      "\u001b[2m\u001b[36m(_process pid=20429)\u001b[0m [25-06-01 20:16:05] Begin to processing data: EDA\n",
      "\u001b[2m\u001b[36m(_process pid=20427)\u001b[0m [25-06-01 20:16:05] Begin to processing data: RRI\n",
      "\u001b[2m\u001b[36m(_process pid=20428)\u001b[0m [25-06-01 20:16:05] Begin to processing data: HR\n",
      "\u001b[2m\u001b[36m(_process pid=20425)\u001b[0m [25-06-01 20:16:05] Complete processing data: SkinTemperature\n",
      "\u001b[2m\u001b[36m(_process pid=20428)\u001b[0m [25-06-01 20:16:14] Complete processing data: HR\n",
      "\u001b[2m\u001b[36m(_process pid=20427)\u001b[0m [25-06-01 20:16:21] Complete processing data: RRI\n",
      "\u001b[2m\u001b[36m(_process pid=20429)\u001b[0m [25-06-01 20:17:00] Complete processing data: EDA\n",
      "[25-06-01 20:17:08] [SAVE] done in 0.8s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from functools import reduce\n",
    "import time\n",
    "\n",
    "FUNC_PROC = {\n",
    "    'EDA': _proc_eda,\n",
    "    'HR': _proc_hr,\n",
    "    'RRI': _proc_rri,\n",
    "    'SkinTemperature': _proc_skin_temperature,\n",
    "}\n",
    "\n",
    "\n",
    "def _process(data_type: str):\n",
    "    log(f'Begin to processing data: {data_type}')\n",
    "    \n",
    "    abbrev = DATA_TYPES[data_type]\n",
    "    data_raw = _load_data(data_type)\n",
    "    data_proc = FUNC_PROC[data_type](data_raw)\n",
    "    result = dict()\n",
    "    \n",
    "    if type(data_proc) is dict:\n",
    "        for k, v in data_proc.items():\n",
    "            result[f'{abbrev}_{k}'] = v\n",
    "    else:\n",
    "        result[abbrev] = data_proc\n",
    "        \n",
    "    log(f'Complete processing data: {data_type}')\n",
    "    return result\n",
    "\n",
    "\n",
    "with on_ray(num_cpus=12):\n",
    "    jobs = []\n",
    "    \n",
    "    func = ray.remote(_process).remote\n",
    "    \n",
    "    for data_type in DATA_TYPES:\n",
    "        job = func(data_type)\n",
    "        jobs.append(job)\n",
    "\n",
    "    jobs = ray.get(jobs)\n",
    "    \n",
    "    # 메모리 최적화를 위해 추가 \n",
    "    combined_result = {}\n",
    "    for d in jobs:\n",
    "        combined_result |= d\n",
    "    \n",
    "    t0 = time.time()\n",
    "    dump(combined_result, os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "    log(f'[SAVE] done in {time.time() - t0:.1f}s')\n",
    "    \n",
    "    del jobs\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/1220431816.py:36: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  (v.loc[(p,)].index.array - v.loc[(p,)].index.array.shift(1)).dropna().total_seconds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### EDA #####\n",
      "- Samp. period: {'n': 71161950, 'sum': 14178099.724999897, 'mean': 0.19923708842998114, 'SD': 0.01263709088351348, 'med': 0.199, 'range': (0.164, 0.235), 'conf.': (0.19923415232697866, 0.19924002453298362), 'nan_count': 0}\n",
      "- Values {'n': 80150329, 'sum': -2529.9434, 'mean': -3.1564978e-05, 'SD': 0.99999815, 'med': -0.10594783, 'range': (-4.833558, 1.4691741), 'conf.': (-0.0002504896157723061, 0.00018735966039347936), 'nan_count': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/1220431816.py:36: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  (v.loc[(p,)].index.array - v.loc[(p,)].index.array.shift(1)).dropna().total_seconds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### HRT #####\n",
      "- Samp. period: {'n': 12126885, 'sum': 12080570.162999991, 'mean': 0.9961808133745799, 'SD': 0.013881222953694618, 'med': 0.996, 'range': (0.956, 1.036), 'conf.': (0.9961730006730264, 0.9961886260761333), 'nan_count': 0}\n",
      "- Values {'n': 13621023, 'sum': 114.31421, 'mean': 8.392483e-06, 'SD': 1.0, 'med': -0.034554552, 'range': (-2.3233254, 2.2542164), 'conf.': (-0.0005226671196859384, 0.0005394520863327485), 'nan_count': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/1220431816.py:36: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  (v.loc[(p,)].index.array - v.loc[(p,)].index.array.shift(1)).dropna().total_seconds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### RRI #####\n",
      "- Samp. period: {'n': 20153483, 'sum': 15346016.337999996, 'mean': 0.7614572795183838, 'SD': 0.17227250402189642, 'med': 0.76, 'range': (0.308, 1.215), 'conf.': (0.761382067191175, 0.7615324918455927), 'nan_count': 0}\n",
      "- Values {'n': 20764471, 'sum': 4.092726157978177e-11, 'mean': 1.971023561340993e-18, 'SD': 1.0000000000000007, 'med': 0.04632033346408256, 'range': (-2.4651769846616585, 2.4630442731345945), 'conf.': (-0.00043011806230934996, 0.00043011806230935386), 'nan_count': 0}\n",
      "\n",
      "##### SKT #####\n",
      "- Samp. period: {'n': 466247, 'sum': 14025575.527000003, 'mean': 30.081856884870042, 'SD': 0.014188487166116254, 'med': 30.082, 'range': (30.04, 30.123), 'conf.': (30.08181615835165, 30.081897611388435), 'nan_count': 0}\n",
      "- Values {'n': 535095, 'sum': 2.2646418074145913e-10, 'mean': 4.232223824581787e-16, 'SD': 1.0000000000000002, 'med': 0.13509866738899262, 'range': (-2.527910477209998, 2.629919190267469), 'conf.': (-0.002679375777865103, 0.0026793757778659495), 'nan_count': 0}\n",
      "\n",
      "# categorical data: 0/# numeric data: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/1220431816.py:36: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  (v.loc[(p,)].index.array - v.loc[(p,)].index.array.shift(1)).dropna().total_seconds()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "# DATA_ITEMS:\n",
    "# [('EDA', pcode  timestamp                       \n",
    "# P19    2019-05-08 09:00:00.029000+09:00     10070.0\n",
    "#        2019-05-08 09:00:00.233000+09:00     10010.0\n",
    "#        2019-05-08 09:00:00.434000+09:00     10160.0\n",
    "#        2019-05-08 09:00:00.640000+09:00     10130.0\n",
    "#        2019-05-08 09:00:00.842000+09:00     10130.0\n",
    "\n",
    "def _remove_outliers_iqr_np(arr: np.ndarray) -> np.ndarray: # IQR 방식으로 샘플링 주기 이상치 제거\n",
    "    q1 = np.percentile(arr, 25)\n",
    "    q3 = np.percentile(arr, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return arr[(arr >= lower) & (arr <= upper)]\n",
    "\n",
    "\n",
    "\n",
    "DATA = load(os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "#categorial, numeric 변수 수 계산\n",
    "N_NUMERIC, N_CATEGORICAL = 0, 0\n",
    "\n",
    "for k, v in DATA.items():\n",
    "    if v.dtype.kind.isupper() or v.dtype.kind == 'b': \n",
    "        N_CATEGORICAL += 1\n",
    "    else:\n",
    "        N_NUMERIC += 1\n",
    "\n",
    "    inst = v.groupby('pcode').count()\n",
    "    \n",
    "    # 샘플링 주기 계산 및 이상치 제거\n",
    "    sam = np.concatenate([\n",
    "        (v.loc[(p,)].index.array - v.loc[(p,)].index.array.shift(1)).dropna().total_seconds()\n",
    "        for p in v.index.get_level_values('pcode').unique()\n",
    "    ])\n",
    "    sam = _remove_outliers_iqr_np(sam)\n",
    "\n",
    "    \n",
    "    print('#'*5, k, '#'*5, )\n",
    "#     print('- # Inst.:', inst)\n",
    "    print('- Samp. period:', summary(sam))\n",
    "    print('- Values', summary(v))\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "print(f'# categorical data: {N_CATEGORICAL}/# numeric data: {N_NUMERIC}')\n",
    "del DATA\n",
    "gc.collect()\n",
    "\n",
    "# IQR 방식으로 샘플링 주기 이상치 제거 전\n",
    "# | 센서   | 샘플링 주기 평균 (s)     | 샘플링 주기 SD    \n",
    "# |-------|----------------------|----------------\n",
    "# | EDA   | 0.514                | 140.55         \n",
    "# | HRT   | 3.008                | 362.92         \n",
    "# | RRI   | 1.985                | 276.20         \n",
    "# | SKT   | 77.03                | 1,719.19       \n",
    "\n",
    "# IQR 방식으로 샘플링 주기 이상치 제거 후\n",
    "# | 센서   | 샘플링 주기 평균 (s)     | 샘플링 주기 SD    \n",
    "# |-------|----------------------|----------------\n",
    "# | EDA   | 0.199                | 0.013          \n",
    "# | HRT   | 0.996                | 0.014          \n",
    "# | RRI   | 0.761                | 0.172          \n",
    "# | SKT   | 30.08                | 0.014          \n",
    "\n",
    "# - EDA:\n",
    "#   · 많이 이상함. 전처리 필요\n",
    "#   · 매우 빠른 샘플링(0.5초), 샘플링 주기의 표준편차가 매우 큼. \n",
    "#   · 샘플 누락, 중단, 오류 구간의 존재 가능성?, 극단적으로 큰 샘플링 주기가 존재?\n",
    "#     -> 이상치 제거, 리샘플링, (스케일이 너무 큼 -> 정규화(로그 변환, 정규화))\n",
    "#   · 측정값이 큼 -> log 변환 고려?\n",
    "\n",
    "# - HRT:\n",
    "#   · 평균 주기 3초, SD=362초 -> 이것도 이상함, 이상치 제거 필요?\n",
    "#   · 평균, 표준편차 왜곡?\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Callable, Union, Tuple, List, Optional, Iterable\n",
    "from datetime import timedelta as td\n",
    "from scipy import stats\n",
    "from scipy.interpolate import CubicSpline\n",
    "import ray\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "def _safe_na_check(_v):\n",
    "    _is_nan_inf = False\n",
    "    try:\n",
    "        _is_nan_inf = np.isnan(_v) or np.isinf(_v)\n",
    "    except:\n",
    "        _is_nan_inf = False\n",
    "    return _is_nan_inf or _v is None\n",
    "\n",
    "# _extract: 한 명의 참가자(pid)의 feature 생성\n",
    "# _extract 출력:\n",
    "# X: DataFrame(n, f) / n = 라벨 개수, f = 추출된 feature 수 / row: timestamp에 대한 feature vector, col: 센서, 시간 기반 피쳐\n",
    "# y: np.ndarray(n,) / timestamp별 라벨(1D)\n",
    "# group: np.ndarray(n,) / 참가자 ID 반복 배열 (모델 그룹 분리용) / 각 row 별 pid - KFold, LOGO에 사용 / 입력 파라미터의 pid와 동일값 반복\n",
    "# date_times: np.ndarray(n,) / 각 sample의 timestamp\n",
    "def _extract(\n",
    "        pid: str,\n",
    "        data: Dict[str, pd.Series], # pcode, timestamp으로 구성된 센서의 시계열 데이터\n",
    "        label: pd.Series, # timestamp별 라벨\n",
    "        label_values: List[str], # 가능한 class: [0, 1]\n",
    "        window_data: Dict[str, Union[int, Callable[[pd.Timestamp], int]]], # 센서별 time-window 크기\n",
    "        window_label: Dict[str, Union[int, Callable[[pd.Timestamp], int]]], # label의 time-window 크기\n",
    "        categories: Dict[str, Optional[List[any]]] = None, # 범주형 센서\n",
    "        resample_s: Dict[str, float] = None # 센서별 리샘플링 간격\n",
    ") -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    _s = time.time()\n",
    "    log(f\"Begin feature extraction on {pid}'s data.\")\n",
    "\n",
    "    categories = categories or dict()\n",
    "    resample_s = resample_s or dict()\n",
    "\n",
    "    X, y, date_times = [], [], [] # 상단 주석 참고\n",
    " \n",
    "    for timestamp in label.index:\n",
    "        row = dict() # 각 timestamp 별 feature을 저장\n",
    "\n",
    "        label_cur = label.at[timestamp]\n",
    "        t = timestamp - td(milliseconds=1)\n",
    "\n",
    "        # Features from sensor data\n",
    "        for d_key, d_val in data.items():\n",
    "            is_numeric = d_key not in categories\n",
    "            cats = categories.get(d_key) or list()\n",
    "            d_val = d_val.sort_index()\n",
    "\n",
    "            if is_numeric or cats:\n",
    "                try:\n",
    "                    v = d_val.loc[:t].iloc[-1]             # t 시점 직전 가장 마지막 센서 값을 사용\n",
    "                except (KeyError, IndexError):\n",
    "                    v = 0\n",
    "\n",
    "                if is_numeric:\n",
    "                    row[f'{d_key}#VAL'] = v\n",
    "                else:\n",
    "                    for c in cats:\n",
    "                        row[f'{d_key}#VAL={c}'] = v == c\n",
    "\n",
    "            # catogorial 데이터의 최근 상태 변화 시간\n",
    "            if not is_numeric:\n",
    "                try:\n",
    "                    v = d_val.loc[:t]\n",
    "                    row[f'{d_key}#DSC'] = (t - v.index[-1]).total_seconds() if len(v) else -1.0\n",
    "                    for c in cats:\n",
    "                        v_sub = v.loc[lambda x: x == c].index\n",
    "                        row[f'{d_key}#DSC={c}'] = (t - v_sub[-1]).total_seconds() if len(v_sub) else -1.0\n",
    "                except (KeyError, IndexError):\n",
    "                    row[f'{d_key}#DSC'] = -1.0\n",
    "                    for c in cats:\n",
    "                        row[f'{d_key}#DSC={c}'] = -1.0\n",
    "\n",
    "            # Time-window 기반 피처 (resampling 포함)\n",
    "            sample_rate = resample_s.get(d_key) or 1\n",
    "            d_val_res = d_val.resample(f'{sample_rate}s', origin='start')\n",
    "            if is_numeric:\n",
    "                \"\"\" 보간 방식 추가 부분 \"\"\"\n",
    "                if d_key == \"interval\":\n",
    "                    interval_series = d_val.dropna()\n",
    "                    if len(interval_series) >= 4:\n",
    "                        ts = interval_series.index.view(np.int64) // 10**6\n",
    "                        cs = CubicSpline(ts, interval_series.values)\n",
    "                        full_ts = d_val.index.view(np.int64) // 10**6\n",
    "                        d_val[:] = cs(full_ts)\n",
    "                else: \n",
    "                    d_val_res = d_val_res.mean().interpolate(method='linear').dropna()\n",
    "            else:\n",
    "                d_val_res = d_val_res.ffill().dropna()\n",
    "\n",
    "            for w_key, w_val in window_data.items():\n",
    "                w_val = w_val(t) if isinstance(w_val, Callable) else w_val\n",
    "                try:\n",
    "                    v = d_val_res.loc[t - td(seconds=w_val):t]\n",
    "                    # numeric 데이터일 경우에만 변환\n",
    "                    if is_numeric:\n",
    "                        v_arr = v.values.astype(np.float64)\n",
    "                    else:\n",
    "                        v_arr = v\n",
    "                except (KeyError, IndexError):\n",
    "                    continue\n",
    "\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter('ignore')\n",
    "\n",
    "                    if is_numeric:\n",
    "                        hist, _ = np.histogram(v, bins='doane', density=False)\n",
    "                        std = np.sqrt(np.var(v, ddof=1)) if len(v) > 1 else 0\n",
    "                        v_norm = (v - np.mean(v)) / std if std != 0 else np.zeros(len(v))\n",
    "                        # window_data 기준으로 구간 추출 - 통계 기반\n",
    "                        row[f'{d_key}#AVG#{w_key}'] = np.float32(np.mean(v_arr))\n",
    "                        row[f'{d_key}#STD#{w_key}'] = np.float32(std)\n",
    "                        row[f'{d_key}#SKW#{w_key}'] = np.float32(stats.skew(v_arr, bias=False))\n",
    "                        row[f'{d_key}#KUR#{w_key}'] = np.float32(stats.kurtosis(v_arr, bias=False))\n",
    "                        row[f'{d_key}#ASC#{w_key}'] = np.float32(np.sum(np.abs(np.diff(v_arr))))\n",
    "                        row[f'{d_key}#BEP#{w_key}'] = np.float32(stats.entropy(hist))\n",
    "                        row[f'{d_key}#MED#{w_key}'] = np.float32(np.median(v_arr))\n",
    "                        # TSC: 시계열 복잡성. √(Δ값 제곱합) \n",
    "                        row[f'{d_key}#TSC#{w_key}'] = np.float32(np.sqrt(np.sum(np.power(np.diff(v_norm), 2))))\n",
    "                    else:\n",
    "                        cnt = v.value_counts()\n",
    "                        val, sup = cnt.index, cnt.values\n",
    "                        hist = {k: v for k, v in zip(val, sup)}\n",
    "\n",
    "                        row[f'{d_key}#ETP#{w_key}'] = stats.entropy(sup / len(v))\n",
    "                        row[f'{d_key}#ASC#{w_key}'] = np.sum(v.values[1:] != v.values[:-1])\n",
    "\n",
    "                        if len(cats) == 2:\n",
    "                            c = cats[0]\n",
    "                            row[f'{d_key}#DUR#{w_key}'] = hist[c] / len(v) if c in hist else 0\n",
    "                        else:\n",
    "                            for c in cats:\n",
    "                                row[f'{d_key}#DUR={c}#{w_key}'] = hist[c] / len(v) if c in hist else 0\n",
    "\n",
    "        # 시간 기반 피처: one-hot encoding\n",
    "        day_of_week = ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN'][t.isoweekday() - 1]\n",
    "        is_weekend = 'Y' if t.isoweekday() > 5 else 'N'\n",
    "        hour = t.hour\n",
    "\n",
    "        # 시간대별 패턴: 비정기적 설문조사 주기에 맞게 하루를 7개의 시간대로 분할\n",
    "        if 6 <= hour < 9:\n",
    "            hour_name = 'DAWN'\n",
    "        elif 9 <= hour < 12:\n",
    "            hour_name = 'MORNING'\n",
    "        elif 12 <= hour < 15:\n",
    "            hour_name = 'AFTERNOON'\n",
    "        elif 15 <= hour < 18:\n",
    "            hour_name = 'LATE_AFTERNOON'\n",
    "        elif 18 <= hour < 21:\n",
    "            hour_name = 'EVENING'\n",
    "        elif 21 <= hour < 24:\n",
    "            hour_name = 'NIGHT'\n",
    "        else:\n",
    "            hour_name = 'MIDNIGHT'\n",
    "\n",
    "        for d in ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']:\n",
    "            row[f'ESM#DOW={d}'] = d == day_of_week\n",
    "\n",
    "        for d in ['Y', 'N']:\n",
    "            row[f'ESM#WKD={d}'] = d == is_weekend\n",
    "\n",
    "        for d in ['DAWN', 'MORNING', 'AFTERNOON', 'LATE_AFTERNOON', 'EVENING', 'NIGHT', 'MIDNIGHT']:\n",
    "            row[f'ESM#HRN={d}'] = d == hour_name\n",
    "\n",
    "        # 응답 이력 기반 피처: 지난 3시간 내 (예시) 응답 중 긍정/부정 응답 비율\n",
    "        for w_key, w_val in window_label.items():\n",
    "            w_val = w_val(t) if isinstance(w_val, Callable) else w_val\n",
    "            try:\n",
    "                v = label.loc[t - td(seconds=w_val):t]\n",
    "                if len(label_values) <= 2:\n",
    "                    row[f'ESM#LIK#{w_key}'] = np.sum(v == label_values[0]) / len(v) if len(v) > 0 else 0\n",
    "                else:\n",
    "                    for l in label_values:\n",
    "                        row[f'ESM#LIK={l}#{w_key}'] = np.sum(v == l) / len(v) if len(v) > 0 else 0\n",
    "            except (KeyError, IndexError):\n",
    "                if len(label_values) <= 2: \n",
    "                    row[f'ESM#LIK#{w_key}'] = 0\n",
    "                else:\n",
    "                    for l in label_values:\n",
    "                        row[f'ESM#LIK={l}#{w_key}'] = 0\n",
    "\n",
    "        row = {\n",
    "            k: 0.0 if _safe_na_check(v) else v\n",
    "            for k, v in row.items()\n",
    "        }\n",
    "        X.append(row)\n",
    "        y.append(label_cur)\n",
    "        date_times.append(timestamp)\n",
    "\n",
    "    log(f\"Complete feature extraction on {pid}'s data ({time.time() - _s:.2f} s).\")\n",
    "    X, y, group, date_times = pd.DataFrame(X), np.asarray(y), np.repeat(pid, len(y)), np.asarray(date_times)\n",
    "    \n",
    "    #출력 결과 코드\n",
    "    print(f\"[{pid}] Extracted {X.shape[0]} samples with {X.shape[1]} features\")\n",
    "    return X, y, group, date_times\n",
    "\n",
    "# _extract를 참가자 리스트 전체에 병렬/순차적으로 적용 -> 최종 feature 데이터\n",
    "# 출력: \n",
    "# X: 전체 참가자의 feature 데이터 (DataFrame)\n",
    "# y: 전체 라벨\n",
    "# group: 각 행에 해당하는 참가자의 ID\n",
    "# t_norm: timestamp를 기준 시점으로부터 정규화한 시간 (초 단위), XGB, NN에 사용 가능\n",
    "# date_times: 각 sample의 실제 timestamp (Datetime array)\n",
    "\n",
    "def extract(\n",
    "        pids: Iterable[str], \n",
    "        data: Dict[str, pd.Series], # 전체 센서 데이터\n",
    "        label: pd.Series, # 전체 라벨\n",
    "        label_values: List[str],\n",
    "        window_data: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],\n",
    "        window_label: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],        \n",
    "        categories: Dict[str, Optional[List[any]]] = None,        \n",
    "        resample_s: Dict[str, float] = None,\n",
    "        with_ray: bool=False\n",
    "):\n",
    "    if with_ray and not ray.is_initialized():\n",
    "        raise EnvironmentError('Ray should be initialized if \"with_ray\" is set as True.')\n",
    "\n",
    "    func = ray.remote(_extract).remote if with_ray else _extract\n",
    "    jobs = []\n",
    "    \n",
    "    # 참가자별로 _extract 실행 (단일 or 병렬)\n",
    "    for pid in pids:\n",
    "        d = dict()\n",
    "        for k, v in data.items():\n",
    "            try:\n",
    "                d[k] = v.loc[(pid, )]\n",
    "            except (KeyError, IndexError):\n",
    "                pass\n",
    "\n",
    "        job = func(\n",
    "            pid=pid,\n",
    "            data=d,\n",
    "            label=label.loc[(pid, )],\n",
    "            label_values=label_values,\n",
    "            window_data=window_data,\n",
    "            window_label=window_label,\n",
    "            categories=categories,\n",
    "            resample_s=resample_s\n",
    "        )\n",
    "        jobs.append(job)\n",
    "\n",
    "    jobs = ray.get(jobs) if with_ray else jobs\n",
    "\n",
    "    X = pd.concat([x for x, _, _, _ in jobs], axis=0, ignore_index=True)\n",
    "    y = np.concatenate([x for _, x, _, _ in jobs], axis=0)\n",
    "    group = np.concatenate([x for _, _, x, _ in jobs], axis=0)\n",
    "    date_times = np.concatenate([x for _, _, _, x in jobs], axis=0)\n",
    "    \n",
    "    # 모든 참가자의 feature / label 결과 통합. timestamp를 자정 기준으로 정렬 -> t_norm(상대적 시간) 계산 위한 준비\n",
    "    t_s = date_times.min().normalize().timestamp()\n",
    "    # datetime을 수치화된 상대 시간으로 변환. 머신러닝의 효과적인 학습 위함. t_s(시작 시간)기준으로 얼마나 지났는지\n",
    "    t_norm = np.asarray(list(map(lambda x: x.timestamp() - t_s, date_times)))\n",
    "\n",
    "    # 결측치 처리 및 dtype 설정\n",
    "    C, DTYPE = X.columns, X.dtypes\n",
    "\n",
    "    X = X.fillna({\n",
    "        **{c: False for c in C[(DTYPE == object) | (DTYPE == bool)]},\n",
    "        **{c: 0.0 for c in C[(DTYPE != object) & (DTYPE != bool)]},\n",
    "    }).astype({\n",
    "        **{c: 'bool' for c in C[(DTYPE == object) | (DTYPE == bool)]},\n",
    "        **{c: 'float32' for c in C[(DTYPE != object) & (DTYPE != bool)]},\n",
    "    })\n",
    "\n",
    "    return X, y, group, t_norm, date_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_VALUES = [1, 0]\n",
    "\n",
    "WINDOW_DATA = {\n",
    "    'S30': 30,\n",
    "    'M01': 60,\n",
    "    'M05': 60 * 5,\n",
    "    'M10': 60 * 10,\n",
    "    'M30': 60 * 30,\n",
    "    'H01': 60 * 60,\n",
    "    # 'H02': 60 * 60 * 2, # 추가 \n",
    "    'H03': 60 * 60 * 3,\n",
    "    # 'H04': 60 * 60 * 4, # 추가 \n",
    "    # 'H05': 60 * 60 * 5, # 추가\n",
    "    'H06': 60 * 60 * 6\n",
    "}\n",
    "\n",
    "WINDOW_LABEL = {\n",
    "    'H06': 60 * 60 * 6,\n",
    "    'H12': 60 * 60 * 12,\n",
    "    'H24': 60 * 60 * 24,\n",
    "}\n",
    "\n",
    "RESAMPLE_s = {\n",
    "    'EDA': 0.25,\n",
    "}\n",
    "\n",
    "DATA = load(os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 20:18:18,139\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/101961088.py:233: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  d[k] = v.loc[(pid, )]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [25-06-01 20:18:21] Begin feature extraction on P01's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [25-06-01 20:18:21] Begin feature extraction on P02's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [25-06-01 20:18:21] Begin feature extraction on P03's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [25-06-01 20:18:21] Begin feature extraction on P05's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [25-06-01 20:18:22] Begin feature extraction on P06's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [25-06-01 20:18:23] Begin feature extraction on P08's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [25-06-01 20:18:23] Begin feature extraction on P09's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [25-06-01 20:18:24] Begin feature extraction on P10's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [25-06-01 20:18:25] Begin feature extraction on P12's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [25-06-01 20:18:27] Begin feature extraction on P13's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 20:18:27] Begin feature extraction on P15's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [25-06-01 20:18:28] Begin feature extraction on P19's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 20:37:25] Complete feature extraction on P15's data (1137.40 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [P15] Extracted 819 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 20:37:25] Begin feature extraction on P21's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [25-06-01 20:40:14] Complete feature extraction on P01's data (1313.60 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [P01] Extracted 840 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [25-06-01 20:40:14] Begin feature extraction on P23's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [25-06-01 20:41:12] Complete feature extraction on P10's data (1367.87 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [P10] Extracted 987 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [25-06-01 20:41:13] Begin feature extraction on P26's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [25-06-01 20:41:41] Complete feature extraction on P03's data (1400.00 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [P03] Extracted 924 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [25-06-01 20:41:41] Begin feature extraction on P28's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [25-06-01 20:43:51] Complete feature extraction on P12's data (1525.90 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [P12] Extracted 945 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [25-06-01 20:43:51] Begin feature extraction on P30's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [25-06-01 20:45:52] Complete feature extraction on P02's data (1651.38 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [P02] Extracted 1071 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [25-06-01 20:45:52] Begin feature extraction on P31's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [25-06-01 20:45:54] Complete feature extraction on P06's data (1651.88 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [P06] Extracted 1029 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [25-06-01 20:45:55] Begin feature extraction on P32's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [25-06-01 20:47:01] Complete feature extraction on P05's data (1719.27 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [P05] Extracted 1071 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [25-06-01 20:47:01] Begin feature extraction on P33's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [25-06-01 20:47:04] Complete feature extraction on P19's data (1715.42 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [P19] Extracted 1092 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [25-06-01 20:47:04] Begin feature extraction on P35's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [25-06-01 20:48:57] Complete feature extraction on P09's data (1833.30 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [P09] Extracted 1155 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [25-06-01 20:48:57] Begin feature extraction on P39's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [25-06-01 20:49:01] Complete feature extraction on P13's data (1834.11 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [P13] Extracted 1134 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [25-06-01 20:49:01] Begin feature extraction on P40's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [25-06-01 20:55:57] Complete feature extraction on P08's data (2254.45 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [P08] Extracted 1449 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [25-06-01 20:55:58] Begin feature extraction on P42's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 21:01:52] Complete feature extraction on P21's data (1466.90 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [P21] Extracted 1050 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 21:01:52] Begin feature extraction on P45's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [25-06-01 21:02:54] Complete feature extraction on P23's data (1359.63 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [P23] Extracted 1029 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [25-06-01 21:02:55] Begin feature extraction on P47's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [25-06-01 21:07:38] Complete feature extraction on P33's data (1236.51 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [P33] Extracted 819 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [25-06-01 21:07:38] Begin feature extraction on P48's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [25-06-01 21:10:17] Complete feature extraction on P32's data (1462.49 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [P32] Extracted 1092 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [25-06-01 21:10:18] Begin feature extraction on P49's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [25-06-01 21:13:17] Complete feature extraction on P31's data (1644.98 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [P31] Extracted 1113 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [25-06-01 21:13:18] Begin feature extraction on P50's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [25-06-01 21:14:27] Complete feature extraction on P35's data (1642.72 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [P35] Extracted 1071 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [25-06-01 21:14:27] Begin feature extraction on P51's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [25-06-01 21:17:28] Complete feature extraction on P39's data (1710.33 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [P39] Extracted 1260 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [25-06-01 21:17:28] Begin feature extraction on P52's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [25-06-01 21:19:35] Complete feature extraction on P26's data (2302.48 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [P26] Extracted 1596 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [25-06-01 21:19:36] Begin feature extraction on P53's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [25-06-01 21:20:09] Complete feature extraction on P40's data (1867.74 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [P40] Extracted 1197 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [25-06-01 21:20:09] Begin feature extraction on P55's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 21:21:33] Complete feature extraction on P45's data (1181.16 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [P45] Extracted 798 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 21:21:34] Begin feature extraction on P57's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [25-06-01 21:22:34] Complete feature extraction on P30's data (2322.68 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [P30] Extracted 1470 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [25-06-01 21:22:34] Begin feature extraction on P60's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [25-06-01 21:26:27] Complete feature extraction on P28's data (2685.75 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [P28] Extracted 1743 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [25-06-01 21:26:28] Begin feature extraction on P61's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [25-06-01 21:26:48] Complete feature extraction on P42's data (1850.16 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [P42] Extracted 1470 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [25-06-01 21:26:49] Begin feature extraction on P66's data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [25-06-01 21:27:36] Complete feature extraction on P48's data (1197.49 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [P48] Extracted 777 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [25-06-01 21:27:36] Begin feature extraction on P67's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [25-06-01 21:35:59] Complete feature extraction on P50's data (1361.36 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [P50] Extracted 903 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [25-06-01 21:36:00] Begin feature extraction on P69's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [25-06-01 21:40:50] Complete feature extraction on P47's data (2275.54 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [P47] Extracted 1617 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [25-06-01 21:40:51] Begin feature extraction on P70's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [25-06-01 21:44:44] Complete feature extraction on P52's data (1635.20 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [P52] Extracted 903 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [25-06-01 21:44:44] Begin feature extraction on P72's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [25-06-01 21:47:27] Complete feature extraction on P51's data (1980.30 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [P51] Extracted 1323 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [25-06-01 21:47:28] Begin feature extraction on P75's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [25-06-01 21:56:06] Complete feature extraction on P55's data (2156.90 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [P55] Extracted 1176 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [25-06-01 21:56:07] Begin feature extraction on P76's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 21:58:14] Complete feature extraction on P57's data (2200.51 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [P57] Extracted 1197 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 21:58:15] Begin feature extraction on P77's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [25-06-01 22:00:55] Complete feature extraction on P49's data (3037.67 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [P49] Extracted 1659 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [25-06-01 22:00:56] Begin feature extraction on P78's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [25-06-01 22:00:58] Complete feature extraction on P53's data (2481.89 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [P53] Extracted 1596 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [25-06-01 22:00:58] Begin feature extraction on P79's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [25-06-01 22:01:30] Complete feature extraction on P66's data (2081.67 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [P66] Extracted 1092 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [25-06-01 22:01:31] Begin feature extraction on P80's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [25-06-01 22:04:08] Complete feature extraction on P60's data (2493.33 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20465)\u001b[0m [P60] Extracted 1281 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [25-06-01 22:09:36] Complete feature extraction on P70's data (1724.97 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20469)\u001b[0m [P70] Extracted 777 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [25-06-01 22:13:54] Complete feature extraction on P67's data (2778.19 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20471)\u001b[0m [P67] Extracted 1365 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [25-06-01 22:15:44] Complete feature extraction on P61's data (2955.68 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20474)\u001b[0m [P61] Extracted 1533 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [25-06-01 22:18:51] Complete feature extraction on P79's data (1073.23 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20467)\u001b[0m [P79] Extracted 756 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [25-06-01 22:19:24] Complete feature extraction on P77's data (1269.05 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20468)\u001b[0m [P77] Extracted 924 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [25-06-01 22:20:37] Complete feature extraction on P80's data (1146.15 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20473)\u001b[0m [P80] Extracted 987 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [25-06-01 22:20:53] Complete feature extraction on P72's data (2168.26 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20466)\u001b[0m [P72] Extracted 1365 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [25-06-01 22:20:53] Complete feature extraction on P69's data (2693.65 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20475)\u001b[0m [P69] Extracted 1596 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [25-06-01 22:21:56] Complete feature extraction on P75's data (2068.21 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20472)\u001b[0m [P75] Extracted 1533 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [25-06-01 22:22:07] Complete feature extraction on P78's data (1271.13 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20470)\u001b[0m [P78] Extracted 1050 samples with 279 features\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [25-06-01 22:22:46] Complete feature extraction on P76's data (1599.00 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=20464)\u001b[0m [P76] Extracted 1365 samples with 279 features\n"
     ]
    }
   ],
   "source": [
    "with on_ray(num_cpus=12):\n",
    "    l = 'attention'\n",
    "\n",
    "    labels = LABELS_PROC[f'{l}_bin']\n",
    "    pids = labels.index.get_level_values('pcode').unique()\n",
    "\n",
    "    feat = extract(\n",
    "        pids=pids, \n",
    "        data=DATA,         \n",
    "        label=labels,\n",
    "        label_values=LABEL_VALUES,\n",
    "        window_data=WINDOW_DATA,\n",
    "        window_label=WINDOW_LABEL,\n",
    "        resample_s=RESAMPLE_s,\n",
    "        with_ray=True\n",
    "    )\n",
    "\n",
    "    dump(feat, os.path.join(PATH_INTERMEDIATE, f'{l}.pkl'))\n",
    "\n",
    "# 결과 timestamp 기반 응답 수가 35~83 -> 참가자 간 f1-score의 분산이 큰 경우, 조정 필요\n",
    "# Extracted 54 samples with 279 features: 응답수 54개, feature 279개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# attention\n",
      "- Feature space: 279; Cat.: 16; Num.: 263\n",
      "- Label distribution: (array([0, 1]), array([27552, 27447]))\n",
      "# attention feature extraction summary\n",
      "- Feature matrix: X.shape = (54999, 279)  (rows: 54999, features: 279)\n",
      "- Label vector:   y.shape = (54999,)\n",
      "- Group vector:   group.shape = (54999,)\n",
      "- Time norm:      t.shape = (54999,)\n",
      "- Label distribution: {0: 27552, 1: 27447}\n",
      "- Feature types: Cat. = 16, Num. = 263\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# attention만 대상\n",
    "X, y, group, t, _ = load(os.path.join(PATH_INTERMEDIATE, 'attention.pkl'))\n",
    "\n",
    "print(f'# attention')\n",
    "# categorical feature은 시간 기반 정보에서 생성. ESM 응답 이력 + 시간대\n",
    "print(f'- Feature space: {len(X.dtypes)}; Cat.: {np.sum(X.dtypes == bool)}; Num.: {np.sum(X.dtypes != bool)}')\n",
    "print(f'- Label distribution: {np.unique(y, return_counts=True)}')\n",
    "\n",
    "print(\"# attention feature extraction summary\")\n",
    "print(f\"- Feature matrix: X.shape = {X.shape}  (rows: {X.shape[0]}, features: {X.shape[1]})\")\n",
    "print(f\"- Label vector:   y.shape = {y.shape}\")\n",
    "print(f\"- Group vector:   group.shape = {group.shape}\")\n",
    "print(f\"- Time norm:      t.shape = {t.shape}\")\n",
    "\n",
    "print(f\"- Label distribution: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "print(f\"- Feature types: Cat. = {np.sum(X.dtypes == bool)}, Num. = {np.sum(X.dtypes != bool)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether the number of features is same as intented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_TIM: 16\n",
      "N_VAL_NUM: 4\n",
      "N_WIN_NUM: 256\n",
      "N_LBL: 3\n",
      "N_FEAT: 279\n"
     ]
    }
   ],
   "source": [
    "N_NUM, N_CAT_B, N_CAT_NB = 0, 0, 0 \n",
    "\n",
    "for k, v in DATA.items():\n",
    "    N_NUM = N_NUM + 1\n",
    "\n",
    "# Features relavant to delivery time\n",
    "N_TIM = 7 + 2 + 7\n",
    "print(f'N_TIM: {N_TIM}')\n",
    "        \n",
    "# Features relevant to latest value\n",
    "N_VAL_NUM = N_NUM\n",
    "print(f'N_VAL_NUM: {N_VAL_NUM}')\n",
    "\n",
    "# Features from time-windows\n",
    "N_WIN_NUM = N_NUM * 8 * len(WINDOW_DATA)\n",
    "\n",
    "print(f'N_WIN_NUM: {N_WIN_NUM}')\n",
    "\n",
    "\n",
    "# Features from previous labels\n",
    "N_LBL = len(WINDOW_LABEL) * (1 if len(LABEL_VALUES) <= 2 else len(LABEL_VALUES))\n",
    "print(f'N_LBL: {N_LBL}')\n",
    "\n",
    "N_FEAT = N_TIM + N_WIN_NUM + N_VAL_NUM + N_LBL\n",
    "print(f'N_FEAT: {N_FEAT}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, features are extracted as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback as tb\n",
    "from contextlib import contextmanager\n",
    "from typing import Tuple, Dict, Union, Generator, List\n",
    "from dataclasses import dataclass\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#stratifiedgroupkfold 추가\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneGroupOut, StratifiedShuffleSplit, RepeatedStratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "import time\n",
    "import ray\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FoldResult:\n",
    "    name: str\n",
    "    estimator: BaseEstimator\n",
    "    X_train: pd.DataFrame\n",
    "    y_train: np.ndarray\n",
    "    X_test: pd.DataFrame\n",
    "    y_test: np.ndarray\n",
    "    categories: Dict[str, Dict[int, str]] = None\n",
    "\n",
    "\n",
    "# logo의 단점: 참가자별 attention label의 불균형을 해결하기 위한 stratification 불가\n",
    "# StratifiedKFold 혹은 StratifiedGroupKFold 필요\n",
    "# StratifiedKFold는 한 pcode의 데이터가 train-test 모두에 포함이 가능 -> StratifiedGroupKFold\n",
    "def _split(\n",
    "        alg: str,\n",
    "        X: Union[pd.DataFrame, np.ndarray] = None,\n",
    "        y: np.ndarray = None,\n",
    "        groups: np.ndarray = None,\n",
    "        random_state: int = None,\n",
    "        n_splits: int = None,\n",
    "        n_repeats: int = None,\n",
    "        test_ratio: float = None\n",
    ") -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n",
    "    if alg == 'holdout':\n",
    "        splitter = StratifiedShuffleSplit(\n",
    "            n_splits=n_splits,\n",
    "            test_size=test_ratio,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif alg == 'kfold':\n",
    "        if n_repeats and n_repeats > 1:\n",
    "            splitter = RepeatedStratifiedKFold(\n",
    "                n_splits=n_splits,\n",
    "                n_repeats=n_repeats,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "        else:\n",
    "            splitter = StratifiedKFold(\n",
    "                n_splits=n_splits,\n",
    "                random_state=random_state,\n",
    "                shuffle=False if random_state is None else True,\n",
    "            )\n",
    "    elif alg == 'stratifiedgroupkfold':\n",
    "        if n_repeats and n_repeats > 1:\n",
    "            splitter = StratifiedGroupKFold(\n",
    "                n_splits=n_splits,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "        else:\n",
    "            splitter = StratifiedGroupKFold(\n",
    "                n_splits=n_splits,\n",
    "                random_state=random_state,\n",
    "                shuffle=False if random_state is None else True,\n",
    "            )\n",
    "    elif alg == 'logo':\n",
    "        splitter = LeaveOneGroupOut()\n",
    "    else:\n",
    "        raise ValueError('\"alg\" should be one of \"holdout\", \"kfold\", \"logo\", or \"groupk\".')\n",
    "\n",
    "    split = splitter.split(X, y, groups)\n",
    "\n",
    "    for I_train, I_test in split:\n",
    "        yield I_train, I_test\n",
    "\n",
    "\n",
    "def _train(\n",
    "    dir_result: str,\n",
    "    name: str,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: np.ndarray,\n",
    "    C_cat: np.ndarray,\n",
    "    C_num: np.ndarray,\n",
    "    estimator: BaseEstimator,\n",
    "    normalize: bool = False,\n",
    "    select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "    oversample: bool = False,\n",
    "    random_state: int = None,\n",
    "    categories: Union[List, Dict[str, Dict[int, str]]] = None\n",
    "):\n",
    "    @contextmanager\n",
    "    def _log(task_type: str):\n",
    "        log(f'In progress: {task_type}.')\n",
    "        _t = time.time()\n",
    "        _err = None\n",
    "        _result = dict()\n",
    "        \n",
    "        try:\n",
    "            yield _result\n",
    "        except:\n",
    "            _err = tb.format_exc()\n",
    "        finally:\n",
    "            _e = time.time() - _t\n",
    "            if _err:\n",
    "                _msg = f'Failure: {task_type} ({_e:.2f}s). Keep running without this task. Caused by: \\n{_err}' \n",
    "            else:\n",
    "                _msg = f'Success: {task_type} ({_e:.2f}s).' \n",
    "                if _result:\n",
    "                    _r = '\\n'.join([f'- {k}: {v}' for k, v in _result.items()])\n",
    "                    _msg = f'{_msg}\\n{_r}'\n",
    "            log(_msg)\n",
    "    \n",
    "    if normalize:\n",
    "        with _log(f'[{name}] Normalizing numeric features'):\n",
    "            X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "            X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "            \n",
    "            scaler = StandardScaler().fit(X_train_N)\n",
    "            X_train_N = scaler.transform(X_train_N)\n",
    "            X_test_N = scaler.transform(X_test_N)\n",
    "         \n",
    "            X_train = pd.DataFrame(\n",
    "                np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            X_test = pd.DataFrame(\n",
    "                np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "           \n",
    "    if select:\n",
    "        if isinstance(select, SelectFromModel):\n",
    "            select = [select]\n",
    "            \n",
    "        for i, s in enumerate(select):\n",
    "            with _log(f'[{name}] {i+1}-th Feature selection') as r:\n",
    "                C = np.asarray(X_train.columns)\n",
    "                r['# Orig. Feat.'] = f'{len(C)} (# Cat. = {len(C_cat)}; # Num. = {len(C_num)})'\n",
    "                M = s.fit(X=X_train.values, y=y_train).get_support()\n",
    "                C_sel = C[M]\n",
    "                C_cat = C_cat[np.isin(C_cat, C_sel)]\n",
    "                C_num = C_num[np.isin(C_num, C_sel)]\n",
    "                \n",
    "                X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "                X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                r['# Sel. Feat.'] = f'{len(C_sel)} (# Cat. = {len(C_cat)}; # Num. = {len(C_num)})'\n",
    "\n",
    "    if oversample:\n",
    "        with _log('Oversampling'):\n",
    "            if len(C_cat):\n",
    "                cat_mask = np.isin(X_train.columns, C_cat)\n",
    "                cat_indices = np.where(cat_mask)[0]  # <- 인덱스 리스트로 변환\n",
    "                sampler = SMOTENC(categorical_features=cat_indices.tolist(), random_state=random_state)\n",
    "            else:\n",
    "                sampler = SMOTE(random_state=random_state)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    with _log(f'[{name}] Training'):\n",
    "        estimator = estimator.fit(X_train, y_train)\n",
    "        result = FoldResult(\n",
    "            name=name,\n",
    "            estimator=estimator,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            categories=categories\n",
    "        )\n",
    "        dump(result, os.path.join(dir_result, f'{name}.pkl'))\n",
    "    \n",
    "\n",
    "# def cross_val(\n",
    "#     X: pd.DataFrame,\n",
    "#     y: np.ndarray,\n",
    "#     groups: np.ndarray,\n",
    "#     path: str,\n",
    "#     name: str,\n",
    "#     estimator: BaseEstimator,\n",
    "#     categories: List[str] = None,\n",
    "#     normalize: bool = False,\n",
    "#     split: str = None,\n",
    "#     split_params: Dict[str, any] = None,\n",
    "#     select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "#     oversample: bool = False,\n",
    "#     random_state: int = None\n",
    "# ):\n",
    "\n",
    "#StratifiedKFold\n",
    "def cross_val(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    groups: np.ndarray,\n",
    "    path: str,\n",
    "    name: str,\n",
    "    estimator: BaseEstimator,\n",
    "    categories: List[str] = None,\n",
    "    normalize: bool = False,\n",
    "    split: str = None,\n",
    "    split_params: Dict[str, any] = None,\n",
    "    select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "    oversample: bool = False,\n",
    "    random_state: int = None\n",
    "):\n",
    "    if not os.path.exists(path):\n",
    "        raise ValueError('\"path\" does not exist.')\n",
    "    \n",
    "    if not split:\n",
    "        raise ValueError('\"split\" should be specified.')\n",
    "    \n",
    "    if not ray.is_initialized():\n",
    "        raise EnvironmentError('\"ray\" should be initialized.')\n",
    "    \n",
    "    jobs = []\n",
    "    func = ray.remote(_train).remote\n",
    "\n",
    "    categories = list() if categories is None else categories\n",
    "    C_cat = np.asarray(sorted(categories))\n",
    "    C_num = np.asarray(sorted(X.columns[~X.columns.isin(C_cat)]))\n",
    "\n",
    "    split_params = split_params or dict()\n",
    "    splitter = _split(alg=split, X=X, y=y, groups=groups, random_state=random_state, **split_params)\n",
    "\n",
    "    for idx_fold, (I_train, I_test) in enumerate(splitter):\n",
    "        if split == 'logo':\n",
    "            FOLD_NAME = str(np.unique(groups[I_test]).item(0))\n",
    "        else:\n",
    "            FOLD_NAME = f\"fold{idx_fold + 1}\"\n",
    "\n",
    "        X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "        X_test, y_test = X.iloc[I_test, :], y[I_test]\n",
    "\n",
    "        job = func(\n",
    "            dir_result=path,\n",
    "            name=f'{name}#{FOLD_NAME}',\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            C_cat=C_cat,\n",
    "            C_num=C_num,\n",
    "            categories=categories,\n",
    "            estimator=clone(estimator),\n",
    "            normalize=normalize,\n",
    "            select=select,\n",
    "            oversample=oversample,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        jobs.append(job)\n",
    "    ray.get(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor Modification on XGBClassifer\n",
    "This modification allows XGBClassifiers to automatically generate evaluation sets during pipeline (without passing any argument in \"fit\" function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) xgboost 공홈 주소 \n",
    "- https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier\n",
    "- https://xgboost.readthedocs.io/en/release_2.0.0/parameter.html\n",
    "\n",
    "### 참고) RF 공홈 주소 \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "<br> parameter 수정 시 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: xgboost\n",
      "Version: 2.1.4\n",
      "Summary: XGBoost Python Package\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Hyunsu Cho <chohyu01@cs.washington.edu>, Jiaming Yuan <jm.yuan@outlook.com>\n",
      "License: Apache-2.0\n",
      "Location: /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages\n",
      "Requires: numpy, scipy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class EvXGBClassifier(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_size=None,\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=10,\n",
    "        random_state=None,\n",
    "        **kwargs\n",
    "        ):\n",
    "        self.random_state = random_state\n",
    "        self.eval_size = eval_size\n",
    "        self.eval_metric = eval_metric\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.model = XGBClassifier(\n",
    "            random_state=self.random_state,\n",
    "            eval_metric=self.eval_metric,\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.model.classes_\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return self.model.feature_importances_\n",
    "    \n",
    "    @property\n",
    "    def feature_names_in_(self):\n",
    "        return self.model.feature_names_in_\n",
    "\n",
    "    def fit(self, X: Union[pd.DataFrame, np.ndarray], y: np.ndarray):\n",
    "        if self.eval_size:\n",
    "            splitter = StratifiedShuffleSplit(random_state=self.random_state, test_size=self.eval_size)\n",
    "            I_train, I_eval = next(splitter.split(X, y))\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X.iloc[I_eval, :], y[I_eval]\n",
    "            else:\n",
    "                X_train, y_train = X[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X[I_eval, :], y[I_eval]\n",
    "                \n",
    "            self.model = self.model.fit(\n",
    "                X=X_train, y=y_train, \n",
    "                eval_set=[(X_eval, y_eval)],\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            self.model = self.model.fit(X=X, y=y, verbose=False)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, our feature data has a big-$p$, little-$N$ problem: # sample = 2,619 while # features = 3,356.\n",
    "Therefore, we need to choose important features only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 22:22:55,598\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P01' 'P01' 'P01' ... 'P80' 'P80' 'P80']\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:22:58] Success: [logreg#fold2] Normalizing numeric features (0.21s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:22:58] Success: [logreg#fold4] Normalizing numeric features (0.21s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:22:58] Success: [logreg#fold3] Normalizing numeric features (0.22s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:22:58] Success: [logreg#fold1] Normalizing numeric features (0.22s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:22:58] In progress: [logreg#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:22:59] Success: [logreg#fold5] Normalizing numeric features (0.62s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:22:59] In progress: [logreg#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:13] Success: [logreg#fold1] Training (14.67s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:16] Success: [logreg#fold2] Training (17.59s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:19] Success: [logreg#fold5] Training (19.70s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:21] Success: [logreg#fold3] Training (22.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:34] Success: [logreg#fold4] Training (35.03s).\n",
      "['P01' 'P01' 'P01' ... 'P80' 'P80' 'P80']\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:34] In progress: [rf_ns#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:34] Success: [rf_ns#fold1] Normalizing numeric features (0.20s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:34] In progress: [rf_ns#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:34] In progress: [rf_ns#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:34] In progress: [rf_ns#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:34] Success: [rf_ns#fold2] Normalizing numeric features (0.20s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:34] In progress: [rf_ns#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:34] In progress: [rf_ns#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:35] Success: [rf_ns#fold3] Normalizing numeric features (0.24s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:35] In progress: [rf_ns#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:35] In progress: [rf_ns#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:35] Success: [rf_ns#fold4] Normalizing numeric features (0.29s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:35] In progress: [rf_ns#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:35] Success: [rf_ns#fold5] Normalizing numeric features (0.37s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:35] In progress: [rf_ns#fold5] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:39] Success: [rf_ns#fold1] 1-th Feature selection (4.76s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m - # Sel. Feat.: 185 (# Cat. = 13; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:39] In progress: [rf_ns#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:39] Success: [rf_ns#fold2] 1-th Feature selection (4.68s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 10; # Num. = 177)\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:39] In progress: [rf_ns#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:39] Success: [rf_ns#fold3] 1-th Feature selection (4.68s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 11; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:39] In progress: [rf_ns#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:39] Success: [rf_ns#fold4] 1-th Feature selection (4.56s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 11; # Num. = 165)\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:39] In progress: [rf_ns#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:40] Success: [rf_ns#fold5] 1-th Feature selection (4.54s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m - # Sel. Feat.: 189 (# Cat. = 9; # Num. = 180)\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:40] In progress: [rf_ns#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:55] Success: [rf_ns#fold1] Training (15.98s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:55] Success: [rf_ns#fold2] Training (16.37s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:56] Success: [rf_ns#fold3] Training (16.28s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:56] Success: [rf_ns#fold4] Training (16.79s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:57] Success: [rf_ns#fold5] Training (17.03s).\n",
      "['P01' 'P01' 'P01' ... 'P80' 'P80' 'P80']\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:57] In progress: [rf_os#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:57] In progress: [rf_os#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:57] Success: [rf_os#fold1] Normalizing numeric features (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:23:57] In progress: [rf_os#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:57] In progress: [rf_os#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:57] Success: [rf_os#fold2] Normalizing numeric features (0.24s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:23:57] In progress: [rf_os#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:57] In progress: [rf_os#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:58] In progress: [rf_os#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:57] Success: [rf_os#fold3] Normalizing numeric features (0.20s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:23:57] In progress: [rf_os#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:58] Success: [rf_os#fold4] Normalizing numeric features (0.37s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:23:58] In progress: [rf_os#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:58] Success: [rf_os#fold5] Normalizing numeric features (0.63s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:23:58] In progress: [rf_os#fold5] 1-th Feature selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:24:02] Success: [rf_os#fold1] 1-th Feature selection (4.94s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m - # Sel. Feat.: 185 (# Cat. = 13; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:24:02] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:24:02] Success: [rf_os#fold2] 1-th Feature selection (5.10s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 10; # Num. = 177)\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:24:02] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:24:03] Success: [rf_os#fold4] 1-th Feature selection (4.93s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 11; # Num. = 165)\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:24:03] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:24:03] Success: [rf_os#fold5] 1-th Feature selection (4.81s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m - # Sel. Feat.: 189 (# Cat. = 9; # Num. = 180)\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:24:03] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:24:03] Success: [rf_os#fold3] 1-th Feature selection (5.49s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 11; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:24:03] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:25:27] Success: Oversampling (84.59s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:25:27] In progress: [rf_os#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:25:29] Success: Oversampling (86.70s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:25:29] In progress: [rf_os#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:25:31] Success: Oversampling (88.85s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:25:31] In progress: [rf_os#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:25:31] Success: Oversampling (88.46s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:25:31] In progress: [rf_os#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:25:38] Success: Oversampling (94.86s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:25:38] In progress: [rf_os#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:25:45] Success: [rf_os#fold4] Training (17.60s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:25:46] Success: [rf_os#fold2] Training (17.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:25:47] Success: [rf_os#fold1] Training (16.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:25:48] Success: [rf_os#fold3] Training (16.33s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:25:55] Success: [rf_os#fold5] Training (16.72s).\n",
      "['P01' 'P01' 'P01' ... 'P80' 'P80' 'P80']\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:25:55] In progress: [xgb_ns#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:25:55] Success: [xgb_ns#fold1] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:25:55] In progress: [xgb_ns#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:25:55] In progress: [xgb_ns#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:25:55] In progress: [xgb_ns#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:25:55] Success: [xgb_ns#fold2] Normalizing numeric features (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:25:55] In progress: [xgb_ns#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:25:55] In progress: [xgb_ns#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:25:55] Success: [xgb_ns#fold3] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:25:55] In progress: [xgb_ns#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:25:56] Success: [xgb_ns#fold4] Normalizing numeric features (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:25:56] In progress: [xgb_ns#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:25:55] In progress: [xgb_ns#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:25:56] Success: [xgb_ns#fold5] Normalizing numeric features (0.20s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:25:56] In progress: [xgb_ns#fold5] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:26:00] Success: [xgb_ns#fold1] 1-th Feature selection (4.62s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m - # Sel. Feat.: 185 (# Cat. = 13; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:26:00] In progress: [xgb_ns#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:26:00] Success: [xgb_ns#fold4] 1-th Feature selection (4.43s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 11; # Num. = 165)\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:26:00] In progress: [xgb_ns#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:26:00] Success: [xgb_ns#fold3] 1-th Feature selection (4.52s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 11; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:26:00] In progress: [xgb_ns#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:26:00] Success: [xgb_ns#fold2] 1-th Feature selection (4.71s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 10; # Num. = 177)\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:26:00] In progress: [xgb_ns#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:26:00] Success: [xgb_ns#fold5] 1-th Feature selection (4.56s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m - # Sel. Feat.: 189 (# Cat. = 9; # Num. = 180)\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:26:00] In progress: [xgb_ns#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:26:05] Success: [xgb_ns#fold4] Training (4.60s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:26:05] Success: [xgb_ns#fold1] Training (4.81s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:26:05] Success: [xgb_ns#fold3] Training (4.62s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:26:05] Success: [xgb_ns#fold2] Training (4.82s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:26:05] Success: [xgb_ns#fold5] Training (4.98s).\n",
      "['P01' 'P01' 'P01' ... 'P80' 'P80' 'P80']\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:26:06] Success: [xgb_os#fold1] Normalizing numeric features (0.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:26:06] Success: [xgb_os#fold2] Normalizing numeric features (0.13s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:26:06] Success: [xgb_os#fold3] Normalizing numeric features (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:26:06] Success: [xgb_os#fold4] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:26:06] Success: [xgb_os#fold5] Normalizing numeric features (0.24s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:26:06] In progress: [xgb_os#fold5] 1-th Feature selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:26:11] Success: [xgb_os#fold1] 1-th Feature selection (4.97s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m - # Sel. Feat.: 185 (# Cat. = 13; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:26:11] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:26:11] Success: [xgb_os#fold2] 1-th Feature selection (4.88s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 10; # Num. = 177)\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:26:11] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:26:11] Success: [xgb_os#fold3] 1-th Feature selection (4.91s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 11; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:26:11] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:26:11] Success: [xgb_os#fold4] 1-th Feature selection (4.73s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 11; # Num. = 165)\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:26:11] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:26:11] Success: [xgb_os#fold5] 1-th Feature selection (5.09s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m - # Sel. Feat.: 189 (# Cat. = 9; # Num. = 180)\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:26:11] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:27:36] Success: Oversampling (84.74s).\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:27:36] In progress: [xgb_os#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:27:38] Success: Oversampling (87.25s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:27:38] In progress: [xgb_os#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:27:39] Success: Oversampling (88.73s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:27:39] In progress: [xgb_os#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:27:40] Success: Oversampling (89.10s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:27:40] In progress: [xgb_os#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=43534)\u001b[0m [25-06-01 22:27:41] Success: [xgb_os#fold4] Training (5.79s).\n",
      "\u001b[2m\u001b[36m(_train pid=43535)\u001b[0m [25-06-01 22:27:44] Success: [xgb_os#fold2] Training (5.62s).\n",
      "\u001b[2m\u001b[36m(_train pid=43527)\u001b[0m [25-06-01 22:27:45] Success: [xgb_os#fold1] Training (5.38s).\n",
      "\u001b[2m\u001b[36m(_train pid=43529)\u001b[0m [25-06-01 22:27:45] Success: [xgb_os#fold3] Training (5.10s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:27:47] Success: Oversampling (95.31s).\n",
      "\u001b[2m\u001b[36m(_train pid=43532)\u001b[0m [25-06-01 22:27:47] In progress: [xgb_os#fold5] Training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# from eli5.sklearn.permutation_importance import PermutationImportance\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "ESTIMATOR_LOGREG = LogisticRegression(\n",
    "    penalty='l1', solver='liblinear', random_state=RANDOM_STATE\n",
    ")\n",
    "ESTIMATOR_RF = RandomForestClassifier(random_state=RANDOM_STATE, max_depth=5)\n",
    "ESTIMATOR_XGB = EvXGBClassifier(\n",
    "    random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss', \n",
    "    eval_size=0.2,\n",
    "    early_stopping_rounds=10, \n",
    "    objective='binary:logistic', \n",
    "    verbosity=0,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "SELECT_SVC = SelectFromModel(\n",
    "    estimator=LinearSVC(\n",
    "        penalty='l1',\n",
    "        loss='squared_hinge',\n",
    "        dual=False,\n",
    "        tol=1e-3,\n",
    "        C=1e-2,\n",
    "        max_iter=5000,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    threshold=1e-5\n",
    ")\n",
    "\n",
    "CLS = ['attention']\n",
    "SETTINGS = [\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_LOGREG),  # 여기서 logistic으로 대체\n",
    "        oversample=False,\n",
    "        select=None,\n",
    "        name='logreg'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_ns'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=True,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_os'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_ns'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=True,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_os'\n",
    "    )\n",
    "]\n",
    "\n",
    "with on_ray(num_cpus=12):\n",
    "    for l, s in product(\n",
    "        CLS, SETTINGS\n",
    "    ):\n",
    "        p = os.path.join(PATH_INTERMEDIATE, f'{l}.pkl')\n",
    "        par_dir = os.path.join(PATH_INTERMEDIATE, 'eval', l)\n",
    "        os.makedirs(par_dir, exist_ok=True)\n",
    "        \n",
    "        X, y, groups, t, datetimes = load(p)\n",
    "        print(groups)\n",
    "        cats = X.columns[X.dtypes == bool]\n",
    "        cross_val(\n",
    "            X=X, y=y, groups=groups,\n",
    "            path=par_dir,\n",
    "            categories=cats,\n",
    "            normalize=True,\n",
    "            split='stratifiedgroupkfold',\n",
    "            split_params={'n_splits': 5}, # logo시 삭제\n",
    "            random_state=RANDOM_STATE,\n",
    "            **s\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 22:27:56,781\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:28:00] Success: [logreg#fold2] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:28:00] Success: [logreg#fold3] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:28:00] Success: [logreg#fold1] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:28:00] Success: [logreg#fold4] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:28:00] Success: [logreg#fold5] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:28:00] In progress: [logreg#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:28:14] Success: [logreg#fold1] Training (13.82s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:28:16] Success: [logreg#fold2] Training (16.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:28:19] Success: [logreg#fold5] Training (18.96s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:28:21] Success: [logreg#fold3] Training (20.89s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:28:35] Success: [logreg#fold4] Training (34.71s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:877: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:28:35] In progress: [logreg_kfold#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:28:35] In progress: [logreg_kfold#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:28:35] Success: [logreg_kfold#fold1] Normalizing numeric features (0.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:28:35] In progress: [logreg_kfold#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:28:35] Success: [logreg_kfold#fold2] Normalizing numeric features (0.13s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:28:35] In progress: [logreg_kfold#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:28:35] In progress: [logreg_kfold#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:28:35] In progress: [logreg_kfold#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:28:35] Success: [logreg_kfold#fold3] Normalizing numeric features (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:28:35] In progress: [logreg_kfold#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:28:36] Success: [logreg_kfold#fold4] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:28:36] In progress: [logreg_kfold#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:28:36] In progress: [logreg_kfold#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:28:36] Success: [logreg_kfold#fold5] Normalizing numeric features (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:28:36] In progress: [logreg_kfold#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:28:51] Success: [logreg_kfold#fold1] Training (15.91s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:28:51] Success: [logreg_kfold#fold2] Training (15.90s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:28:52] Success: [logreg_kfold#fold5] Training (16.50s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:28:55] Success: [logreg_kfold#fold3] Training (19.93s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:02] Success: [logreg_kfold#fold4] Training (26.36s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:02] In progress: [rf_ns#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:02] Success: [rf_ns#fold1] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:03] In progress: [rf_ns#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:02] In progress: [rf_ns#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:03] In progress: [rf_ns#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:03] Success: [rf_ns#fold2] Normalizing numeric features (0.13s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:03] In progress: [rf_ns#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:03] In progress: [rf_ns#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:03] Success: [rf_ns#fold3] Normalizing numeric features (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:03] In progress: [rf_ns#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:03] In progress: [rf_ns#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:03] Success: [rf_ns#fold4] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:03] In progress: [rf_ns#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:03] Success: [rf_ns#fold5] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:03] In progress: [rf_ns#fold5] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:07] Success: [rf_ns#fold1] 1-th Feature selection (4.50s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Sel. Feat.: 185 (# Cat. = 13; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:07] In progress: [rf_ns#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:07] Success: [rf_ns#fold2] 1-th Feature selection (4.46s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 10; # Num. = 177)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:07] In progress: [rf_ns#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:07] Success: [rf_ns#fold4] 1-th Feature selection (4.38s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 11; # Num. = 165)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:07] In progress: [rf_ns#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:07] Success: [rf_ns#fold3] 1-th Feature selection (4.56s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 11; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:07] In progress: [rf_ns#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:08] Success: [rf_ns#fold5] 1-th Feature selection (4.50s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Sel. Feat.: 189 (# Cat. = 9; # Num. = 180)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:08] In progress: [rf_ns#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:23] Success: [rf_ns#fold1] Training (16.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:23] Success: [rf_ns#fold2] Training (16.40s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:24] Success: [rf_ns#fold3] Training (16.27s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:24] Success: [rf_ns#fold4] Training (16.66s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:24] Success: [rf_ns#fold5] Training (16.91s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:877: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:25] Success: [rf_ns_kfold#fold1] Normalizing numeric features (0.11s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:25] Success: [rf_ns_kfold#fold2] Normalizing numeric features (0.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:25] Success: [rf_ns_kfold#fold3] Normalizing numeric features (0.10s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:25] Success: [rf_ns_kfold#fold4] Normalizing numeric features (0.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:25] In progress: [rf_ns_kfold#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:26] Success: [rf_ns_kfold#fold5] Normalizing numeric features (0.23s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:26] In progress: [rf_ns_kfold#fold5] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:29] Success: [rf_ns_kfold#fold3] 1-th Feature selection (4.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Sel. Feat.: 181 (# Cat. = 11; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:29] In progress: [rf_ns_kfold#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:29] Success: [rf_ns_kfold#fold4] 1-th Feature selection (4.31s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Sel. Feat.: 182 (# Cat. = 13; # Num. = 169)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:29] In progress: [rf_ns_kfold#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:30] Success: [rf_ns_kfold#fold1] 1-th Feature selection (4.78s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Sel. Feat.: 184 (# Cat. = 10; # Num. = 174)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:30] In progress: [rf_ns_kfold#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:30] Success: [rf_ns_kfold#fold2] 1-th Feature selection (5.54s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Sel. Feat.: 180 (# Cat. = 10; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:30] In progress: [rf_ns_kfold#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:31] Success: [rf_ns_kfold#fold5] 1-th Feature selection (5.09s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Sel. Feat.: 184 (# Cat. = 12; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:31] In progress: [rf_ns_kfold#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:45] Success: [rf_ns_kfold#fold4] Training (15.90s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:46] Success: [rf_ns_kfold#fold3] Training (16.42s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:46] Success: [rf_ns_kfold#fold1] Training (16.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:47] Success: [rf_ns_kfold#fold2] Training (16.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:47] Success: [rf_ns_kfold#fold5] Training (16.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:47] In progress: [rf_os#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:47] Success: [rf_os#fold1] Normalizing numeric features (0.11s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:47] In progress: [rf_os#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:47] In progress: [rf_os#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:47] Success: [rf_os#fold2] Normalizing numeric features (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:47] In progress: [rf_os#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:47] In progress: [rf_os#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:48] Success: [rf_os#fold3] Normalizing numeric features (0.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:48] In progress: [rf_os#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:48] In progress: [rf_os#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:48] Success: [rf_os#fold4] Normalizing numeric features (0.13s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:48] In progress: [rf_os#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:48] In progress: [rf_os#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:48] Success: [rf_os#fold5] Normalizing numeric features (0.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:48] In progress: [rf_os#fold5] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:52] Success: [rf_os#fold1] 1-th Feature selection (4.58s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Sel. Feat.: 185 (# Cat. = 13; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:29:52] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:52] Success: [rf_os#fold2] 1-th Feature selection (4.48s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 10; # Num. = 177)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:29:52] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:52] Success: [rf_os#fold3] 1-th Feature selection (4.58s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 11; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:29:52] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:52] Success: [rf_os#fold4] 1-th Feature selection (4.52s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 11; # Num. = 165)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:29:52] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:52] Success: [rf_os#fold5] 1-th Feature selection (4.49s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Sel. Feat.: 189 (# Cat. = 9; # Num. = 180)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:29:52] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:31:15] Success: Oversampling (82.71s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:31:15] In progress: [rf_os#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:31:16] Success: Oversampling (84.58s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:31:16] In progress: [rf_os#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:31:19] Success: Oversampling (86.88s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:31:19] In progress: [rf_os#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:31:19] Success: Oversampling (86.69s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:31:19] In progress: [rf_os#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:31:26] Success: Oversampling (93.57s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:31:26] In progress: [rf_os#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:31:34] Success: [rf_os#fold4] Training (18.65s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:31:34] Success: [rf_os#fold2] Training (17.75s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:31:36] Success: [rf_os#fold1] Training (16.79s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:31:36] Success: [rf_os#fold3] Training (17.07s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:31:43] Success: [rf_os#fold5] Training (17.51s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:877: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:31:44] Success: [rf_os_kfold#fold1] Normalizing numeric features (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:31:44] Success: [rf_os_kfold#fold2] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:31:44] Success: [rf_os_kfold#fold3] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:31:44] Success: [rf_os_kfold#fold4] Normalizing numeric features (0.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:31:44] In progress: [rf_os_kfold#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:31:45] Success: [rf_os_kfold#fold5] Normalizing numeric features (0.38s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:31:45] In progress: [rf_os_kfold#fold5] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:31:49] Success: [rf_os_kfold#fold3] 1-th Feature selection (4.42s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Sel. Feat.: 181 (# Cat. = 11; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:31:49] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:31:49] Success: [rf_os_kfold#fold4] 1-th Feature selection (4.67s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Sel. Feat.: 182 (# Cat. = 13; # Num. = 169)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:31:49] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:31:49] Success: [rf_os_kfold#fold1] 1-th Feature selection (5.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Sel. Feat.: 184 (# Cat. = 10; # Num. = 174)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:31:49] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:31:50] Success: [rf_os_kfold#fold5] 1-th Feature selection (5.48s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Sel. Feat.: 184 (# Cat. = 12; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:31:50] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:31:50] Success: [rf_os_kfold#fold2] 1-th Feature selection (6.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Sel. Feat.: 180 (# Cat. = 10; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:31:50] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:20] Success: Oversampling (91.20s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:20] In progress: [rf_os_kfold#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:21] Success: Oversampling (90.79s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:21] In progress: [rf_os_kfold#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:21] Success: Oversampling (92.29s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:21] In progress: [rf_os_kfold#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:22] Success: Oversampling (92.73s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:22] In progress: [rf_os_kfold#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:23] Success: Oversampling (92.96s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:23] In progress: [rf_os_kfold#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:37] Success: [rf_os_kfold#fold3] Training (16.91s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:38] Success: [rf_os_kfold#fold4] Training (16.29s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:38] Success: [rf_os_kfold#fold2] Training (16.68s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:38] Success: [rf_os_kfold#fold1] Training (16.71s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:40] Success: [rf_os_kfold#fold5] Training (16.49s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:40] In progress: [xgb_ns#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:40] In progress: [xgb_ns#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:40] In progress: [xgb_ns#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:41] Success: [xgb_ns#fold1] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:41] In progress: [xgb_ns#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:41] In progress: [xgb_ns#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:41] In progress: [xgb_ns#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:41] Success: [xgb_ns#fold2] Normalizing numeric features (0.32s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:41] In progress: [xgb_ns#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:41] Success: [xgb_ns#fold3] Normalizing numeric features (0.36s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:41] In progress: [xgb_ns#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:41] Success: [xgb_ns#fold4] Normalizing numeric features (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:41] In progress: [xgb_ns#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:41] Success: [xgb_ns#fold5] Normalizing numeric features (0.34s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:41] In progress: [xgb_ns#fold5] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:46] Success: [xgb_ns#fold1] 1-th Feature selection (5.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Sel. Feat.: 185 (# Cat. = 13; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:46] In progress: [xgb_ns#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:46] Success: [xgb_ns#fold2] 1-th Feature selection (5.09s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 10; # Num. = 177)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:46] In progress: [xgb_ns#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:46] Success: [xgb_ns#fold4] 1-th Feature selection (4.94s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 11; # Num. = 165)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:46] In progress: [xgb_ns#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:46] Success: [xgb_ns#fold5] 1-th Feature selection (4.93s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Sel. Feat.: 189 (# Cat. = 9; # Num. = 180)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:46] In progress: [xgb_ns#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:46] Success: [xgb_ns#fold3] 1-th Feature selection (5.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 11; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:46] In progress: [xgb_ns#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:51] Success: [xgb_ns#fold4] Training (4.93s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:51] Success: [xgb_ns#fold1] Training (5.19s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:51] Success: [xgb_ns#fold2] Training (5.23s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:51] Success: [xgb_ns#fold3] Training (5.09s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:51] Success: [xgb_ns#fold5] Training (5.37s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:877: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:52] Success: [xgb_ns_kfold#fold1] Normalizing numeric features (0.13s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:52] Success: [xgb_ns_kfold#fold2] Normalizing numeric features (0.13s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:52] Success: [xgb_ns_kfold#fold3] Normalizing numeric features (0.13s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:52] Success: [xgb_ns_kfold#fold4] Normalizing numeric features (0.24s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:52] Success: [xgb_ns_kfold#fold5] Normalizing numeric features (0.35s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:52] In progress: [xgb_ns_kfold#fold5] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:57] Success: [xgb_ns_kfold#fold3] 1-th Feature selection (4.91s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Sel. Feat.: 181 (# Cat. = 11; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:33:57] In progress: [xgb_ns_kfold#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:57] Success: [xgb_ns_kfold#fold4] 1-th Feature selection (4.93s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Sel. Feat.: 182 (# Cat. = 13; # Num. = 169)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:33:57] In progress: [xgb_ns_kfold#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:57] Success: [xgb_ns_kfold#fold1] 1-th Feature selection (5.43s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Sel. Feat.: 184 (# Cat. = 10; # Num. = 174)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:33:57] In progress: [xgb_ns_kfold#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:58] Success: [xgb_ns_kfold#fold2] 1-th Feature selection (6.65s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Sel. Feat.: 180 (# Cat. = 10; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:33:58] In progress: [xgb_ns_kfold#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:59] Success: [xgb_ns_kfold#fold5] 1-th Feature selection (6.09s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Sel. Feat.: 184 (# Cat. = 12; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:33:59] In progress: [xgb_ns_kfold#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:34:02] Success: [xgb_ns_kfold#fold3] Training (5.34s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:34:02] Success: [xgb_ns_kfold#fold4] Training (5.22s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:34:02] Success: [xgb_ns_kfold#fold1] Training (5.30s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:34:03] Success: [xgb_ns_kfold#fold2] Training (4.88s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:34:03] Success: [xgb_ns_kfold#fold5] Training (4.98s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:34:04] In progress: [xgb_os#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:34:04] Success: [xgb_os#fold1] Normalizing numeric features (0.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:34:04] In progress: [xgb_os#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:34:04] In progress: [xgb_os#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:34:04] In progress: [xgb_os#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:34:04] Success: [xgb_os#fold2] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:34:04] In progress: [xgb_os#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:34:04] In progress: [xgb_os#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:34:04] Success: [xgb_os#fold3] Normalizing numeric features (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:34:04] In progress: [xgb_os#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:34:04] In progress: [xgb_os#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:34:05] Success: [xgb_os#fold4] Normalizing numeric features (0.37s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:34:05] In progress: [xgb_os#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:34:05] Success: [xgb_os#fold5] Normalizing numeric features (0.28s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:34:05] In progress: [xgb_os#fold5] 1-th Feature selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:34:09] Success: [xgb_os#fold1] 1-th Feature selection (5.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Sel. Feat.: 185 (# Cat. = 13; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:34:09] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:34:09] Success: [xgb_os#fold2] 1-th Feature selection (5.24s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 10; # Num. = 177)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:34:09] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:34:10] Success: [xgb_os#fold3] 1-th Feature selection (5.33s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 11; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:34:10] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:34:10] Success: [xgb_os#fold4] 1-th Feature selection (5.26s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 11; # Num. = 165)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:34:10] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:34:10] Success: [xgb_os#fold5] 1-th Feature selection (5.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Sel. Feat.: 189 (# Cat. = 9; # Num. = 180)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:34:10] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:35:38] Success: Oversampling (88.47s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:35:38] In progress: [xgb_os#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:35:40] Success: Oversampling (90.93s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:35:40] In progress: [xgb_os#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:35:42] Success: Oversampling (92.92s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:35:42] In progress: [xgb_os#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:35:43] Success: Oversampling (92.88s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:35:43] In progress: [xgb_os#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:35:44] Success: [xgb_os#fold4] Training (5.24s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:35:46] Success: [xgb_os#fold2] Training (5.36s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:35:47] Success: [xgb_os#fold1] Training (4.86s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:35:47] Success: [xgb_os#fold3] Training (4.86s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:35:49] Success: Oversampling (99.31s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:35:49] In progress: [xgb_os#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:35:54] Success: [xgb_os#fold5] Training (4.85s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:877: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:35:55] Success: [xgb_os_kfold#fold1] Normalizing numeric features (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:35:55] Success: [xgb_os_kfold#fold2] Normalizing numeric features (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold4] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:35:55] Success: [xgb_os_kfold#fold3] Normalizing numeric features (0.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold5] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:35:55] Success: [xgb_os_kfold#fold4] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold4] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:35:55] Success: [xgb_os_kfold#fold5] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:35:55] In progress: [xgb_os_kfold#fold5] 1-th Feature selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:35:59] Success: [xgb_os_kfold#fold3] 1-th Feature selection (4.04s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m - # Sel. Feat.: 181 (# Cat. = 11; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:35:59] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:35:59] Success: [xgb_os_kfold#fold1] 1-th Feature selection (4.63s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m - # Sel. Feat.: 184 (# Cat. = 10; # Num. = 174)\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:35:59] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:35:59] Success: [xgb_os_kfold#fold4] 1-th Feature selection (4.33s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m - # Sel. Feat.: 182 (# Cat. = 13; # Num. = 169)\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:35:59] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:36:00] Success: [xgb_os_kfold#fold2] 1-th Feature selection (5.59s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m - # Sel. Feat.: 180 (# Cat. = 10; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:36:00] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:36:01] Success: [xgb_os_kfold#fold5] 1-th Feature selection (5.24s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m - # Sel. Feat.: 184 (# Cat. = 12; # Num. = 172)\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:36:01] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:37:30] Success: Oversampling (90.81s).\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:37:30] In progress: [xgb_os_kfold#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:37:30] Success: Oversampling (89.76s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:37:30] In progress: [xgb_os_kfold#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:37:31] Success: Oversampling (91.58s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:37:31] In progress: [xgb_os_kfold#fold4] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:37:31] Success: Oversampling (91.63s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:37:31] In progress: [xgb_os_kfold#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:37:32] Success: Oversampling (91.94s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:37:32] In progress: [xgb_os_kfold#fold5] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=44997)\u001b[0m [25-06-01 22:37:35] Success: [xgb_os_kfold#fold3] Training (5.28s).\n",
      "\u001b[2m\u001b[36m(_train pid=44999)\u001b[0m [25-06-01 22:37:35] Success: [xgb_os_kfold#fold2] Training (5.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=44995)\u001b[0m [25-06-01 22:37:36] Success: [xgb_os_kfold#fold4] Training (5.21s).\n",
      "\u001b[2m\u001b[36m(_train pid=44994)\u001b[0m [25-06-01 22:37:36] Success: [xgb_os_kfold#fold1] Training (5.26s).\n",
      "\u001b[2m\u001b[36m(_train pid=44998)\u001b[0m [25-06-01 22:37:38] Success: [xgb_os_kfold#fold5] Training (5.21s).\n"
     ]
    }
   ],
   "source": [
    "# StratifiedGroupKFold + StratifiedKFold 비교용 실험 확장\n",
    "SETTINGS_EXTENDED = []\n",
    "for s in SETTINGS:\n",
    "    # StratifiedGroupKFold 설정\n",
    "    s_group = dict(s)\n",
    "    s_group['split'] = 'stratifiedgroupkfold'\n",
    "    s_group['name'] = s_group['name']\n",
    "    SETTINGS_EXTENDED.append(s_group)\n",
    "\n",
    "    # StratifiedKFold 설정\n",
    "    s_kfold = dict(s)\n",
    "    s_kfold['split'] = 'kfold'\n",
    "    s_kfold['name'] = s_kfold['name'] + '_kfold'\n",
    "    SETTINGS_EXTENDED.append(s_kfold)\n",
    "\n",
    "with on_ray(num_cpus=12):\n",
    "    for l, s in product(CLS, SETTINGS_EXTENDED):\n",
    "        p = os.path.join(PATH_INTERMEDIATE, f'{l}.pkl')\n",
    "        par_dir = os.path.join(PATH_INTERMEDIATE, 'eval', l)\n",
    "        os.makedirs(par_dir, exist_ok=True)\n",
    "\n",
    "        X, y, groups, t, datetimes = load(p)\n",
    "        cats = X.columns[X.dtypes == bool]\n",
    "\n",
    "        split_mode = s['split']\n",
    "        split_params = {'n_splits': 5}\n",
    "\n",
    "        # 중복 방지: s 딕셔너리에서 'split' 키 제거\n",
    "        s_clean = {k: v for k, v in s.items() if k != 'split'}\n",
    "\n",
    "        cross_val(\n",
    "            X=X, y=y, groups=groups,\n",
    "            path=par_dir,\n",
    "            categories=cats,\n",
    "            normalize=True,\n",
    "            split=split_mode,\n",
    "            split_params=split_params,\n",
    "            random_state=RANDOM_STATE,\n",
    "            **s_clean\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "  Train groups: ['P02' 'P05' 'P09' 'P10' 'P12' 'P13' 'P15' 'P19' 'P21' 'P23' 'P26' 'P31'\n",
      " 'P32' 'P33' 'P35' 'P39' 'P40' 'P42' 'P45' 'P47' 'P48' 'P50' 'P51' 'P52'\n",
      " 'P53' 'P55' 'P57' 'P60' 'P66' 'P67' 'P69' 'P70' 'P72' 'P75' 'P77' 'P78'\n",
      " 'P79' 'P80']\n",
      "  Test groups:  ['P01' 'P03' 'P06' 'P08' 'P28' 'P30' 'P49' 'P61' 'P76']\n",
      "OK: No overlap between train/test groups\n",
      "\n",
      "Fold 2\n",
      "  Train groups: ['P01' 'P02' 'P03' 'P06' 'P08' 'P13' 'P15' 'P19' 'P21' 'P23' 'P26' 'P28'\n",
      " 'P30' 'P31' 'P32' 'P33' 'P35' 'P39' 'P40' 'P42' 'P45' 'P47' 'P49' 'P50'\n",
      " 'P51' 'P52' 'P53' 'P55' 'P57' 'P61' 'P67' 'P70' 'P72' 'P76' 'P78' 'P79'\n",
      " 'P80']\n",
      "  Test groups:  ['P05' 'P09' 'P10' 'P12' 'P48' 'P60' 'P66' 'P69' 'P75' 'P77']\n",
      "OK: No overlap between train/test groups\n",
      "\n",
      "Fold 3\n",
      "  Train groups: ['P01' 'P03' 'P05' 'P06' 'P08' 'P09' 'P10' 'P12' 'P13' 'P15' 'P23' 'P28'\n",
      " 'P30' 'P31' 'P33' 'P40' 'P42' 'P45' 'P47' 'P48' 'P49' 'P50' 'P51' 'P52'\n",
      " 'P55' 'P57' 'P60' 'P61' 'P66' 'P69' 'P70' 'P72' 'P75' 'P76' 'P77' 'P78'\n",
      " 'P79' 'P80']\n",
      "  Test groups:  ['P02' 'P19' 'P21' 'P26' 'P32' 'P35' 'P39' 'P53' 'P67']\n",
      "OK: No overlap between train/test groups\n",
      "\n",
      "Fold 4\n",
      "  Train groups: ['P01' 'P02' 'P03' 'P05' 'P06' 'P08' 'P09' 'P10' 'P12' 'P19' 'P21' 'P26'\n",
      " 'P28' 'P30' 'P32' 'P33' 'P35' 'P39' 'P47' 'P48' 'P49' 'P51' 'P52' 'P53'\n",
      " 'P55' 'P60' 'P61' 'P66' 'P67' 'P69' 'P72' 'P75' 'P76' 'P77' 'P78' 'P79'\n",
      " 'P80']\n",
      "  Test groups:  ['P13' 'P15' 'P23' 'P31' 'P40' 'P42' 'P45' 'P50' 'P57' 'P70']\n",
      "OK: No overlap between train/test groups\n",
      "\n",
      "Fold 5\n",
      "  Train groups: ['P01' 'P02' 'P03' 'P05' 'P06' 'P08' 'P09' 'P10' 'P12' 'P13' 'P15' 'P19'\n",
      " 'P21' 'P23' 'P26' 'P28' 'P30' 'P31' 'P32' 'P35' 'P39' 'P40' 'P42' 'P45'\n",
      " 'P48' 'P49' 'P50' 'P53' 'P57' 'P60' 'P61' 'P66' 'P67' 'P69' 'P70' 'P75'\n",
      " 'P76' 'P77']\n",
      "  Test groups:  ['P33' 'P47' 'P51' 'P52' 'P55' 'P72' 'P78' 'P79' 'P80']\n",
      "OK: No overlap between train/test groups\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# StratifiedGroupKFold 잘 되었는지 확인\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(sgkf.split(X, y, groups=groups)):\n",
    "    train_groups = np.unique(groups[train_idx])\n",
    "    test_groups = np.unique(groups[test_idx])\n",
    "    intersection = np.intersect1d(train_groups, test_groups)\n",
    "    \n",
    "    print(f\"Fold {fold_idx + 1}\")\n",
    "    print(f\"  Train groups: {train_groups}\")\n",
    "    print(f\"  Test groups:  {test_groups}\")\n",
    "    \n",
    "    if len(intersection) == 0:\n",
    "        print(\"OK: No overlap between train/test groups\\n\")\n",
    "    else:\n",
    "        print(f\"Overlap found: {intersection}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "from itertools import product\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, \\\n",
    "    confusion_matrix, precision_recall_fscore_support, \\\n",
    "    roc_auc_score, matthews_corrcoef, average_precision_score, \\\n",
    "    log_loss, brier_score_loss\n",
    "import scipy.stats.mstats as ms\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    y_proba: np.ndarray,\n",
    "    classes: np.ndarray\n",
    ") -> Dict[str, any]:\n",
    "    R = {}\n",
    "    n_classes = len(classes)\n",
    "    is_multiclass = n_classes > 2\n",
    "    is_same_y = len(np.unique(y_true)) == 1\n",
    "    R['inst'] = len(y_true)\n",
    "    \n",
    "    for c in classes:\n",
    "        R[f'inst_{c}'] = np.sum(y_true == c)\n",
    "        \n",
    "    if not is_multiclass:\n",
    "        _, cnt = np.unique(y_true, return_counts=True)\n",
    "        \n",
    "        if len(cnt) > 1:\n",
    "            R['class_ratio'] = cnt[0] / cnt[1]\n",
    "        else:\n",
    "            R['class_ratio'] = np.nan\n",
    "\n",
    "    C = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=classes)\n",
    "    for (i1, c1), (i2, c2) in product(enumerate(classes), enumerate(classes)):\n",
    "        R[f'true_{c1}_pred_{c2}'] = C[i1, i2]\n",
    "\n",
    "    # Threshold Measure\n",
    "    R['acc'] = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['bac'] = balanced_accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
    "    R['mcc'] = matthews_corrcoef(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    if is_multiclass:\n",
    "        for avg in ('macro', 'micro'):\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true,\n",
    "                y_pred=y_pred,\n",
    "                labels=classes,\n",
    "                average=avg, \n",
    "                zero_division=0\n",
    "            )\n",
    "            R[f'pre_{avg}'] = pre\n",
    "            R[f'rec_{avg}'] = rec\n",
    "            R[f'f1_{avg}'] = f1\n",
    "    else:\n",
    "        pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true=y_true, y_pred=y_pred, pos_label=c, average='macro', zero_division=0\n",
    "        )\n",
    "        R[f'pre_macro'] = pre\n",
    "        R[f'rec_macro'] = rec\n",
    "        R[f'f1_macro'] = f1\n",
    "        \n",
    "        for c in classes:\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true, y_pred=y_pred, pos_label=c, average='binary', zero_division=0\n",
    "            )\n",
    "            R[f'pre_{c}'] = pre\n",
    "            R[f'rec_{c}'] = rec\n",
    "            R[f'f1_{c}'] = f1\n",
    "\n",
    "    # Ranking Measure\n",
    "    if is_multiclass:\n",
    "        for avg, mc in product(('macro', 'micro'), ('ovr', 'ovo')):\n",
    "            R[f'roauc_{avg}_{mc}'] = roc_auc_score(\n",
    "                y_true=y_true, y_score=y_proba,\n",
    "                average=avg, multi_class=mc, labels=classes\n",
    "            ) if not is_same_y else np.nan\n",
    "    else:\n",
    "        R[f'roauc'] = roc_auc_score(\n",
    "            y_true=y_true, y_score=y_proba[:, 1], average=None\n",
    "        ) if not is_same_y else np.nan\n",
    "        for i, c in enumerate(classes):\n",
    "            R[f'prauc_{c}'] = average_precision_score(\n",
    "                y_true=y_true, y_score=y_proba[:, i], pos_label=c, average=None\n",
    "            ) \n",
    "            R[f'prauc_ref_{c}'] = np.sum(y_true == c) / len(y_true)\n",
    "\n",
    "    # Probability Measure\n",
    "    R['log_loss'] = log_loss(y_true=y_true, y_pred=y_proba, labels=classes, normalize=True)\n",
    "\n",
    "    if not is_multiclass:\n",
    "        R[f'brier_loss'] = brier_score_loss(\n",
    "            y_true=y_true, y_prob=y_proba[:, 1], pos_label=classes[1]\n",
    "        )\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n",
      "/Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3284: FutureWarning: y_prob was deprecated in version 1.5 and will be removed in 1.7.Please use ``y_proba`` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>split</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_inst</th>\n",
       "      <th>test_inst_0</th>\n",
       "      <th>test_inst_1</th>\n",
       "      <th>test_class_ratio</th>\n",
       "      <th>test_true_0_pred_0</th>\n",
       "      <th>test_true_0_pred_1</th>\n",
       "      <th>...</th>\n",
       "      <th>train_pre_1</th>\n",
       "      <th>train_rec_1</th>\n",
       "      <th>train_f1_1</th>\n",
       "      <th>train_roauc</th>\n",
       "      <th>train_prauc_0</th>\n",
       "      <th>train_prauc_ref_0</th>\n",
       "      <th>train_prauc_1</th>\n",
       "      <th>train_prauc_ref_1</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>train_brier_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os</td>\n",
       "      <td>fold4</td>\n",
       "      <td>176</td>\n",
       "      <td>10437</td>\n",
       "      <td>4410</td>\n",
       "      <td>6027</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>2224</td>\n",
       "      <td>2186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725388</td>\n",
       "      <td>0.955492</td>\n",
       "      <td>0.824690</td>\n",
       "      <td>0.913873</td>\n",
       "      <td>0.921846</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.913785</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507157</td>\n",
       "      <td>0.163555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>fold3</td>\n",
       "      <td>179</td>\n",
       "      <td>11193</td>\n",
       "      <td>5859</td>\n",
       "      <td>5334</td>\n",
       "      <td>1.098425</td>\n",
       "      <td>4285</td>\n",
       "      <td>1574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998596</td>\n",
       "      <td>0.996925</td>\n",
       "      <td>0.997760</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.003013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns_kfold</td>\n",
       "      <td>fold1</td>\n",
       "      <td>184</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>3688</td>\n",
       "      <td>1822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736441</td>\n",
       "      <td>0.932550</td>\n",
       "      <td>0.822974</td>\n",
       "      <td>0.900676</td>\n",
       "      <td>0.913071</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.893909</td>\n",
       "      <td>0.499034</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.176567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>fold2</td>\n",
       "      <td>187</td>\n",
       "      <td>11361</td>\n",
       "      <td>6468</td>\n",
       "      <td>4893</td>\n",
       "      <td>1.321888</td>\n",
       "      <td>4599</td>\n",
       "      <td>1869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998933</td>\n",
       "      <td>0.995788</td>\n",
       "      <td>0.997358</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999574</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025755</td>\n",
       "      <td>0.003386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os</td>\n",
       "      <td>fold5</td>\n",
       "      <td>189</td>\n",
       "      <td>9996</td>\n",
       "      <td>4641</td>\n",
       "      <td>5355</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2556</td>\n",
       "      <td>2085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736960</td>\n",
       "      <td>0.920693</td>\n",
       "      <td>0.818644</td>\n",
       "      <td>0.906347</td>\n",
       "      <td>0.915428</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.905423</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.515802</td>\n",
       "      <td>0.166943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns_kfold</td>\n",
       "      <td>fold3</td>\n",
       "      <td>181</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>3556</td>\n",
       "      <td>1955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733343</td>\n",
       "      <td>0.934329</td>\n",
       "      <td>0.821725</td>\n",
       "      <td>0.901806</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.500943</td>\n",
       "      <td>0.899512</td>\n",
       "      <td>0.499057</td>\n",
       "      <td>0.536499</td>\n",
       "      <td>0.175562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns_kfold</td>\n",
       "      <td>fold4</td>\n",
       "      <td>182</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>5483</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998489</td>\n",
       "      <td>0.993442</td>\n",
       "      <td>0.995959</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>0.998471</td>\n",
       "      <td>0.500943</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>0.499057</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.005265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns_kfold</td>\n",
       "      <td>fold5</td>\n",
       "      <td>184</td>\n",
       "      <td>10999</td>\n",
       "      <td>5510</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.003826</td>\n",
       "      <td>5476</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998402</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>0.997173</td>\n",
       "      <td>0.999164</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.500955</td>\n",
       "      <td>0.999052</td>\n",
       "      <td>0.499045</td>\n",
       "      <td>0.035981</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns_kfold</td>\n",
       "      <td>fold2</td>\n",
       "      <td>180</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>3772</td>\n",
       "      <td>1738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745738</td>\n",
       "      <td>0.910461</td>\n",
       "      <td>0.819908</td>\n",
       "      <td>0.896891</td>\n",
       "      <td>0.910084</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.887714</td>\n",
       "      <td>0.499034</td>\n",
       "      <td>0.545350</td>\n",
       "      <td>0.179203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>fold1</td>\n",
       "      <td>185</td>\n",
       "      <td>12012</td>\n",
       "      <td>6174</td>\n",
       "      <td>5838</td>\n",
       "      <td>1.057554</td>\n",
       "      <td>4115</td>\n",
       "      <td>2059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.994817</td>\n",
       "      <td>0.996893</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.026037</td>\n",
       "      <td>0.003450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os</td>\n",
       "      <td>fold2</td>\n",
       "      <td>187</td>\n",
       "      <td>11361</td>\n",
       "      <td>6468</td>\n",
       "      <td>4893</td>\n",
       "      <td>1.321888</td>\n",
       "      <td>4105</td>\n",
       "      <td>2363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752812</td>\n",
       "      <td>0.928749</td>\n",
       "      <td>0.831577</td>\n",
       "      <td>0.920156</td>\n",
       "      <td>0.926015</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.919054</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.531166</td>\n",
       "      <td>0.172728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>fold5</td>\n",
       "      <td>189</td>\n",
       "      <td>9996</td>\n",
       "      <td>4641</td>\n",
       "      <td>5355</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3255</td>\n",
       "      <td>1386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998035</td>\n",
       "      <td>0.997556</td>\n",
       "      <td>0.997795</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025725</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns_kfold</td>\n",
       "      <td>fold1</td>\n",
       "      <td>184</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>5473</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998630</td>\n",
       "      <td>0.995901</td>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.499034</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>0.004601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>fold4</td>\n",
       "      <td>176</td>\n",
       "      <td>10437</td>\n",
       "      <td>4410</td>\n",
       "      <td>6027</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>2803</td>\n",
       "      <td>1607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998615</td>\n",
       "      <td>0.997148</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025618</td>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os</td>\n",
       "      <td>fold3</td>\n",
       "      <td>179</td>\n",
       "      <td>11193</td>\n",
       "      <td>5859</td>\n",
       "      <td>5334</td>\n",
       "      <td>1.098425</td>\n",
       "      <td>3882</td>\n",
       "      <td>1977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757798</td>\n",
       "      <td>0.915163</td>\n",
       "      <td>0.829079</td>\n",
       "      <td>0.910933</td>\n",
       "      <td>0.920113</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.907151</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.532591</td>\n",
       "      <td>0.173318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os</td>\n",
       "      <td>fold1</td>\n",
       "      <td>185</td>\n",
       "      <td>12012</td>\n",
       "      <td>6174</td>\n",
       "      <td>5838</td>\n",
       "      <td>1.057554</td>\n",
       "      <td>3526</td>\n",
       "      <td>2648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753881</td>\n",
       "      <td>0.928178</td>\n",
       "      <td>0.831999</td>\n",
       "      <td>0.912198</td>\n",
       "      <td>0.920003</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.910493</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.510193</td>\n",
       "      <td>0.164142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns_kfold</td>\n",
       "      <td>fold2</td>\n",
       "      <td>180</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>5488</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997488</td>\n",
       "      <td>0.994671</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.998818</td>\n",
       "      <td>0.998677</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.499034</td>\n",
       "      <td>0.040558</td>\n",
       "      <td>0.005771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns_kfold</td>\n",
       "      <td>fold5</td>\n",
       "      <td>184</td>\n",
       "      <td>10999</td>\n",
       "      <td>5510</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.003826</td>\n",
       "      <td>3857</td>\n",
       "      <td>1653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747712</td>\n",
       "      <td>0.900537</td>\n",
       "      <td>0.817040</td>\n",
       "      <td>0.889608</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.500955</td>\n",
       "      <td>0.878700</td>\n",
       "      <td>0.499045</td>\n",
       "      <td>0.551987</td>\n",
       "      <td>0.182225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns_kfold</td>\n",
       "      <td>fold4</td>\n",
       "      <td>182</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>3650</td>\n",
       "      <td>1861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736734</td>\n",
       "      <td>0.918754</td>\n",
       "      <td>0.817738</td>\n",
       "      <td>0.897677</td>\n",
       "      <td>0.909071</td>\n",
       "      <td>0.500943</td>\n",
       "      <td>0.892321</td>\n",
       "      <td>0.499057</td>\n",
       "      <td>0.539053</td>\n",
       "      <td>0.176620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns_kfold</td>\n",
       "      <td>fold3</td>\n",
       "      <td>181</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>5474</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998766</td>\n",
       "      <td>0.995218</td>\n",
       "      <td>0.996989</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.500943</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.499057</td>\n",
       "      <td>0.035060</td>\n",
       "      <td>0.004630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os_kfold</td>\n",
       "      <td>fold1</td>\n",
       "      <td>184</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>3686</td>\n",
       "      <td>1824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738568</td>\n",
       "      <td>0.929861</td>\n",
       "      <td>0.823248</td>\n",
       "      <td>0.900994</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.894774</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.539908</td>\n",
       "      <td>0.176796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg_kfold</td>\n",
       "      <td>fold1</td>\n",
       "      <td>279</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>4200</td>\n",
       "      <td>1310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760738</td>\n",
       "      <td>0.764722</td>\n",
       "      <td>0.762725</td>\n",
       "      <td>0.850375</td>\n",
       "      <td>0.853742</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.847109</td>\n",
       "      <td>0.499034</td>\n",
       "      <td>0.479711</td>\n",
       "      <td>0.158563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os_kfold</td>\n",
       "      <td>fold2</td>\n",
       "      <td>180</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>3741</td>\n",
       "      <td>1769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744184</td>\n",
       "      <td>0.914345</td>\n",
       "      <td>0.820536</td>\n",
       "      <td>0.896654</td>\n",
       "      <td>0.909555</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888310</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.544884</td>\n",
       "      <td>0.179002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>fold5</td>\n",
       "      <td>184</td>\n",
       "      <td>10999</td>\n",
       "      <td>5510</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.003826</td>\n",
       "      <td>5473</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998634</td>\n",
       "      <td>0.994919</td>\n",
       "      <td>0.996773</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.035515</td>\n",
       "      <td>0.004698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg_kfold</td>\n",
       "      <td>fold2</td>\n",
       "      <td>279</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>4169</td>\n",
       "      <td>1341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.768365</td>\n",
       "      <td>0.764518</td>\n",
       "      <td>0.850418</td>\n",
       "      <td>0.853454</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.846317</td>\n",
       "      <td>0.499034</td>\n",
       "      <td>0.479771</td>\n",
       "      <td>0.158423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg_kfold</td>\n",
       "      <td>fold3</td>\n",
       "      <td>279</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>4116</td>\n",
       "      <td>1395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762153</td>\n",
       "      <td>0.771108</td>\n",
       "      <td>0.766605</td>\n",
       "      <td>0.852616</td>\n",
       "      <td>0.855026</td>\n",
       "      <td>0.500943</td>\n",
       "      <td>0.849737</td>\n",
       "      <td>0.499057</td>\n",
       "      <td>0.476649</td>\n",
       "      <td>0.157323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>fold4</td>\n",
       "      <td>182</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>5483</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998680</td>\n",
       "      <td>0.995236</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>0.999007</td>\n",
       "      <td>0.998720</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.036375</td>\n",
       "      <td>0.004844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os_kfold</td>\n",
       "      <td>fold3</td>\n",
       "      <td>181</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>3556</td>\n",
       "      <td>1955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734157</td>\n",
       "      <td>0.932943</td>\n",
       "      <td>0.821698</td>\n",
       "      <td>0.901745</td>\n",
       "      <td>0.911789</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.534829</td>\n",
       "      <td>0.174806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>fold1</td>\n",
       "      <td>184</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>5471</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>0.996189</td>\n",
       "      <td>0.997456</td>\n",
       "      <td>0.999420</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.033367</td>\n",
       "      <td>0.004284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>fold3</td>\n",
       "      <td>181</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>5476</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998907</td>\n",
       "      <td>0.995145</td>\n",
       "      <td>0.997023</td>\n",
       "      <td>0.999249</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.032155</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os_kfold</td>\n",
       "      <td>fold4</td>\n",
       "      <td>182</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>3642</td>\n",
       "      <td>1869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736684</td>\n",
       "      <td>0.922417</td>\n",
       "      <td>0.819154</td>\n",
       "      <td>0.897330</td>\n",
       "      <td>0.908971</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.891122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.539920</td>\n",
       "      <td>0.176949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg_kfold</td>\n",
       "      <td>fold4</td>\n",
       "      <td>279</td>\n",
       "      <td>11000</td>\n",
       "      <td>5511</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.004008</td>\n",
       "      <td>4145</td>\n",
       "      <td>1366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760328</td>\n",
       "      <td>0.768604</td>\n",
       "      <td>0.764443</td>\n",
       "      <td>0.851047</td>\n",
       "      <td>0.854668</td>\n",
       "      <td>0.500943</td>\n",
       "      <td>0.847909</td>\n",
       "      <td>0.499057</td>\n",
       "      <td>0.478658</td>\n",
       "      <td>0.158170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg_kfold</td>\n",
       "      <td>fold5</td>\n",
       "      <td>279</td>\n",
       "      <td>10999</td>\n",
       "      <td>5510</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.003826</td>\n",
       "      <td>4195</td>\n",
       "      <td>1315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761419</td>\n",
       "      <td>0.769014</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.850637</td>\n",
       "      <td>0.852978</td>\n",
       "      <td>0.500955</td>\n",
       "      <td>0.847979</td>\n",
       "      <td>0.499045</td>\n",
       "      <td>0.479335</td>\n",
       "      <td>0.158339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_os_kfold</td>\n",
       "      <td>fold5</td>\n",
       "      <td>184</td>\n",
       "      <td>10999</td>\n",
       "      <td>5510</td>\n",
       "      <td>5489</td>\n",
       "      <td>1.003826</td>\n",
       "      <td>3833</td>\n",
       "      <td>1677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746508</td>\n",
       "      <td>0.904500</td>\n",
       "      <td>0.817945</td>\n",
       "      <td>0.888354</td>\n",
       "      <td>0.903880</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875609</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.552213</td>\n",
       "      <td>0.182333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>fold2</td>\n",
       "      <td>180</td>\n",
       "      <td>11000</td>\n",
       "      <td>5510</td>\n",
       "      <td>5490</td>\n",
       "      <td>1.003643</td>\n",
       "      <td>5492</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997817</td>\n",
       "      <td>0.995554</td>\n",
       "      <td>0.996684</td>\n",
       "      <td>0.998915</td>\n",
       "      <td>0.998837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.998878</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.005042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns</td>\n",
       "      <td>fold2</td>\n",
       "      <td>187</td>\n",
       "      <td>11361</td>\n",
       "      <td>6468</td>\n",
       "      <td>4893</td>\n",
       "      <td>1.321888</td>\n",
       "      <td>3867</td>\n",
       "      <td>2601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734669</td>\n",
       "      <td>0.956105</td>\n",
       "      <td>0.830887</td>\n",
       "      <td>0.918008</td>\n",
       "      <td>0.920498</td>\n",
       "      <td>0.483157</td>\n",
       "      <td>0.921341</td>\n",
       "      <td>0.516843</td>\n",
       "      <td>0.528734</td>\n",
       "      <td>0.171633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns</td>\n",
       "      <td>fold5</td>\n",
       "      <td>189</td>\n",
       "      <td>9996</td>\n",
       "      <td>4641</td>\n",
       "      <td>5355</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3355</td>\n",
       "      <td>1286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998277</td>\n",
       "      <td>0.996334</td>\n",
       "      <td>0.997304</td>\n",
       "      <td>0.999308</td>\n",
       "      <td>0.999270</td>\n",
       "      <td>0.509099</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.490901</td>\n",
       "      <td>0.026567</td>\n",
       "      <td>0.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>fold4</td>\n",
       "      <td>279</td>\n",
       "      <td>10437</td>\n",
       "      <td>4410</td>\n",
       "      <td>6027</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>3022</td>\n",
       "      <td>1388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753601</td>\n",
       "      <td>0.749907</td>\n",
       "      <td>0.751749</td>\n",
       "      <td>0.850343</td>\n",
       "      <td>0.864929</td>\n",
       "      <td>0.519321</td>\n",
       "      <td>0.834260</td>\n",
       "      <td>0.480679</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.158284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>fold5</td>\n",
       "      <td>279</td>\n",
       "      <td>9996</td>\n",
       "      <td>4641</td>\n",
       "      <td>5355</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3235</td>\n",
       "      <td>1406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767815</td>\n",
       "      <td>0.772089</td>\n",
       "      <td>0.769946</td>\n",
       "      <td>0.859932</td>\n",
       "      <td>0.865412</td>\n",
       "      <td>0.509099</td>\n",
       "      <td>0.851713</td>\n",
       "      <td>0.490901</td>\n",
       "      <td>0.465761</td>\n",
       "      <td>0.152810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns</td>\n",
       "      <td>fold4</td>\n",
       "      <td>176</td>\n",
       "      <td>10437</td>\n",
       "      <td>4410</td>\n",
       "      <td>6027</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>2986</td>\n",
       "      <td>1424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>0.995752</td>\n",
       "      <td>0.997265</td>\n",
       "      <td>0.999523</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>0.519321</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>0.480679</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns</td>\n",
       "      <td>fold3</td>\n",
       "      <td>179</td>\n",
       "      <td>11193</td>\n",
       "      <td>5859</td>\n",
       "      <td>5334</td>\n",
       "      <td>1.098425</td>\n",
       "      <td>3827</td>\n",
       "      <td>2032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757355</td>\n",
       "      <td>0.916203</td>\n",
       "      <td>0.829240</td>\n",
       "      <td>0.909335</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>0.495206</td>\n",
       "      <td>0.907060</td>\n",
       "      <td>0.504794</td>\n",
       "      <td>0.533404</td>\n",
       "      <td>0.173623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns</td>\n",
       "      <td>fold1</td>\n",
       "      <td>185</td>\n",
       "      <td>12012</td>\n",
       "      <td>6174</td>\n",
       "      <td>5838</td>\n",
       "      <td>1.057554</td>\n",
       "      <td>3414</td>\n",
       "      <td>2760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749592</td>\n",
       "      <td>0.934102</td>\n",
       "      <td>0.831737</td>\n",
       "      <td>0.911809</td>\n",
       "      <td>0.918974</td>\n",
       "      <td>0.497313</td>\n",
       "      <td>0.911285</td>\n",
       "      <td>0.502687</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>0.162893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns</td>\n",
       "      <td>fold4</td>\n",
       "      <td>176</td>\n",
       "      <td>10437</td>\n",
       "      <td>4410</td>\n",
       "      <td>6027</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>2404</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725889</td>\n",
       "      <td>0.930439</td>\n",
       "      <td>0.815533</td>\n",
       "      <td>0.915165</td>\n",
       "      <td>0.926693</td>\n",
       "      <td>0.519321</td>\n",
       "      <td>0.910979</td>\n",
       "      <td>0.480679</td>\n",
       "      <td>0.505713</td>\n",
       "      <td>0.163329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns</td>\n",
       "      <td>fold3</td>\n",
       "      <td>179</td>\n",
       "      <td>11193</td>\n",
       "      <td>5859</td>\n",
       "      <td>5334</td>\n",
       "      <td>1.098425</td>\n",
       "      <td>4289</td>\n",
       "      <td>1570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998731</td>\n",
       "      <td>0.996699</td>\n",
       "      <td>0.997714</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.495206</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>0.504794</td>\n",
       "      <td>0.023812</td>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>fold2</td>\n",
       "      <td>279</td>\n",
       "      <td>11361</td>\n",
       "      <td>6468</td>\n",
       "      <td>4893</td>\n",
       "      <td>1.321888</td>\n",
       "      <td>4867</td>\n",
       "      <td>1601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771210</td>\n",
       "      <td>0.783896</td>\n",
       "      <td>0.777502</td>\n",
       "      <td>0.854269</td>\n",
       "      <td>0.848539</td>\n",
       "      <td>0.483157</td>\n",
       "      <td>0.859592</td>\n",
       "      <td>0.516843</td>\n",
       "      <td>0.473639</td>\n",
       "      <td>0.156172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>fold3</td>\n",
       "      <td>279</td>\n",
       "      <td>11193</td>\n",
       "      <td>5859</td>\n",
       "      <td>5334</td>\n",
       "      <td>1.098425</td>\n",
       "      <td>4363</td>\n",
       "      <td>1496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763176</td>\n",
       "      <td>0.769457</td>\n",
       "      <td>0.766303</td>\n",
       "      <td>0.854869</td>\n",
       "      <td>0.854271</td>\n",
       "      <td>0.495206</td>\n",
       "      <td>0.856642</td>\n",
       "      <td>0.504794</td>\n",
       "      <td>0.473374</td>\n",
       "      <td>0.156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns</td>\n",
       "      <td>fold2</td>\n",
       "      <td>187</td>\n",
       "      <td>11361</td>\n",
       "      <td>6468</td>\n",
       "      <td>4893</td>\n",
       "      <td>1.321888</td>\n",
       "      <td>4463</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.997648</td>\n",
       "      <td>0.999567</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.483157</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.516843</td>\n",
       "      <td>0.026153</td>\n",
       "      <td>0.003251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>attention</td>\n",
       "      <td>rf_ns</td>\n",
       "      <td>fold5</td>\n",
       "      <td>189</td>\n",
       "      <td>9996</td>\n",
       "      <td>4641</td>\n",
       "      <td>5355</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2704</td>\n",
       "      <td>1937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740127</td>\n",
       "      <td>0.911959</td>\n",
       "      <td>0.817107</td>\n",
       "      <td>0.908461</td>\n",
       "      <td>0.919632</td>\n",
       "      <td>0.509099</td>\n",
       "      <td>0.904064</td>\n",
       "      <td>0.490901</td>\n",
       "      <td>0.518857</td>\n",
       "      <td>0.168207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>fold1</td>\n",
       "      <td>279</td>\n",
       "      <td>12012</td>\n",
       "      <td>6174</td>\n",
       "      <td>5838</td>\n",
       "      <td>1.057554</td>\n",
       "      <td>4457</td>\n",
       "      <td>1717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763967</td>\n",
       "      <td>0.773937</td>\n",
       "      <td>0.768920</td>\n",
       "      <td>0.854548</td>\n",
       "      <td>0.854830</td>\n",
       "      <td>0.497313</td>\n",
       "      <td>0.856110</td>\n",
       "      <td>0.502687</td>\n",
       "      <td>0.473643</td>\n",
       "      <td>0.156398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_ns</td>\n",
       "      <td>fold1</td>\n",
       "      <td>185</td>\n",
       "      <td>12012</td>\n",
       "      <td>6174</td>\n",
       "      <td>5838</td>\n",
       "      <td>1.057554</td>\n",
       "      <td>4150</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999071</td>\n",
       "      <td>0.995095</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.999235</td>\n",
       "      <td>0.497313</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.502687</td>\n",
       "      <td>0.024142</td>\n",
       "      <td>0.003243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label           alg  split  n_feature  test_inst  test_inst_0  \\\n",
       "0   attention         rf_os  fold4        176      10437         4410   \n",
       "1   attention        xgb_os  fold3        179      11193         5859   \n",
       "2   attention   rf_ns_kfold  fold1        184      11000         5510   \n",
       "3   attention        xgb_os  fold2        187      11361         6468   \n",
       "4   attention         rf_os  fold5        189       9996         4641   \n",
       "5   attention   rf_ns_kfold  fold3        181      11000         5511   \n",
       "6   attention  xgb_ns_kfold  fold4        182      11000         5511   \n",
       "7   attention  xgb_ns_kfold  fold5        184      10999         5510   \n",
       "8   attention   rf_ns_kfold  fold2        180      11000         5510   \n",
       "9   attention        xgb_os  fold1        185      12012         6174   \n",
       "10  attention         rf_os  fold2        187      11361         6468   \n",
       "11  attention        xgb_os  fold5        189       9996         4641   \n",
       "12  attention  xgb_ns_kfold  fold1        184      11000         5510   \n",
       "13  attention        xgb_os  fold4        176      10437         4410   \n",
       "14  attention         rf_os  fold3        179      11193         5859   \n",
       "15  attention         rf_os  fold1        185      12012         6174   \n",
       "16  attention  xgb_ns_kfold  fold2        180      11000         5510   \n",
       "17  attention   rf_ns_kfold  fold5        184      10999         5510   \n",
       "18  attention   rf_ns_kfold  fold4        182      11000         5511   \n",
       "19  attention  xgb_ns_kfold  fold3        181      11000         5511   \n",
       "20  attention   rf_os_kfold  fold1        184      11000         5510   \n",
       "21  attention  logreg_kfold  fold1        279      11000         5510   \n",
       "22  attention   rf_os_kfold  fold2        180      11000         5510   \n",
       "23  attention  xgb_os_kfold  fold5        184      10999         5510   \n",
       "24  attention  logreg_kfold  fold2        279      11000         5510   \n",
       "25  attention  logreg_kfold  fold3        279      11000         5511   \n",
       "26  attention  xgb_os_kfold  fold4        182      11000         5511   \n",
       "27  attention   rf_os_kfold  fold3        181      11000         5511   \n",
       "28  attention  xgb_os_kfold  fold1        184      11000         5510   \n",
       "29  attention  xgb_os_kfold  fold3        181      11000         5511   \n",
       "30  attention   rf_os_kfold  fold4        182      11000         5511   \n",
       "31  attention  logreg_kfold  fold4        279      11000         5511   \n",
       "32  attention  logreg_kfold  fold5        279      10999         5510   \n",
       "33  attention   rf_os_kfold  fold5        184      10999         5510   \n",
       "34  attention  xgb_os_kfold  fold2        180      11000         5510   \n",
       "35  attention         rf_ns  fold2        187      11361         6468   \n",
       "36  attention        xgb_ns  fold5        189       9996         4641   \n",
       "37  attention        logreg  fold4        279      10437         4410   \n",
       "38  attention        logreg  fold5        279       9996         4641   \n",
       "39  attention        xgb_ns  fold4        176      10437         4410   \n",
       "40  attention         rf_ns  fold3        179      11193         5859   \n",
       "41  attention         rf_ns  fold1        185      12012         6174   \n",
       "42  attention         rf_ns  fold4        176      10437         4410   \n",
       "43  attention        xgb_ns  fold3        179      11193         5859   \n",
       "44  attention        logreg  fold2        279      11361         6468   \n",
       "45  attention        logreg  fold3        279      11193         5859   \n",
       "46  attention        xgb_ns  fold2        187      11361         6468   \n",
       "47  attention         rf_ns  fold5        189       9996         4641   \n",
       "48  attention        logreg  fold1        279      12012         6174   \n",
       "49  attention        xgb_ns  fold1        185      12012         6174   \n",
       "\n",
       "    test_inst_1  test_class_ratio  test_true_0_pred_0  test_true_0_pred_1  \\\n",
       "0          6027          0.731707                2224                2186   \n",
       "1          5334          1.098425                4285                1574   \n",
       "2          5490          1.003643                3688                1822   \n",
       "3          4893          1.321888                4599                1869   \n",
       "4          5355          0.866667                2556                2085   \n",
       "5          5489          1.004008                3556                1955   \n",
       "6          5489          1.004008                5483                  28   \n",
       "7          5489          1.003826                5476                  34   \n",
       "8          5490          1.003643                3772                1738   \n",
       "9          5838          1.057554                4115                2059   \n",
       "10         4893          1.321888                4105                2363   \n",
       "11         5355          0.866667                3255                1386   \n",
       "12         5490          1.003643                5473                  37   \n",
       "13         6027          0.731707                2803                1607   \n",
       "14         5334          1.098425                3882                1977   \n",
       "15         5838          1.057554                3526                2648   \n",
       "16         5490          1.003643                5488                  22   \n",
       "17         5489          1.003826                3857                1653   \n",
       "18         5489          1.004008                3650                1861   \n",
       "19         5489          1.004008                5474                  37   \n",
       "20         5490          1.003643                3686                1824   \n",
       "21         5490          1.003643                4200                1310   \n",
       "22         5490          1.003643                3741                1769   \n",
       "23         5489          1.003826                5473                  37   \n",
       "24         5490          1.003643                4169                1341   \n",
       "25         5489          1.004008                4116                1395   \n",
       "26         5489          1.004008                5483                  28   \n",
       "27         5489          1.004008                3556                1955   \n",
       "28         5490          1.003643                5471                  39   \n",
       "29         5489          1.004008                5476                  35   \n",
       "30         5489          1.004008                3642                1869   \n",
       "31         5489          1.004008                4145                1366   \n",
       "32         5489          1.003826                4195                1315   \n",
       "33         5489          1.003826                3833                1677   \n",
       "34         5490          1.003643                5492                  18   \n",
       "35         4893          1.321888                3867                2601   \n",
       "36         5355          0.866667                3355                1286   \n",
       "37         6027          0.731707                3022                1388   \n",
       "38         5355          0.866667                3235                1406   \n",
       "39         6027          0.731707                2986                1424   \n",
       "40         5334          1.098425                3827                2032   \n",
       "41         5838          1.057554                3414                2760   \n",
       "42         6027          0.731707                2404                2006   \n",
       "43         5334          1.098425                4289                1570   \n",
       "44         4893          1.321888                4867                1601   \n",
       "45         5334          1.098425                4363                1496   \n",
       "46         4893          1.321888                4463                2005   \n",
       "47         5355          0.866667                2704                1937   \n",
       "48         5838          1.057554                4457                1717   \n",
       "49         5838          1.057554                4150                2024   \n",
       "\n",
       "    ...  train_pre_1  train_rec_1  train_f1_1  train_roauc  train_prauc_0  \\\n",
       "0   ...     0.725388     0.955492    0.824690     0.913873       0.921846   \n",
       "1   ...     0.998596     0.996925    0.997760     0.999332       0.999210   \n",
       "2   ...     0.736441     0.932550    0.822974     0.900676       0.913071   \n",
       "3   ...     0.998933     0.995788    0.997358     0.999504       0.999356   \n",
       "4   ...     0.736960     0.920693    0.818644     0.906347       0.915428   \n",
       "5   ...     0.733343     0.934329    0.821725     0.901806       0.912027   \n",
       "6   ...     0.998489     0.993442    0.995959     0.998800       0.998471   \n",
       "7   ...     0.998402     0.995947    0.997173     0.999164       0.999196   \n",
       "8   ...     0.745738     0.910461    0.819908     0.896891       0.910084   \n",
       "9   ...     0.998978     0.994817    0.996893     0.999217       0.998970   \n",
       "10  ...     0.752812     0.928749    0.831577     0.920156       0.926015   \n",
       "11  ...     0.998035     0.997556    0.997795     0.999509       0.999451   \n",
       "12  ...     0.998630     0.995901    0.997264     0.999307       0.999202   \n",
       "13  ...     0.998615     0.997148    0.997881     0.999555       0.999460   \n",
       "14  ...     0.757798     0.915163    0.829079     0.910933       0.920113   \n",
       "15  ...     0.753881     0.928178    0.831999     0.912198       0.920003   \n",
       "16  ...     0.997488     0.994671    0.996078     0.998818       0.998677   \n",
       "17  ...     0.747712     0.900537    0.817040     0.889608       0.904389   \n",
       "18  ...     0.736734     0.918754    0.817738     0.897677       0.909071   \n",
       "19  ...     0.998766     0.995218    0.996989     0.999294       0.999142   \n",
       "20  ...     0.738568     0.929861    0.823248     0.900994       0.912900   \n",
       "21  ...     0.760738     0.764722    0.762725     0.850375       0.853742   \n",
       "22  ...     0.744184     0.914345    0.820536     0.896654       0.909555   \n",
       "23  ...     0.998634     0.994919    0.996773     0.999121       0.999068   \n",
       "24  ...     0.760709     0.768365    0.764518     0.850418       0.853454   \n",
       "25  ...     0.762153     0.771108    0.766605     0.852616       0.855026   \n",
       "26  ...     0.998680     0.995236    0.996955     0.999007       0.998720   \n",
       "27  ...     0.734157     0.932943    0.821698     0.901745       0.911789   \n",
       "28  ...     0.998726     0.996189    0.997456     0.999420       0.999344   \n",
       "29  ...     0.998907     0.995145    0.997023     0.999249       0.999063   \n",
       "30  ...     0.736684     0.922417    0.819154     0.897330       0.908971   \n",
       "31  ...     0.760328     0.768604    0.764443     0.851047       0.854668   \n",
       "32  ...     0.761419     0.769014    0.765198     0.850637       0.852978   \n",
       "33  ...     0.746508     0.904500    0.817945     0.888354       0.903880   \n",
       "34  ...     0.997817     0.995554    0.996684     0.998915       0.998837   \n",
       "35  ...     0.734669     0.956105    0.830887     0.918008       0.920498   \n",
       "36  ...     0.998277     0.996334    0.997304     0.999308       0.999270   \n",
       "37  ...     0.753601     0.749907    0.751749     0.850343       0.864929   \n",
       "38  ...     0.767815     0.772089    0.769946     0.859932       0.865412   \n",
       "39  ...     0.998782     0.995752    0.997265     0.999523       0.999469   \n",
       "40  ...     0.757355     0.916203    0.829240     0.909335       0.917391   \n",
       "41  ...     0.749592     0.934102    0.831737     0.911809       0.918974   \n",
       "42  ...     0.725889     0.930439    0.815533     0.915165       0.926693   \n",
       "43  ...     0.998731     0.996699    0.997714     0.999430       0.999331   \n",
       "44  ...     0.771210     0.783896    0.777502     0.854269       0.848539   \n",
       "45  ...     0.763176     0.769457    0.766303     0.854869       0.854271   \n",
       "46  ...     0.998711     0.996586    0.997648     0.999567       0.999481   \n",
       "47  ...     0.740127     0.911959    0.817107     0.908461       0.919632   \n",
       "48  ...     0.763967     0.773937    0.768920     0.854548       0.854830   \n",
       "49  ...     0.999071     0.995095    0.997079     0.999355       0.999235   \n",
       "\n",
       "    train_prauc_ref_0  train_prauc_1  train_prauc_ref_1  train_log_loss  \\\n",
       "0            0.500000       0.913785           0.500000        0.507157   \n",
       "1            0.500000       0.999362           0.500000        0.025328   \n",
       "2            0.500966       0.893909           0.499034        0.539256   \n",
       "3            0.500000       0.999574           0.500000        0.025755   \n",
       "4            0.500000       0.905423           0.500000        0.515802   \n",
       "5            0.500943       0.899512           0.499057        0.536499   \n",
       "6            0.500943       0.998975           0.499057        0.037892   \n",
       "7            0.500955       0.999052           0.499045        0.035981   \n",
       "8            0.500966       0.887714           0.499034        0.545350   \n",
       "9            0.500000       0.999325           0.500000        0.026037   \n",
       "10           0.500000       0.919054           0.500000        0.531166   \n",
       "11           0.500000       0.999546           0.500000        0.025725   \n",
       "12           0.500966       0.999339           0.499034        0.035779   \n",
       "13           0.500000       0.999594           0.500000        0.025618   \n",
       "14           0.500000       0.907151           0.500000        0.532591   \n",
       "15           0.500000       0.910493           0.500000        0.510193   \n",
       "16           0.500966       0.998778           0.499034        0.040558   \n",
       "17           0.500955       0.878700           0.499045        0.551987   \n",
       "18           0.500943       0.892321           0.499057        0.539053   \n",
       "19           0.500943       0.999390           0.499057        0.035060   \n",
       "20           0.500000       0.894774           0.500000        0.539908   \n",
       "21           0.500966       0.847109           0.499034        0.479711   \n",
       "22           0.500000       0.888310           0.500000        0.544884   \n",
       "23           0.500000       0.998969           0.500000        0.035515   \n",
       "24           0.500966       0.846317           0.499034        0.479771   \n",
       "25           0.500943       0.849737           0.499057        0.476649   \n",
       "26           0.500000       0.999094           0.500000        0.036375   \n",
       "27           0.500000       0.899664           0.500000        0.534829   \n",
       "28           0.500000       0.999443           0.500000        0.033367   \n",
       "29           0.500000       0.999323           0.500000        0.032155   \n",
       "30           0.500000       0.891122           0.500000        0.539920   \n",
       "31           0.500943       0.847909           0.499057        0.478658   \n",
       "32           0.500955       0.847979           0.499045        0.479335   \n",
       "33           0.500000       0.875609           0.500000        0.552213   \n",
       "34           0.500000       0.998878           0.500000        0.037892   \n",
       "35           0.483157       0.921341           0.516843        0.528734   \n",
       "36           0.509099       0.999299           0.490901        0.026567   \n",
       "37           0.519321       0.834260           0.480679        0.479000   \n",
       "38           0.509099       0.851713           0.490901        0.465761   \n",
       "39           0.519321       0.999566           0.480679        0.025611   \n",
       "40           0.495206       0.907060           0.504794        0.533404   \n",
       "41           0.497313       0.911285           0.502687        0.506944   \n",
       "42           0.519321       0.910979           0.480679        0.505713   \n",
       "43           0.495206       0.999496           0.504794        0.023812   \n",
       "44           0.483157       0.859592           0.516843        0.473639   \n",
       "45           0.495206       0.856642           0.504794        0.473374   \n",
       "46           0.483157       0.999612           0.516843        0.026153   \n",
       "47           0.509099       0.904064           0.490901        0.518857   \n",
       "48           0.497313       0.856110           0.502687        0.473643   \n",
       "49           0.497313       0.999435           0.502687        0.024142   \n",
       "\n",
       "    train_brier_loss  \n",
       "0           0.163555  \n",
       "1           0.003013  \n",
       "2           0.176567  \n",
       "3           0.003386  \n",
       "4           0.166943  \n",
       "5           0.175562  \n",
       "6           0.005265  \n",
       "7           0.004678  \n",
       "8           0.179203  \n",
       "9           0.003450  \n",
       "10          0.172728  \n",
       "11          0.003158  \n",
       "12          0.004601  \n",
       "13          0.003074  \n",
       "14          0.173318  \n",
       "15          0.164142  \n",
       "16          0.005771  \n",
       "17          0.182225  \n",
       "18          0.176620  \n",
       "19          0.004630  \n",
       "20          0.176796  \n",
       "21          0.158563  \n",
       "22          0.179002  \n",
       "23          0.004698  \n",
       "24          0.158423  \n",
       "25          0.157323  \n",
       "26          0.004844  \n",
       "27          0.174806  \n",
       "28          0.004284  \n",
       "29          0.004132  \n",
       "30          0.176949  \n",
       "31          0.158170  \n",
       "32          0.158339  \n",
       "33          0.182333  \n",
       "34          0.005042  \n",
       "35          0.171633  \n",
       "36          0.003483  \n",
       "37          0.158284  \n",
       "38          0.152810  \n",
       "39          0.003241  \n",
       "40          0.173623  \n",
       "41          0.162893  \n",
       "42          0.163329  \n",
       "43          0.002856  \n",
       "44          0.156172  \n",
       "45          0.156300  \n",
       "46          0.003251  \n",
       "47          0.168207  \n",
       "48          0.156398  \n",
       "49          0.003243  \n",
       "\n",
       "[50 rows x 60 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "RESULTS_EVAL = []\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "\n",
    "for l in ['attention']:\n",
    "    dir_l = os.path.join(DIR_EVAL, l)\n",
    "    if not os.path.exists(dir_l):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(dir_l):\n",
    "        model, pid = f[:f.index('.pkl')].split('#')\n",
    "        res = load(os.path.join(dir_l, f))\n",
    "        X, y = res.X_test, res.y_test\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        y_proba = res.estimator.predict_proba(X)\n",
    "        ev_test = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_proba=y_proba,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "\n",
    "        X, y = res.X_train, res.y_train\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        y_proba = res.estimator.predict_proba(X)\n",
    "        ev_train = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_proba=y_proba,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "\n",
    "        RESULTS_EVAL.append({\n",
    "            'label': l,\n",
    "            'alg': model,\n",
    "            'split': pid,\n",
    "            'n_feature': len(X.columns),\n",
    "            **{\n",
    "                f'test_{k}': v for k, v in ev_test.items()\n",
    "            },\n",
    "            **{\n",
    "                f'train_{k}': v for k, v in ev_train.items()\n",
    "                            }\n",
    "        })\n",
    "    \n",
    "RESULTS_EVAL = pd.DataFrame(RESULTS_EVAL)\n",
    "RESULTS_EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 22:37:52,830\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:37:55] In progress: [rf_ns#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:37:55] In progress: [rf_ns#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:37:55] In progress: [rf_ns#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:37:55] Success: [rf_ns#fold1] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:37:55] In progress: [rf_ns#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:37:55] Success: [rf_ns#fold2] Normalizing numeric features (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:37:55] In progress: [rf_ns#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:37:55] Success: [rf_ns#fold3] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:37:55] In progress: [rf_ns#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:37:58] Success: [rf_ns#fold1] 1-th Feature selection (2.35s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m - # Sel. Feat.: 165 (# Cat. = 10; # Num. = 155)\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:37:58] In progress: [rf_ns#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:37:59] Success: [rf_ns#fold2] 1-th Feature selection (3.45s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 9; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:37:59] In progress: [rf_ns#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:38:00] Success: [rf_ns#fold3] 1-th Feature selection (4.56s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 8; # Num. = 179)\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:38:00] In progress: [rf_ns#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:38:10] Success: [rf_ns#fold1] Training (12.15s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:38:12] Success: [rf_ns#fold2] Training (13.41s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:38:13] Success: [rf_ns#fold3] Training (13.38s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:38:14] In progress: [rf_os#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:38:14] In progress: [rf_os#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:38:14] Success: [rf_os#fold1] Normalizing numeric features (0.11s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:38:14] In progress: [rf_os#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:38:14] In progress: [rf_os#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:38:14] Success: [rf_os#fold2] Normalizing numeric features (0.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:38:14] In progress: [rf_os#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:38:14] Success: [rf_os#fold3] Normalizing numeric features (0.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:38:14] In progress: [rf_os#fold3] 1-th Feature selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:38:16] Success: [rf_os#fold1] 1-th Feature selection (2.34s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m - # Sel. Feat.: 165 (# Cat. = 10; # Num. = 155)\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:38:16] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:38:17] Success: [rf_os#fold2] 1-th Feature selection (3.43s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 9; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:38:17] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:38:19] Success: [rf_os#fold3] 1-th Feature selection (4.56s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 8; # Num. = 179)\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:38:19] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:04] Success: Oversampling (47.57s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:04] In progress: [rf_os#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:11] Success: Oversampling (53.38s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:11] In progress: [rf_os#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:13] Success: Oversampling (54.29s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:13] In progress: [rf_os#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:16] Success: [rf_os#fold1] Training (12.46s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:24] Success: [rf_os#fold2] Training (13.50s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:26] Success: [rf_os#fold3] Training (13.26s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:27] In progress: [xgb_ns#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:27] Success: [xgb_ns#fold1] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:27] In progress: [xgb_ns#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:27] In progress: [xgb_ns#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:27] Success: [xgb_ns#fold2] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:27] In progress: [xgb_ns#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:27] In progress: [xgb_ns#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:27] Success: [xgb_ns#fold3] Normalizing numeric features (0.17s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:27] In progress: [xgb_ns#fold3] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:29] Success: [xgb_ns#fold1] 1-th Feature selection (2.35s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m - # Sel. Feat.: 165 (# Cat. = 10; # Num. = 155)\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:29] In progress: [xgb_ns#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:30] Success: [xgb_ns#fold2] 1-th Feature selection (3.44s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 9; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:30] In progress: [xgb_ns#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:32] Success: [xgb_ns#fold3] 1-th Feature selection (4.52s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 8; # Num. = 179)\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:32] In progress: [xgb_ns#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:33] Success: [xgb_ns#fold1] Training (3.56s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:34] Success: [xgb_ns#fold2] Training (3.91s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:36] Success: [xgb_ns#fold3] Training (4.16s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:36] In progress: [xgb_os#fold1] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:36] In progress: [xgb_os#fold2] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:36] Success: [xgb_os#fold1] Normalizing numeric features (0.10s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:36] In progress: [xgb_os#fold1] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:37] Success: [xgb_os#fold2] Normalizing numeric features (0.10s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:37] In progress: [xgb_os#fold2] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:37] In progress: [xgb_os#fold3] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:37] Success: [xgb_os#fold3] Normalizing numeric features (0.11s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:37] In progress: [xgb_os#fold3] 1-th Feature selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:39] Success: [xgb_os#fold1] 1-th Feature selection (2.33s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m - # Sel. Feat.: 165 (# Cat. = 10; # Num. = 155)\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:39:39] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:40] Success: [xgb_os#fold2] 1-th Feature selection (3.39s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m - # Sel. Feat.: 179 (# Cat. = 9; # Num. = 170)\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:39:40] In progress: Oversampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m /Users/idong-won/anaconda3/envs/ray-env/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:41] Success: [xgb_os#fold3] 1-th Feature selection (4.53s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m - # Orig. Feat.: 279 (# Cat. = 16; # Num. = 263)\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m - # Sel. Feat.: 187 (# Cat. = 8; # Num. = 179)\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:39:41] In progress: Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:40:27] Success: Oversampling (47.82s).\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:40:27] In progress: [xgb_os#fold1] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48004)\u001b[0m [25-06-01 22:40:30] Success: [xgb_os#fold1] Training (3.82s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:40:33] Success: Oversampling (53.46s).\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:40:33] In progress: [xgb_os#fold2] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:40:36] Success: Oversampling (54.58s).\n",
      "\u001b[2m\u001b[36m(_train pid=48000)\u001b[0m [25-06-01 22:40:36] In progress: [xgb_os#fold3] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=48006)\u001b[0m [25-06-01 22:40:37] Success: [xgb_os#fold2] Training (4.12s).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# from eli5.sklearn.permutation_importance import PermutationImportance\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "ESTIMATOR_LOGREG = LogisticRegression(\n",
    "    penalty='l2', solver='liblinear', random_state=RANDOM_STATE\n",
    ")\n",
    "ESTIMATOR_RF = RandomForestClassifier(random_state=RANDOM_STATE, max_depth=5, class_weight='balanced')\n",
    "ESTIMATOR_XGB = EvXGBClassifier(\n",
    "    random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss', \n",
    "    eval_size=0.2,\n",
    "    early_stopping_rounds=10, \n",
    "    objective='binary:logistic', \n",
    "    verbosity=0,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "SELECT_SVC = SelectFromModel(\n",
    "    estimator=LinearSVC(\n",
    "        penalty='l1',\n",
    "        loss='squared_hinge',\n",
    "        dual=False,\n",
    "        tol=1e-3,\n",
    "        C=1e-2,\n",
    "        max_iter=5000,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    threshold=1e-5\n",
    ")\n",
    "\n",
    "CLS = ['attention']\n",
    "SETTINGS = [\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_ns'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=True,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_os'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_ns'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=True,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_os'\n",
    "    )\n",
    "]\n",
    "\n",
    "with on_ray(num_cpus=12):\n",
    "    for l, s in product(\n",
    "        CLS, SETTINGS\n",
    "    ):\n",
    "        p = os.path.join(PATH_INTERMEDIATE, f'{l}.pkl')\n",
    "        par_dir = os.path.join(PATH_INTERMEDIATE, 'eval', l)\n",
    "        os.makedirs(par_dir, exist_ok=True)\n",
    "        \n",
    "        X, y, groups, t, datetimes = load(p)\n",
    "        cats = X.columns[X.dtypes == bool]\n",
    "        cross_val(\n",
    "            X=X, y=y, groups=groups,\n",
    "            path=par_dir,\n",
    "            categories=cats,\n",
    "            normalize=True,\n",
    "            split='stratifiedgroupkfold',\n",
    "            split_params={'n_splits': 3}, # logo시 삭제\n",
    "            random_state=RANDOM_STATE,\n",
    "            **s\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>value_count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>med</th>\n",
       "      <th>range</th>\n",
       "      <th>conf.</th>\n",
       "      <th>nan_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>split</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fold4:1, fold5:1, fold2:1, fold3:1, fold1:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>n_feature</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1395.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>(279, 279)</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>test_inst</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54999.000000</td>\n",
       "      <td>10999.800000</td>\n",
       "      <td>793.205333</td>\n",
       "      <td>11193.000000</td>\n",
       "      <td>(9996, 12012)</td>\n",
       "      <td>(10014.905495065195, 11984.694504934803)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>test_inst_0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27552.000000</td>\n",
       "      <td>5510.400000</td>\n",
       "      <td>928.119227</td>\n",
       "      <td>5859.000000</td>\n",
       "      <td>(4410, 6468)</td>\n",
       "      <td>(4357.987769477046, 6662.8122305229535)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention</td>\n",
       "      <td>logreg</td>\n",
       "      <td>test_inst_1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27447.000000</td>\n",
       "      <td>5489.400000</td>\n",
       "      <td>449.566791</td>\n",
       "      <td>5355.000000</td>\n",
       "      <td>(4893, 6027)</td>\n",
       "      <td>(4931.189100233543, 6047.610899766456)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>train_prauc_ref_0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>train_prauc_1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.995707</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>(0.9988779608069768, 0.9994428034779939)</td>\n",
       "      <td>(0.9988467297736084, 0.9994361946579394)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>train_prauc_ref_1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>train_log_loss</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.175303</td>\n",
       "      <td>0.035061</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.035515</td>\n",
       "      <td>(0.03215469923155882, 0.037891645428662635)</td>\n",
       "      <td>(0.03219804555252801, 0.03792321579713962)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>attention</td>\n",
       "      <td>xgb_os_kfold</td>\n",
       "      <td>train_brier_loss</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023001</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>(0.004131998959546725, 0.0050422757194056285)</td>\n",
       "      <td>(0.004125860140624047, 0.005074358032229038)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label           alg             metric  n  cardinality  \\\n",
       "0    attention        logreg              split  5          5.0   \n",
       "1    attention        logreg          n_feature  5          NaN   \n",
       "2    attention        logreg          test_inst  5          NaN   \n",
       "3    attention        logreg        test_inst_0  5          NaN   \n",
       "4    attention        logreg        test_inst_1  5          NaN   \n",
       "..         ...           ...                ... ..          ...   \n",
       "575  attention  xgb_os_kfold  train_prauc_ref_0  5          NaN   \n",
       "576  attention  xgb_os_kfold      train_prauc_1  5          NaN   \n",
       "577  attention  xgb_os_kfold  train_prauc_ref_1  5          NaN   \n",
       "578  attention  xgb_os_kfold     train_log_loss  5          NaN   \n",
       "579  attention  xgb_os_kfold   train_brier_loss  5          NaN   \n",
       "\n",
       "                                     value_count           sum          mean  \\\n",
       "0    fold4:1, fold5:1, fold2:1, fold3:1, fold1:1           NaN           NaN   \n",
       "1                                            NaN   1395.000000    279.000000   \n",
       "2                                            NaN  54999.000000  10999.800000   \n",
       "3                                            NaN  27552.000000   5510.400000   \n",
       "4                                            NaN  27447.000000   5489.400000   \n",
       "..                                           ...           ...           ...   \n",
       "575                                          NaN      2.500000      0.500000   \n",
       "576                                          NaN      4.995707      0.999141   \n",
       "577                                          NaN      2.500000      0.500000   \n",
       "578                                          NaN      0.175303      0.035061   \n",
       "579                                          NaN      0.023001      0.004600   \n",
       "\n",
       "             SD           med                                          range  \\\n",
       "0           NaN           NaN                                            NaN   \n",
       "1      0.000000    279.000000                                     (279, 279)   \n",
       "2    793.205333  11193.000000                                  (9996, 12012)   \n",
       "3    928.119227   5859.000000                                   (4410, 6468)   \n",
       "4    449.566791   5355.000000                                   (4893, 6027)   \n",
       "..          ...           ...                                            ...   \n",
       "575    0.000000      0.500000                                     (0.5, 0.5)   \n",
       "576    0.000237      0.999094       (0.9988779608069768, 0.9994428034779939)   \n",
       "577    0.000000      0.500000                                     (0.5, 0.5)   \n",
       "578    0.002305      0.035515    (0.03215469923155882, 0.037891645428662635)   \n",
       "579    0.000382      0.004698  (0.004131998959546725, 0.0050422757194056285)   \n",
       "\n",
       "                                            conf.  nan_count  \n",
       "0                                             NaN        NaN  \n",
       "1                                      (nan, nan)        0.0  \n",
       "2        (10014.905495065195, 11984.694504934803)        0.0  \n",
       "3         (4357.987769477046, 6662.8122305229535)        0.0  \n",
       "4          (4931.189100233543, 6047.610899766456)        0.0  \n",
       "..                                            ...        ...  \n",
       "575                                    (nan, nan)        0.0  \n",
       "576      (0.9988467297736084, 0.9994361946579394)        0.0  \n",
       "577                                    (nan, nan)        0.0  \n",
       "578    (0.03219804555252801, 0.03792321579713962)        0.0  \n",
       "579  (0.004125860140624047, 0.005074358032229038)        0.0  \n",
       "\n",
       "[580 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SUMMARY_EVAL = []\n",
    "\n",
    "for row in RESULTS_EVAL.groupby(\n",
    "    ['label', 'alg']\n",
    ").agg(summary).reset_index().itertuples():\n",
    "    for k, v in row._asdict().items():\n",
    "        if type(v) is dict:\n",
    "            r = dict(\n",
    "                label=row.label,\n",
    "                alg=row.alg,\n",
    "                metric=k,\n",
    "                **v\n",
    "            )\n",
    "            SUMMARY_EVAL.append(r)\n",
    "\n",
    "SUMMARY_EVAL = pd.DataFrame(SUMMARY_EVAL)    \n",
    "SUMMARY_EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows metrics of our interest only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"13\" halign=\"left\">mean_sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1_0</th>\n",
       "      <th>test_f1_1</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_inst_0</th>\n",
       "      <th>test_inst_1</th>\n",
       "      <th>train_class_ratio</th>\n",
       "      <th>train_f1_0</th>\n",
       "      <th>train_f1_1</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_inst_0</th>\n",
       "      <th>train_inst_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">attention</th>\n",
       "      <th>logreg</th>\n",
       "      <td>279.0 (0.0)</td>\n",
       "      <td>0.731 (0.02)</td>\n",
       "      <td>0.726 (0.034)</td>\n",
       "      <td>0.731 (0.034)</td>\n",
       "      <td>0.728 (0.018)</td>\n",
       "      <td>5510.4 (928.119)</td>\n",
       "      <td>5489.4 (449.567)</td>\n",
       "      <td>1.005 (0.056)</td>\n",
       "      <td>0.766 (0.008)</td>\n",
       "      <td>0.767 (0.009)</td>\n",
       "      <td>0.766 (0.005)</td>\n",
       "      <td>22041.6 (928.119)</td>\n",
       "      <td>21957.6 (449.567)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg_kfold</th>\n",
       "      <td>279.0 (0.0)</td>\n",
       "      <td>0.76 (0.006)</td>\n",
       "      <td>0.76 (0.006)</td>\n",
       "      <td>0.761 (0.006)</td>\n",
       "      <td>0.76 (0.006)</td>\n",
       "      <td>5510.4 (0.548)</td>\n",
       "      <td>5489.4 (0.548)</td>\n",
       "      <td>1.004 (0.0)</td>\n",
       "      <td>0.763 (0.001)</td>\n",
       "      <td>0.765 (0.001)</td>\n",
       "      <td>0.764 (0.001)</td>\n",
       "      <td>22041.6 (0.548)</td>\n",
       "      <td>21957.6 (0.548)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ns</th>\n",
       "      <td>183.2 (5.495)</td>\n",
       "      <td>0.734 (0.018)</td>\n",
       "      <td>0.685 (0.04)</td>\n",
       "      <td>0.767 (0.023)</td>\n",
       "      <td>0.726 (0.019)</td>\n",
       "      <td>5510.4 (928.119)</td>\n",
       "      <td>5489.4 (449.567)</td>\n",
       "      <td>1.005 (0.056)</td>\n",
       "      <td>0.775 (0.013)</td>\n",
       "      <td>0.825 (0.008)</td>\n",
       "      <td>0.8 (0.007)</td>\n",
       "      <td>22041.6 (928.119)</td>\n",
       "      <td>21957.6 (449.567)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ns_kfold</th>\n",
       "      <td>182.2 (1.789)</td>\n",
       "      <td>0.793 (0.006)</td>\n",
       "      <td>0.765 (0.011)</td>\n",
       "      <td>0.815 (0.003)</td>\n",
       "      <td>0.79 (0.007)</td>\n",
       "      <td>5510.4 (0.548)</td>\n",
       "      <td>5489.4 (0.548)</td>\n",
       "      <td>1.004 (0.0)</td>\n",
       "      <td>0.771 (0.005)</td>\n",
       "      <td>0.82 (0.003)</td>\n",
       "      <td>0.796 (0.002)</td>\n",
       "      <td>22041.6 (0.548)</td>\n",
       "      <td>21957.6 (0.548)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_os</th>\n",
       "      <td>183.2 (5.495)</td>\n",
       "      <td>0.732 (0.016)</td>\n",
       "      <td>0.682 (0.053)</td>\n",
       "      <td>0.764 (0.023)</td>\n",
       "      <td>0.723 (0.021)</td>\n",
       "      <td>5510.4 (928.119)</td>\n",
       "      <td>5489.4 (449.567)</td>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.778 (0.014)</td>\n",
       "      <td>0.827 (0.006)</td>\n",
       "      <td>0.803 (0.009)</td>\n",
       "      <td>22465.8 (616.807)</td>\n",
       "      <td>22465.8 (616.807)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_os_kfold</th>\n",
       "      <td>182.2 (1.789)</td>\n",
       "      <td>0.793 (0.005)</td>\n",
       "      <td>0.764 (0.01)</td>\n",
       "      <td>0.815 (0.003)</td>\n",
       "      <td>0.789 (0.006)</td>\n",
       "      <td>5510.4 (0.548)</td>\n",
       "      <td>5489.4 (0.548)</td>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.771 (0.004)</td>\n",
       "      <td>0.821 (0.002)</td>\n",
       "      <td>0.796 (0.002)</td>\n",
       "      <td>22041.6 (0.548)</td>\n",
       "      <td>22041.6 (0.548)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_ns</th>\n",
       "      <td>183.2 (5.495)</td>\n",
       "      <td>0.728 (0.015)</td>\n",
       "      <td>0.718 (0.022)</td>\n",
       "      <td>0.733 (0.034)</td>\n",
       "      <td>0.726 (0.013)</td>\n",
       "      <td>5510.4 (928.119)</td>\n",
       "      <td>5489.4 (449.567)</td>\n",
       "      <td>1.005 (0.056)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>22041.6 (928.119)</td>\n",
       "      <td>21957.6 (449.567)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_ns_kfold</th>\n",
       "      <td>182.2 (1.789)</td>\n",
       "      <td>0.99 (0.001)</td>\n",
       "      <td>0.99 (0.001)</td>\n",
       "      <td>0.99 (0.001)</td>\n",
       "      <td>0.99 (0.001)</td>\n",
       "      <td>5510.4 (0.548)</td>\n",
       "      <td>5489.4 (0.548)</td>\n",
       "      <td>1.004 (0.0)</td>\n",
       "      <td>0.997 (0.001)</td>\n",
       "      <td>0.997 (0.001)</td>\n",
       "      <td>0.997 (0.001)</td>\n",
       "      <td>22041.6 (0.548)</td>\n",
       "      <td>21957.6 (0.548)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_os</th>\n",
       "      <td>183.2 (5.495)</td>\n",
       "      <td>0.723 (0.009)</td>\n",
       "      <td>0.71 (0.032)</td>\n",
       "      <td>0.729 (0.031)</td>\n",
       "      <td>0.72 (0.008)</td>\n",
       "      <td>5510.4 (928.119)</td>\n",
       "      <td>5489.4 (449.567)</td>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.998 (0.0)</td>\n",
       "      <td>0.998 (0.0)</td>\n",
       "      <td>0.998 (0.0)</td>\n",
       "      <td>22465.8 (616.807)</td>\n",
       "      <td>22465.8 (616.807)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_os_kfold</th>\n",
       "      <td>182.2 (1.789)</td>\n",
       "      <td>0.991 (0.002)</td>\n",
       "      <td>0.991 (0.001)</td>\n",
       "      <td>0.991 (0.002)</td>\n",
       "      <td>0.991 (0.002)</td>\n",
       "      <td>5510.4 (0.548)</td>\n",
       "      <td>5489.4 (0.548)</td>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>0.997 (0.0)</td>\n",
       "      <td>22041.6 (0.548)</td>\n",
       "      <td>22041.6 (0.548)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean_sd                                \\\n",
       "metric                      n_feature       test_acc      test_f1_0   \n",
       "label     alg                                                         \n",
       "attention logreg          279.0 (0.0)   0.731 (0.02)  0.726 (0.034)   \n",
       "          logreg_kfold    279.0 (0.0)   0.76 (0.006)   0.76 (0.006)   \n",
       "          rf_ns         183.2 (5.495)  0.734 (0.018)   0.685 (0.04)   \n",
       "          rf_ns_kfold   182.2 (1.789)  0.793 (0.006)  0.765 (0.011)   \n",
       "          rf_os         183.2 (5.495)  0.732 (0.016)  0.682 (0.053)   \n",
       "          rf_os_kfold   182.2 (1.789)  0.793 (0.005)   0.764 (0.01)   \n",
       "          xgb_ns        183.2 (5.495)  0.728 (0.015)  0.718 (0.022)   \n",
       "          xgb_ns_kfold  182.2 (1.789)   0.99 (0.001)   0.99 (0.001)   \n",
       "          xgb_os        183.2 (5.495)  0.723 (0.009)   0.71 (0.032)   \n",
       "          xgb_os_kfold  182.2 (1.789)  0.991 (0.002)  0.991 (0.001)   \n",
       "\n",
       "                                                                        \\\n",
       "metric                      test_f1_1  test_f1_macro       test_inst_0   \n",
       "label     alg                                                            \n",
       "attention logreg        0.731 (0.034)  0.728 (0.018)  5510.4 (928.119)   \n",
       "          logreg_kfold  0.761 (0.006)   0.76 (0.006)    5510.4 (0.548)   \n",
       "          rf_ns         0.767 (0.023)  0.726 (0.019)  5510.4 (928.119)   \n",
       "          rf_ns_kfold   0.815 (0.003)   0.79 (0.007)    5510.4 (0.548)   \n",
       "          rf_os         0.764 (0.023)  0.723 (0.021)  5510.4 (928.119)   \n",
       "          rf_os_kfold   0.815 (0.003)  0.789 (0.006)    5510.4 (0.548)   \n",
       "          xgb_ns        0.733 (0.034)  0.726 (0.013)  5510.4 (928.119)   \n",
       "          xgb_ns_kfold   0.99 (0.001)   0.99 (0.001)    5510.4 (0.548)   \n",
       "          xgb_os        0.729 (0.031)   0.72 (0.008)  5510.4 (928.119)   \n",
       "          xgb_os_kfold  0.991 (0.002)  0.991 (0.002)    5510.4 (0.548)   \n",
       "\n",
       "                                                                           \\\n",
       "metric                       test_inst_1 train_class_ratio     train_f1_0   \n",
       "label     alg                                                               \n",
       "attention logreg        5489.4 (449.567)     1.005 (0.056)  0.766 (0.008)   \n",
       "          logreg_kfold    5489.4 (0.548)       1.004 (0.0)  0.763 (0.001)   \n",
       "          rf_ns         5489.4 (449.567)     1.005 (0.056)  0.775 (0.013)   \n",
       "          rf_ns_kfold     5489.4 (0.548)       1.004 (0.0)  0.771 (0.005)   \n",
       "          rf_os         5489.4 (449.567)         1.0 (0.0)  0.778 (0.014)   \n",
       "          rf_os_kfold     5489.4 (0.548)         1.0 (0.0)  0.771 (0.004)   \n",
       "          xgb_ns        5489.4 (449.567)     1.005 (0.056)    0.997 (0.0)   \n",
       "          xgb_ns_kfold    5489.4 (0.548)       1.004 (0.0)  0.997 (0.001)   \n",
       "          xgb_os        5489.4 (449.567)         1.0 (0.0)    0.998 (0.0)   \n",
       "          xgb_os_kfold    5489.4 (0.548)         1.0 (0.0)    0.997 (0.0)   \n",
       "\n",
       "                                                                         \\\n",
       "metric                     train_f1_1 train_f1_macro       train_inst_0   \n",
       "label     alg                                                             \n",
       "attention logreg        0.767 (0.009)  0.766 (0.005)  22041.6 (928.119)   \n",
       "          logreg_kfold  0.765 (0.001)  0.764 (0.001)    22041.6 (0.548)   \n",
       "          rf_ns         0.825 (0.008)    0.8 (0.007)  22041.6 (928.119)   \n",
       "          rf_ns_kfold    0.82 (0.003)  0.796 (0.002)    22041.6 (0.548)   \n",
       "          rf_os         0.827 (0.006)  0.803 (0.009)  22465.8 (616.807)   \n",
       "          rf_os_kfold   0.821 (0.002)  0.796 (0.002)    22041.6 (0.548)   \n",
       "          xgb_ns          0.997 (0.0)    0.997 (0.0)  22041.6 (928.119)   \n",
       "          xgb_ns_kfold  0.997 (0.001)  0.997 (0.001)    22041.6 (0.548)   \n",
       "          xgb_os          0.998 (0.0)    0.998 (0.0)  22465.8 (616.807)   \n",
       "          xgb_os_kfold    0.997 (0.0)    0.997 (0.0)    22041.6 (0.548)   \n",
       "\n",
       "                                           \n",
       "metric                       train_inst_1  \n",
       "label     alg                              \n",
       "attention logreg        21957.6 (449.567)  \n",
       "          logreg_kfold    21957.6 (0.548)  \n",
       "          rf_ns         21957.6 (449.567)  \n",
       "          rf_ns_kfold     21957.6 (0.548)  \n",
       "          rf_os         22465.8 (616.807)  \n",
       "          rf_os_kfold     22041.6 (0.548)  \n",
       "          xgb_ns        21957.6 (449.567)  \n",
       "          xgb_ns_kfold    21957.6 (0.548)  \n",
       "          xgb_os        22465.8 (616.807)  \n",
       "          xgb_os_kfold    22041.6 (0.548)  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUB_SUMMARY_EVAL = SUMMARY_EVAL.loc[\n",
    "    lambda x: x['metric'].isin(\n",
    "        ['n_feature', 'train_class_ratio', 'train_inst_0', 'train_inst_1', 'test_inst_0', 'test_inst_1', 'test_acc', 'test_f1_0' ,'test_f1_1', 'test_f1_macro', 'train_f1_0' ,'train_f1_1', 'train_f1_macro',]\n",
    "    )\n",
    "].round(3).assign(\n",
    "    mean_sd=lambda x: x['mean'].astype(str).str.cat(' (' + x['SD'].astype(str) + ')', sep='')\n",
    ").pivot(\n",
    "    index=['label', 'alg'], columns=['metric'], values=['mean_sd']\n",
    ")\n",
    "SUB_SUMMARY_EVAL.to_csv('./fig/SUB_SUMMARY_EVAL.csv')\n",
    "SUB_SUMMARY_EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "# ——— 1. FoldResult 객체 로드 ——————————————————————————————————\n",
    "dir_result = os.path.join(PATH_INTERMEDIATE, 'eval', 'attention')\n",
    "folds = []\n",
    "for fname in os.listdir(dir_result):\n",
    "    if not fname.endswith('.pkl') or 'proba' in fname:\n",
    "        continue\n",
    "    fold = load(os.path.join(dir_result, fname))\n",
    "    fold.name = os.path.splitext(fname)[0]   # ex: 'rf_ns#fold1'\n",
    "    folds.append(fold)\n",
    "\n",
    "# ——— 2. ROC/AUC 및 최적 threshold 계산 ——————————————————————————\n",
    "records = []\n",
    "fpr_map, tpr_map = {}, {}\n",
    "\n",
    "for fold in folds:\n",
    "    y_true = fold.y_test\n",
    "    # predict_proba vs decision_function\n",
    "    if hasattr(fold.estimator, \"predict_proba\"):\n",
    "        y_proba = fold.estimator.predict_proba(fold.X_test)[:,1]\n",
    "    elif hasattr(fold.estimator, \"decision_function\"):\n",
    "        scores  = fold.estimator.decision_function(fold.X_test)\n",
    "        y_proba = 1 / (1 + np.exp(-scores))\n",
    "    else:\n",
    "        raise RuntimeError(f\"{fold.name}에 predict_proba/decision_function 없음\")\n",
    "\n",
    "    alg = fold.name.split('#',1)[0]\n",
    "    # ROC/AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    roc_auc     = auc(fpr, tpr)\n",
    "    fpr_map[alg] = fpr\n",
    "    tpr_map[alg] = tpr\n",
    "\n",
    "    # F1 기준 최적 threshold\n",
    "    best_thresh, best_f1 = 0.5, 0\n",
    "    for t in np.linspace(0,1,101):\n",
    "        f1 = f1_score(y_true, (y_proba>=t).astype(int))\n",
    "        if f1>best_f1:\n",
    "            best_f1, best_thresh = f1, t\n",
    "\n",
    "    y_pred = (y_proba>=best_thresh).astype(int)\n",
    "    prec   = precision_score(y_true, y_pred)\n",
    "    rec    = recall_score(y_true, y_pred)\n",
    "\n",
    "    records.append({\n",
    "        \"label\":      os.path.basename(dir_result),  # 'attention'\n",
    "        \"alg\":        alg,\n",
    "        \"roc_auc\":    roc_auc,\n",
    "        \"best_thresh\":best_thresh,\n",
    "        \"precision\":  prec,\n",
    "        \"recall\":     rec,\n",
    "        \"f1\":         best_f1\n",
    "    })\n",
    "\n",
    "df_thresh = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/s4x3th851w574ph7qygky7xc0000gn/T/ipykernel_20404/3148654761.py:15: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (이전까지 준비해둔 fpr_map, tpr_map, df_thresh 이용)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for _, row in df_thresh.iterrows():\n",
    "    alg = row[\"alg\"]\n",
    "    plt.plot(fpr_map[alg], tpr_map[alg],\n",
    "             label=f\"{alg} (AUC={row['roc_auc']:.2f})\")\n",
    "plt.plot([0,1], [0,1], 'k--', lw=1)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves by Algorithm\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de742 th {\n",
       "  background-color: #F0F0F0;\n",
       "}\n",
       "#T_de742 td {\n",
       "  padding: 4px 8px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de742\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_de742_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_de742_level0_col1\" class=\"col_heading level0 col1\" >alg</th>\n",
       "      <th id=\"T_de742_level0_col2\" class=\"col_heading level0 col2\" >roc_auc</th>\n",
       "      <th id=\"T_de742_level0_col3\" class=\"col_heading level0 col3\" >best_thresh</th>\n",
       "      <th id=\"T_de742_level0_col4\" class=\"col_heading level0 col4\" >precision</th>\n",
       "      <th id=\"T_de742_level0_col5\" class=\"col_heading level0 col5\" >recall</th>\n",
       "      <th id=\"T_de742_level0_col6\" class=\"col_heading level0 col6\" >f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row0_col0\" class=\"data row0 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row0_col1\" class=\"data row0 col1\" >rf_os</td>\n",
       "      <td id=\"T_de742_row0_col2\" class=\"data row0 col2\" >0.815</td>\n",
       "      <td id=\"T_de742_row0_col3\" class=\"data row0 col3\" >0.36</td>\n",
       "      <td id=\"T_de742_row0_col4\" class=\"data row0 col4\" >0.687</td>\n",
       "      <td id=\"T_de742_row0_col5\" class=\"data row0 col5\" >0.988</td>\n",
       "      <td id=\"T_de742_row0_col6\" class=\"data row0 col6\" >0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row1_col0\" class=\"data row1 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row1_col1\" class=\"data row1 col1\" >xgb_os</td>\n",
       "      <td id=\"T_de742_row1_col2\" class=\"data row1 col2\" >0.826</td>\n",
       "      <td id=\"T_de742_row1_col3\" class=\"data row1 col3\" >0.30</td>\n",
       "      <td id=\"T_de742_row1_col4\" class=\"data row1 col4\" >0.688</td>\n",
       "      <td id=\"T_de742_row1_col5\" class=\"data row1 col5\" >0.849</td>\n",
       "      <td id=\"T_de742_row1_col6\" class=\"data row1 col6\" >0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row2_col0\" class=\"data row2 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row2_col1\" class=\"data row2 col1\" >rf_ns_kfold</td>\n",
       "      <td id=\"T_de742_row2_col2\" class=\"data row2 col2\" >0.893</td>\n",
       "      <td id=\"T_de742_row2_col3\" class=\"data row2 col3\" >0.50</td>\n",
       "      <td id=\"T_de742_row2_col4\" class=\"data row2 col4\" >0.735</td>\n",
       "      <td id=\"T_de742_row2_col5\" class=\"data row2 col5\" >0.923</td>\n",
       "      <td id=\"T_de742_row2_col6\" class=\"data row2 col6\" >0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row3_col0\" class=\"data row3 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row3_col1\" class=\"data row3 col1\" >xgb_os</td>\n",
       "      <td id=\"T_de742_row3_col2\" class=\"data row3 col2\" >0.842</td>\n",
       "      <td id=\"T_de742_row3_col3\" class=\"data row3 col3\" >0.30</td>\n",
       "      <td id=\"T_de742_row3_col4\" class=\"data row3 col4\" >0.681</td>\n",
       "      <td id=\"T_de742_row3_col5\" class=\"data row3 col5\" >0.862</td>\n",
       "      <td id=\"T_de742_row3_col6\" class=\"data row3 col6\" >0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row4_col0\" class=\"data row4 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row4_col1\" class=\"data row4 col1\" >rf_os</td>\n",
       "      <td id=\"T_de742_row4_col2\" class=\"data row4 col2\" >0.809</td>\n",
       "      <td id=\"T_de742_row4_col3\" class=\"data row4 col3\" >0.38</td>\n",
       "      <td id=\"T_de742_row4_col4\" class=\"data row4 col4\" >0.653</td>\n",
       "      <td id=\"T_de742_row4_col5\" class=\"data row4 col5\" >0.980</td>\n",
       "      <td id=\"T_de742_row4_col6\" class=\"data row4 col6\" >0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row5_col0\" class=\"data row5 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row5_col1\" class=\"data row5 col1\" >rf_ns_kfold</td>\n",
       "      <td id=\"T_de742_row5_col2\" class=\"data row5 col2\" >0.890</td>\n",
       "      <td id=\"T_de742_row5_col3\" class=\"data row5 col3\" >0.51</td>\n",
       "      <td id=\"T_de742_row5_col4\" class=\"data row5 col4\" >0.734</td>\n",
       "      <td id=\"T_de742_row5_col5\" class=\"data row5 col5\" >0.912</td>\n",
       "      <td id=\"T_de742_row5_col6\" class=\"data row5 col6\" >0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row6_col0\" class=\"data row6 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row6_col1\" class=\"data row6 col1\" >xgb_ns_kfold</td>\n",
       "      <td id=\"T_de742_row6_col2\" class=\"data row6 col2\" >0.997</td>\n",
       "      <td id=\"T_de742_row6_col3\" class=\"data row6 col3\" >0.43</td>\n",
       "      <td id=\"T_de742_row6_col4\" class=\"data row6 col4\" >0.995</td>\n",
       "      <td id=\"T_de742_row6_col5\" class=\"data row6 col5\" >0.989</td>\n",
       "      <td id=\"T_de742_row6_col6\" class=\"data row6 col6\" >0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row7_col0\" class=\"data row7 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row7_col1\" class=\"data row7 col1\" >xgb_ns_kfold</td>\n",
       "      <td id=\"T_de742_row7_col2\" class=\"data row7 col2\" >0.996</td>\n",
       "      <td id=\"T_de742_row7_col3\" class=\"data row7 col3\" >0.48</td>\n",
       "      <td id=\"T_de742_row7_col4\" class=\"data row7 col4\" >0.993</td>\n",
       "      <td id=\"T_de742_row7_col5\" class=\"data row7 col5\" >0.990</td>\n",
       "      <td id=\"T_de742_row7_col6\" class=\"data row7 col6\" >0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row8_col0\" class=\"data row8 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row8_col1\" class=\"data row8 col1\" >rf_ns_kfold</td>\n",
       "      <td id=\"T_de742_row8_col2\" class=\"data row8 col2\" >0.890</td>\n",
       "      <td id=\"T_de742_row8_col3\" class=\"data row8 col3\" >0.49</td>\n",
       "      <td id=\"T_de742_row8_col4\" class=\"data row8 col4\" >0.727</td>\n",
       "      <td id=\"T_de742_row8_col5\" class=\"data row8 col5\" >0.928</td>\n",
       "      <td id=\"T_de742_row8_col6\" class=\"data row8 col6\" >0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row9_col0\" class=\"data row9 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row9_col1\" class=\"data row9 col1\" >xgb_os</td>\n",
       "      <td id=\"T_de742_row9_col2\" class=\"data row9 col2\" >0.812</td>\n",
       "      <td id=\"T_de742_row9_col3\" class=\"data row9 col3\" >0.16</td>\n",
       "      <td id=\"T_de742_row9_col4\" class=\"data row9 col4\" >0.654</td>\n",
       "      <td id=\"T_de742_row9_col5\" class=\"data row9 col5\" >0.910</td>\n",
       "      <td id=\"T_de742_row9_col6\" class=\"data row9 col6\" >0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row10_col0\" class=\"data row10 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row10_col1\" class=\"data row10 col1\" >rf_os</td>\n",
       "      <td id=\"T_de742_row10_col2\" class=\"data row10 col2\" >0.844</td>\n",
       "      <td id=\"T_de742_row10_col3\" class=\"data row10 col3\" >0.49</td>\n",
       "      <td id=\"T_de742_row10_col4\" class=\"data row10 col4\" >0.666</td>\n",
       "      <td id=\"T_de742_row10_col5\" class=\"data row10 col5\" >0.942</td>\n",
       "      <td id=\"T_de742_row10_col6\" class=\"data row10 col6\" >0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row11_col0\" class=\"data row11 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row11_col1\" class=\"data row11 col1\" >xgb_os</td>\n",
       "      <td id=\"T_de742_row11_col2\" class=\"data row11 col2\" >0.803</td>\n",
       "      <td id=\"T_de742_row11_col3\" class=\"data row11 col3\" >0.14</td>\n",
       "      <td id=\"T_de742_row11_col4\" class=\"data row11 col4\" >0.656</td>\n",
       "      <td id=\"T_de742_row11_col5\" class=\"data row11 col5\" >0.883</td>\n",
       "      <td id=\"T_de742_row11_col6\" class=\"data row11 col6\" >0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row12_col0\" class=\"data row12 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row12_col1\" class=\"data row12 col1\" >xgb_ns_kfold</td>\n",
       "      <td id=\"T_de742_row12_col2\" class=\"data row12 col2\" >0.994</td>\n",
       "      <td id=\"T_de742_row12_col3\" class=\"data row12 col3\" >0.47</td>\n",
       "      <td id=\"T_de742_row12_col4\" class=\"data row12 col4\" >0.993</td>\n",
       "      <td id=\"T_de742_row12_col5\" class=\"data row12 col5\" >0.984</td>\n",
       "      <td id=\"T_de742_row12_col6\" class=\"data row12 col6\" >0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row13_col0\" class=\"data row13 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row13_col1\" class=\"data row13 col1\" >xgb_os</td>\n",
       "      <td id=\"T_de742_row13_col2\" class=\"data row13 col2\" >0.828</td>\n",
       "      <td id=\"T_de742_row13_col3\" class=\"data row13 col3\" >0.09</td>\n",
       "      <td id=\"T_de742_row13_col4\" class=\"data row13 col4\" >0.690</td>\n",
       "      <td id=\"T_de742_row13_col5\" class=\"data row13 col5\" >0.944</td>\n",
       "      <td id=\"T_de742_row13_col6\" class=\"data row13 col6\" >0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row14_col0\" class=\"data row14 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row14_col1\" class=\"data row14 col1\" >rf_os</td>\n",
       "      <td id=\"T_de742_row14_col2\" class=\"data row14 col2\" >0.835</td>\n",
       "      <td id=\"T_de742_row14_col3\" class=\"data row14 col3\" >0.42</td>\n",
       "      <td id=\"T_de742_row14_col4\" class=\"data row14 col4\" >0.654</td>\n",
       "      <td id=\"T_de742_row14_col5\" class=\"data row14 col5\" >0.979</td>\n",
       "      <td id=\"T_de742_row14_col6\" class=\"data row14 col6\" >0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row15_col0\" class=\"data row15 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row15_col1\" class=\"data row15 col1\" >rf_os</td>\n",
       "      <td id=\"T_de742_row15_col2\" class=\"data row15 col2\" >0.753</td>\n",
       "      <td id=\"T_de742_row15_col3\" class=\"data row15 col3\" >0.44</td>\n",
       "      <td id=\"T_de742_row15_col4\" class=\"data row15 col4\" >0.647</td>\n",
       "      <td id=\"T_de742_row15_col5\" class=\"data row15 col5\" >0.879</td>\n",
       "      <td id=\"T_de742_row15_col6\" class=\"data row15 col6\" >0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row16_col0\" class=\"data row16 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row16_col1\" class=\"data row16 col1\" >xgb_ns_kfold</td>\n",
       "      <td id=\"T_de742_row16_col2\" class=\"data row16 col2\" >0.996</td>\n",
       "      <td id=\"T_de742_row16_col3\" class=\"data row16 col3\" >0.52</td>\n",
       "      <td id=\"T_de742_row16_col4\" class=\"data row16 col4\" >0.997</td>\n",
       "      <td id=\"T_de742_row16_col5\" class=\"data row16 col5\" >0.986</td>\n",
       "      <td id=\"T_de742_row16_col6\" class=\"data row16 col6\" >0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row17_col0\" class=\"data row17 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row17_col1\" class=\"data row17 col1\" >rf_ns_kfold</td>\n",
       "      <td id=\"T_de742_row17_col2\" class=\"data row17 col2\" >0.888</td>\n",
       "      <td id=\"T_de742_row17_col3\" class=\"data row17 col3\" >0.49</td>\n",
       "      <td id=\"T_de742_row17_col4\" class=\"data row17 col4\" >0.742</td>\n",
       "      <td id=\"T_de742_row17_col5\" class=\"data row17 col5\" >0.921</td>\n",
       "      <td id=\"T_de742_row17_col6\" class=\"data row17 col6\" >0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row18_col0\" class=\"data row18 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row18_col1\" class=\"data row18 col1\" >rf_ns_kfold</td>\n",
       "      <td id=\"T_de742_row18_col2\" class=\"data row18 col2\" >0.890</td>\n",
       "      <td id=\"T_de742_row18_col3\" class=\"data row18 col3\" >0.51</td>\n",
       "      <td id=\"T_de742_row18_col4\" class=\"data row18 col4\" >0.743</td>\n",
       "      <td id=\"T_de742_row18_col5\" class=\"data row18 col5\" >0.895</td>\n",
       "      <td id=\"T_de742_row18_col6\" class=\"data row18 col6\" >0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row19_col0\" class=\"data row19 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row19_col1\" class=\"data row19 col1\" >xgb_ns_kfold</td>\n",
       "      <td id=\"T_de742_row19_col2\" class=\"data row19 col2\" >0.995</td>\n",
       "      <td id=\"T_de742_row19_col3\" class=\"data row19 col3\" >0.47</td>\n",
       "      <td id=\"T_de742_row19_col4\" class=\"data row19 col4\" >0.993</td>\n",
       "      <td id=\"T_de742_row19_col5\" class=\"data row19 col5\" >0.987</td>\n",
       "      <td id=\"T_de742_row19_col6\" class=\"data row19 col6\" >0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row20_col0\" class=\"data row20 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row20_col1\" class=\"data row20 col1\" >rf_os_kfold</td>\n",
       "      <td id=\"T_de742_row20_col2\" class=\"data row20 col2\" >0.893</td>\n",
       "      <td id=\"T_de742_row20_col3\" class=\"data row20 col3\" >0.50</td>\n",
       "      <td id=\"T_de742_row20_col4\" class=\"data row20 col4\" >0.735</td>\n",
       "      <td id=\"T_de742_row20_col5\" class=\"data row20 col5\" >0.921</td>\n",
       "      <td id=\"T_de742_row20_col6\" class=\"data row20 col6\" >0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row21_col0\" class=\"data row21 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row21_col1\" class=\"data row21 col1\" >logreg_kfold</td>\n",
       "      <td id=\"T_de742_row21_col2\" class=\"data row21 col2\" >0.849</td>\n",
       "      <td id=\"T_de742_row21_col3\" class=\"data row21 col3\" >0.34</td>\n",
       "      <td id=\"T_de742_row21_col4\" class=\"data row21 col4\" >0.704</td>\n",
       "      <td id=\"T_de742_row21_col5\" class=\"data row21 col5\" >0.877</td>\n",
       "      <td id=\"T_de742_row21_col6\" class=\"data row21 col6\" >0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row22_col0\" class=\"data row22 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row22_col1\" class=\"data row22 col1\" >rf_os_kfold</td>\n",
       "      <td id=\"T_de742_row22_col2\" class=\"data row22 col2\" >0.890</td>\n",
       "      <td id=\"T_de742_row22_col3\" class=\"data row22 col3\" >0.49</td>\n",
       "      <td id=\"T_de742_row22_col4\" class=\"data row22 col4\" >0.726</td>\n",
       "      <td id=\"T_de742_row22_col5\" class=\"data row22 col5\" >0.929</td>\n",
       "      <td id=\"T_de742_row22_col6\" class=\"data row22 col6\" >0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row23_col0\" class=\"data row23 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row23_col1\" class=\"data row23 col1\" >xgb_os_kfold</td>\n",
       "      <td id=\"T_de742_row23_col2\" class=\"data row23 col2\" >0.996</td>\n",
       "      <td id=\"T_de742_row23_col3\" class=\"data row23 col3\" >0.52</td>\n",
       "      <td id=\"T_de742_row23_col4\" class=\"data row23 col4\" >0.994</td>\n",
       "      <td id=\"T_de742_row23_col5\" class=\"data row23 col5\" >0.989</td>\n",
       "      <td id=\"T_de742_row23_col6\" class=\"data row23 col6\" >0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row24_col0\" class=\"data row24 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row24_col1\" class=\"data row24 col1\" >logreg_kfold</td>\n",
       "      <td id=\"T_de742_row24_col2\" class=\"data row24 col2\" >0.849</td>\n",
       "      <td id=\"T_de742_row24_col3\" class=\"data row24 col3\" >0.33</td>\n",
       "      <td id=\"T_de742_row24_col4\" class=\"data row24 col4\" >0.695</td>\n",
       "      <td id=\"T_de742_row24_col5\" class=\"data row24 col5\" >0.882</td>\n",
       "      <td id=\"T_de742_row24_col6\" class=\"data row24 col6\" >0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row25_col0\" class=\"data row25 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row25_col1\" class=\"data row25 col1\" >logreg_kfold</td>\n",
       "      <td id=\"T_de742_row25_col2\" class=\"data row25 col2\" >0.841</td>\n",
       "      <td id=\"T_de742_row25_col3\" class=\"data row25 col3\" >0.28</td>\n",
       "      <td id=\"T_de742_row25_col4\" class=\"data row25 col4\" >0.673</td>\n",
       "      <td id=\"T_de742_row25_col5\" class=\"data row25 col5\" >0.906</td>\n",
       "      <td id=\"T_de742_row25_col6\" class=\"data row25 col6\" >0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row26_col0\" class=\"data row26 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row26_col1\" class=\"data row26 col1\" >xgb_os_kfold</td>\n",
       "      <td id=\"T_de742_row26_col2\" class=\"data row26 col2\" >0.996</td>\n",
       "      <td id=\"T_de742_row26_col3\" class=\"data row26 col3\" >0.35</td>\n",
       "      <td id=\"T_de742_row26_col4\" class=\"data row26 col4\" >0.993</td>\n",
       "      <td id=\"T_de742_row26_col5\" class=\"data row26 col5\" >0.991</td>\n",
       "      <td id=\"T_de742_row26_col6\" class=\"data row26 col6\" >0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row27_col0\" class=\"data row27 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row27_col1\" class=\"data row27 col1\" >rf_os_kfold</td>\n",
       "      <td id=\"T_de742_row27_col2\" class=\"data row27 col2\" >0.890</td>\n",
       "      <td id=\"T_de742_row27_col3\" class=\"data row27 col3\" >0.51</td>\n",
       "      <td id=\"T_de742_row27_col4\" class=\"data row27 col4\" >0.736</td>\n",
       "      <td id=\"T_de742_row27_col5\" class=\"data row27 col5\" >0.913</td>\n",
       "      <td id=\"T_de742_row27_col6\" class=\"data row27 col6\" >0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row28_col0\" class=\"data row28 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row28_col1\" class=\"data row28 col1\" >xgb_os_kfold</td>\n",
       "      <td id=\"T_de742_row28_col2\" class=\"data row28 col2\" >0.995</td>\n",
       "      <td id=\"T_de742_row28_col3\" class=\"data row28 col3\" >0.40</td>\n",
       "      <td id=\"T_de742_row28_col4\" class=\"data row28 col4\" >0.992</td>\n",
       "      <td id=\"T_de742_row28_col5\" class=\"data row28 col5\" >0.985</td>\n",
       "      <td id=\"T_de742_row28_col6\" class=\"data row28 col6\" >0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row29_col0\" class=\"data row29 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row29_col1\" class=\"data row29 col1\" >xgb_os_kfold</td>\n",
       "      <td id=\"T_de742_row29_col2\" class=\"data row29 col2\" >0.996</td>\n",
       "      <td id=\"T_de742_row29_col3\" class=\"data row29 col3\" >0.45</td>\n",
       "      <td id=\"T_de742_row29_col4\" class=\"data row29 col4\" >0.993</td>\n",
       "      <td id=\"T_de742_row29_col5\" class=\"data row29 col5\" >0.989</td>\n",
       "      <td id=\"T_de742_row29_col6\" class=\"data row29 col6\" >0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row30_col0\" class=\"data row30 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row30_col1\" class=\"data row30 col1\" >rf_os_kfold</td>\n",
       "      <td id=\"T_de742_row30_col2\" class=\"data row30 col2\" >0.890</td>\n",
       "      <td id=\"T_de742_row30_col3\" class=\"data row30 col3\" >0.50</td>\n",
       "      <td id=\"T_de742_row30_col4\" class=\"data row30 col4\" >0.730</td>\n",
       "      <td id=\"T_de742_row30_col5\" class=\"data row30 col5\" >0.920</td>\n",
       "      <td id=\"T_de742_row30_col6\" class=\"data row30 col6\" >0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row31_col0\" class=\"data row31 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row31_col1\" class=\"data row31 col1\" >logreg_kfold</td>\n",
       "      <td id=\"T_de742_row31_col2\" class=\"data row31 col2\" >0.846</td>\n",
       "      <td id=\"T_de742_row31_col3\" class=\"data row31 col3\" >0.29</td>\n",
       "      <td id=\"T_de742_row31_col4\" class=\"data row31 col4\" >0.678</td>\n",
       "      <td id=\"T_de742_row31_col5\" class=\"data row31 col5\" >0.905</td>\n",
       "      <td id=\"T_de742_row31_col6\" class=\"data row31 col6\" >0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row32_col0\" class=\"data row32 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row32_col1\" class=\"data row32 col1\" >logreg_kfold</td>\n",
       "      <td id=\"T_de742_row32_col2\" class=\"data row32 col2\" >0.848</td>\n",
       "      <td id=\"T_de742_row32_col3\" class=\"data row32 col3\" >0.32</td>\n",
       "      <td id=\"T_de742_row32_col4\" class=\"data row32 col4\" >0.696</td>\n",
       "      <td id=\"T_de742_row32_col5\" class=\"data row32 col5\" >0.886</td>\n",
       "      <td id=\"T_de742_row32_col6\" class=\"data row32 col6\" >0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row33_col0\" class=\"data row33 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row33_col1\" class=\"data row33 col1\" >rf_os_kfold</td>\n",
       "      <td id=\"T_de742_row33_col2\" class=\"data row33 col2\" >0.887</td>\n",
       "      <td id=\"T_de742_row33_col3\" class=\"data row33 col3\" >0.48</td>\n",
       "      <td id=\"T_de742_row33_col4\" class=\"data row33 col4\" >0.727</td>\n",
       "      <td id=\"T_de742_row33_col5\" class=\"data row33 col5\" >0.939</td>\n",
       "      <td id=\"T_de742_row33_col6\" class=\"data row33 col6\" >0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row34_col0\" class=\"data row34 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row34_col1\" class=\"data row34 col1\" >xgb_os_kfold</td>\n",
       "      <td id=\"T_de742_row34_col2\" class=\"data row34 col2\" >0.996</td>\n",
       "      <td id=\"T_de742_row34_col3\" class=\"data row34 col3\" >0.42</td>\n",
       "      <td id=\"T_de742_row34_col4\" class=\"data row34 col4\" >0.996</td>\n",
       "      <td id=\"T_de742_row34_col5\" class=\"data row34 col5\" >0.989</td>\n",
       "      <td id=\"T_de742_row34_col6\" class=\"data row34 col6\" >0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row35_col0\" class=\"data row35 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row35_col1\" class=\"data row35 col1\" >rf_ns</td>\n",
       "      <td id=\"T_de742_row35_col2\" class=\"data row35 col2\" >0.846</td>\n",
       "      <td id=\"T_de742_row35_col3\" class=\"data row35 col3\" >0.48</td>\n",
       "      <td id=\"T_de742_row35_col4\" class=\"data row35 col4\" >0.663</td>\n",
       "      <td id=\"T_de742_row35_col5\" class=\"data row35 col5\" >0.959</td>\n",
       "      <td id=\"T_de742_row35_col6\" class=\"data row35 col6\" >0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row36_col0\" class=\"data row36 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row36_col1\" class=\"data row36 col1\" >xgb_ns</td>\n",
       "      <td id=\"T_de742_row36_col2\" class=\"data row36 col2\" >0.815</td>\n",
       "      <td id=\"T_de742_row36_col3\" class=\"data row36 col3\" >0.25</td>\n",
       "      <td id=\"T_de742_row36_col4\" class=\"data row36 col4\" >0.693</td>\n",
       "      <td id=\"T_de742_row36_col5\" class=\"data row36 col5\" >0.839</td>\n",
       "      <td id=\"T_de742_row36_col6\" class=\"data row36 col6\" >0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row37_col0\" class=\"data row37 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row37_col1\" class=\"data row37 col1\" >logreg</td>\n",
       "      <td id=\"T_de742_row37_col2\" class=\"data row37 col2\" >0.821</td>\n",
       "      <td id=\"T_de742_row37_col3\" class=\"data row37 col3\" >0.38</td>\n",
       "      <td id=\"T_de742_row37_col4\" class=\"data row37 col4\" >0.745</td>\n",
       "      <td id=\"T_de742_row37_col5\" class=\"data row37 col5\" >0.860</td>\n",
       "      <td id=\"T_de742_row37_col6\" class=\"data row37 col6\" >0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row38_col0\" class=\"data row38 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row38_col1\" class=\"data row38 col1\" >logreg</td>\n",
       "      <td id=\"T_de742_row38_col2\" class=\"data row38 col2\" >0.778</td>\n",
       "      <td id=\"T_de742_row38_col3\" class=\"data row38 col3\" >0.20</td>\n",
       "      <td id=\"T_de742_row38_col4\" class=\"data row38 col4\" >0.645</td>\n",
       "      <td id=\"T_de742_row38_col5\" class=\"data row38 col5\" >0.903</td>\n",
       "      <td id=\"T_de742_row38_col6\" class=\"data row38 col6\" >0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row39_col0\" class=\"data row39 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row39_col1\" class=\"data row39 col1\" >xgb_ns</td>\n",
       "      <td id=\"T_de742_row39_col2\" class=\"data row39 col2\" >0.844</td>\n",
       "      <td id=\"T_de742_row39_col3\" class=\"data row39 col3\" >0.09</td>\n",
       "      <td id=\"T_de742_row39_col4\" class=\"data row39 col4\" >0.694</td>\n",
       "      <td id=\"T_de742_row39_col5\" class=\"data row39 col5\" >0.963</td>\n",
       "      <td id=\"T_de742_row39_col6\" class=\"data row39 col6\" >0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row40_col0\" class=\"data row40 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row40_col1\" class=\"data row40 col1\" >rf_ns</td>\n",
       "      <td id=\"T_de742_row40_col2\" class=\"data row40 col2\" >0.834</td>\n",
       "      <td id=\"T_de742_row40_col3\" class=\"data row40 col3\" >0.40</td>\n",
       "      <td id=\"T_de742_row40_col4\" class=\"data row40 col4\" >0.652</td>\n",
       "      <td id=\"T_de742_row40_col5\" class=\"data row40 col5\" >0.983</td>\n",
       "      <td id=\"T_de742_row40_col6\" class=\"data row40 col6\" >0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row41_col0\" class=\"data row41 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row41_col1\" class=\"data row41 col1\" >rf_ns</td>\n",
       "      <td id=\"T_de742_row41_col2\" class=\"data row41 col2\" >0.748</td>\n",
       "      <td id=\"T_de742_row41_col3\" class=\"data row41 col3\" >0.44</td>\n",
       "      <td id=\"T_de742_row41_col4\" class=\"data row41 col4\" >0.651</td>\n",
       "      <td id=\"T_de742_row41_col5\" class=\"data row41 col5\" >0.880</td>\n",
       "      <td id=\"T_de742_row41_col6\" class=\"data row41 col6\" >0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row42_col0\" class=\"data row42 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row42_col1\" class=\"data row42 col1\" >rf_ns</td>\n",
       "      <td id=\"T_de742_row42_col2\" class=\"data row42 col2\" >0.816</td>\n",
       "      <td id=\"T_de742_row42_col3\" class=\"data row42 col3\" >0.38</td>\n",
       "      <td id=\"T_de742_row42_col4\" class=\"data row42 col4\" >0.694</td>\n",
       "      <td id=\"T_de742_row42_col5\" class=\"data row42 col5\" >0.971</td>\n",
       "      <td id=\"T_de742_row42_col6\" class=\"data row42 col6\" >0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row43_col0\" class=\"data row43 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row43_col1\" class=\"data row43 col1\" >xgb_ns</td>\n",
       "      <td id=\"T_de742_row43_col2\" class=\"data row43 col2\" >0.815</td>\n",
       "      <td id=\"T_de742_row43_col3\" class=\"data row43 col3\" >0.13</td>\n",
       "      <td id=\"T_de742_row43_col4\" class=\"data row43 col4\" >0.641</td>\n",
       "      <td id=\"T_de742_row43_col5\" class=\"data row43 col5\" >0.912</td>\n",
       "      <td id=\"T_de742_row43_col6\" class=\"data row43 col6\" >0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row44_col0\" class=\"data row44 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row44_col1\" class=\"data row44 col1\" >logreg</td>\n",
       "      <td id=\"T_de742_row44_col2\" class=\"data row44 col2\" >0.814</td>\n",
       "      <td id=\"T_de742_row44_col3\" class=\"data row44 col3\" >0.37</td>\n",
       "      <td id=\"T_de742_row44_col4\" class=\"data row44 col4\" >0.641</td>\n",
       "      <td id=\"T_de742_row44_col5\" class=\"data row44 col5\" >0.814</td>\n",
       "      <td id=\"T_de742_row44_col6\" class=\"data row44 col6\" >0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row45_col0\" class=\"data row45 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row45_col1\" class=\"data row45 col1\" >logreg</td>\n",
       "      <td id=\"T_de742_row45_col2\" class=\"data row45 col2\" >0.809</td>\n",
       "      <td id=\"T_de742_row45_col3\" class=\"data row45 col3\" >0.32</td>\n",
       "      <td id=\"T_de742_row45_col4\" class=\"data row45 col4\" >0.673</td>\n",
       "      <td id=\"T_de742_row45_col5\" class=\"data row45 col5\" >0.865</td>\n",
       "      <td id=\"T_de742_row45_col6\" class=\"data row45 col6\" >0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row46_col0\" class=\"data row46 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row46_col1\" class=\"data row46 col1\" >xgb_ns</td>\n",
       "      <td id=\"T_de742_row46_col2\" class=\"data row46 col2\" >0.840</td>\n",
       "      <td id=\"T_de742_row46_col3\" class=\"data row46 col3\" >0.11</td>\n",
       "      <td id=\"T_de742_row46_col4\" class=\"data row46 col4\" >0.629</td>\n",
       "      <td id=\"T_de742_row46_col5\" class=\"data row46 col5\" >0.951</td>\n",
       "      <td id=\"T_de742_row46_col6\" class=\"data row46 col6\" >0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row47_col0\" class=\"data row47 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row47_col1\" class=\"data row47 col1\" >rf_ns</td>\n",
       "      <td id=\"T_de742_row47_col2\" class=\"data row47 col2\" >0.803</td>\n",
       "      <td id=\"T_de742_row47_col3\" class=\"data row47 col3\" >0.37</td>\n",
       "      <td id=\"T_de742_row47_col4\" class=\"data row47 col4\" >0.652</td>\n",
       "      <td id=\"T_de742_row47_col5\" class=\"data row47 col5\" >0.981</td>\n",
       "      <td id=\"T_de742_row47_col6\" class=\"data row47 col6\" >0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row48_col0\" class=\"data row48 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row48_col1\" class=\"data row48 col1\" >logreg</td>\n",
       "      <td id=\"T_de742_row48_col2\" class=\"data row48 col2\" >0.814</td>\n",
       "      <td id=\"T_de742_row48_col3\" class=\"data row48 col3\" >0.31</td>\n",
       "      <td id=\"T_de742_row48_col4\" class=\"data row48 col4\" >0.657</td>\n",
       "      <td id=\"T_de742_row48_col5\" class=\"data row48 col5\" >0.895</td>\n",
       "      <td id=\"T_de742_row48_col6\" class=\"data row48 col6\" >0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de742_row49_col0\" class=\"data row49 col0\" >attention</td>\n",
       "      <td id=\"T_de742_row49_col1\" class=\"data row49 col1\" >xgb_ns</td>\n",
       "      <td id=\"T_de742_row49_col2\" class=\"data row49 col2\" >0.817</td>\n",
       "      <td id=\"T_de742_row49_col3\" class=\"data row49 col3\" >0.21</td>\n",
       "      <td id=\"T_de742_row49_col4\" class=\"data row49 col4\" >0.670</td>\n",
       "      <td id=\"T_de742_row49_col5\" class=\"data row49 col5\" >0.890</td>\n",
       "      <td id=\"T_de742_row49_col6\" class=\"data row49 col6\" >0.764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d217ac10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) label 과 alg 를 컬럼으로 올리고\n",
    "df_show = df_thresh.reset_index(drop=True)\n",
    "\n",
    "# 2) 컬럼 순서 재배치 (원하는 순서대로)\n",
    "df_show = df_show[[\n",
    "    \"label\", \"alg\",\n",
    "    \"roc_auc\", \"best_thresh\",\n",
    "    \"precision\", \"recall\", \"f1\"\n",
    "]]\n",
    "\n",
    "# 3) 숫자 포맷 지정\n",
    "fmt = {\n",
    "    \"roc_auc\":    \"{:.3f}\",\n",
    "    \"best_thresh\":\"{:.2f}\",\n",
    "    \"precision\":  \"{:.3f}\",\n",
    "    \"recall\":     \"{:.3f}\",\n",
    "    \"f1\":         \"{:.3f}\"\n",
    "}\n",
    "\n",
    "# 4) 스타일 적용 (수정된 부분만 표시)\n",
    "(df_show\n",
    " .style\n",
    " .format(fmt)\n",
    " .set_table_styles([\n",
    "     {\"selector\":\"th\", \"props\":[(\"background-color\",\"#F0F0F0\")]},\n",
    "     {\"selector\":\"td\", \"props\":[(\"padding\",\"4px 8px\")]}\n",
    " ])\n",
    " .hide(axis=\"index\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_da43a th {\n",
       "  background-color: #F0F0F0;\n",
       "}\n",
       "#T_da43a td {\n",
       "  padding: 4px 8px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_da43a\">\n",
       "  <caption>🔝 ROC AUC 상위 5개 결과</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_da43a_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_da43a_level0_col1\" class=\"col_heading level0 col1\" >alg</th>\n",
       "      <th id=\"T_da43a_level0_col2\" class=\"col_heading level0 col2\" >roc_auc</th>\n",
       "      <th id=\"T_da43a_level0_col3\" class=\"col_heading level0 col3\" >best_thresh</th>\n",
       "      <th id=\"T_da43a_level0_col4\" class=\"col_heading level0 col4\" >precision</th>\n",
       "      <th id=\"T_da43a_level0_col5\" class=\"col_heading level0 col5\" >recall</th>\n",
       "      <th id=\"T_da43a_level0_col6\" class=\"col_heading level0 col6\" >f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_da43a_row0_col0\" class=\"data row0 col0\" >attention</td>\n",
       "      <td id=\"T_da43a_row0_col1\" class=\"data row0 col1\" >xgb_ns_kfold</td>\n",
       "      <td id=\"T_da43a_row0_col2\" class=\"data row0 col2\" >0.997</td>\n",
       "      <td id=\"T_da43a_row0_col3\" class=\"data row0 col3\" >0.43</td>\n",
       "      <td id=\"T_da43a_row0_col4\" class=\"data row0 col4\" >0.995</td>\n",
       "      <td id=\"T_da43a_row0_col5\" class=\"data row0 col5\" >0.989</td>\n",
       "      <td id=\"T_da43a_row0_col6\" class=\"data row0 col6\" >0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_da43a_row1_col0\" class=\"data row1 col0\" >attention</td>\n",
       "      <td id=\"T_da43a_row1_col1\" class=\"data row1 col1\" >xgb_os_kfold</td>\n",
       "      <td id=\"T_da43a_row1_col2\" class=\"data row1 col2\" >0.996</td>\n",
       "      <td id=\"T_da43a_row1_col3\" class=\"data row1 col3\" >0.35</td>\n",
       "      <td id=\"T_da43a_row1_col4\" class=\"data row1 col4\" >0.993</td>\n",
       "      <td id=\"T_da43a_row1_col5\" class=\"data row1 col5\" >0.991</td>\n",
       "      <td id=\"T_da43a_row1_col6\" class=\"data row1 col6\" >0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_da43a_row2_col0\" class=\"data row2 col0\" >attention</td>\n",
       "      <td id=\"T_da43a_row2_col1\" class=\"data row2 col1\" >xgb_ns_kfold</td>\n",
       "      <td id=\"T_da43a_row2_col2\" class=\"data row2 col2\" >0.996</td>\n",
       "      <td id=\"T_da43a_row2_col3\" class=\"data row2 col3\" >0.48</td>\n",
       "      <td id=\"T_da43a_row2_col4\" class=\"data row2 col4\" >0.993</td>\n",
       "      <td id=\"T_da43a_row2_col5\" class=\"data row2 col5\" >0.990</td>\n",
       "      <td id=\"T_da43a_row2_col6\" class=\"data row2 col6\" >0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_da43a_row3_col0\" class=\"data row3 col0\" >attention</td>\n",
       "      <td id=\"T_da43a_row3_col1\" class=\"data row3 col1\" >xgb_os_kfold</td>\n",
       "      <td id=\"T_da43a_row3_col2\" class=\"data row3 col2\" >0.996</td>\n",
       "      <td id=\"T_da43a_row3_col3\" class=\"data row3 col3\" >0.52</td>\n",
       "      <td id=\"T_da43a_row3_col4\" class=\"data row3 col4\" >0.994</td>\n",
       "      <td id=\"T_da43a_row3_col5\" class=\"data row3 col5\" >0.989</td>\n",
       "      <td id=\"T_da43a_row3_col6\" class=\"data row3 col6\" >0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_da43a_row4_col0\" class=\"data row4 col0\" >attention</td>\n",
       "      <td id=\"T_da43a_row4_col1\" class=\"data row4 col1\" >xgb_os_kfold</td>\n",
       "      <td id=\"T_da43a_row4_col2\" class=\"data row4 col2\" >0.996</td>\n",
       "      <td id=\"T_da43a_row4_col3\" class=\"data row4 col3\" >0.42</td>\n",
       "      <td id=\"T_da43a_row4_col4\" class=\"data row4 col4\" >0.996</td>\n",
       "      <td id=\"T_da43a_row4_col5\" class=\"data row4 col5\" >0.989</td>\n",
       "      <td id=\"T_da43a_row4_col6\" class=\"data row4 col6\" >0.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d5ab8bb0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0) df_show 준비 (위에서 이미 만드셨다면 재선언 불필요)\n",
    "df_show = df_thresh.reset_index(drop=True)[[\n",
    "    \"label\",\"alg\",\"roc_auc\",\"best_thresh\",\"precision\",\"recall\",\"f1\"\n",
    "]]\n",
    "\n",
    "# 1) F1 상위 5개\n",
    "df_top_f1 = df_show.sort_values(by=\"f1\", ascending=False).head(5)\n",
    "\n",
    "# 2) ROC AUC 상위 5개\n",
    "df_top_auc = df_show.sort_values(by=\"roc_auc\", ascending=False).head(5)\n",
    "\n",
    "# 3) 숫자 포맷 지정\n",
    "fmt = {\n",
    "    \"roc_auc\":     \"{:.3f}\",\n",
    "    \"best_thresh\": \"{:.2f}\",\n",
    "    \"precision\":   \"{:.3f}\",\n",
    "    \"recall\":      \"{:.3f}\",\n",
    "    \"f1\":          \"{:.3f}\"\n",
    "}\n",
    "\n",
    "# 4) 스타일링 & 출력\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "styled_f1 = (\n",
    "    df_top_f1\n",
    "    .style\n",
    "    .format(fmt)\n",
    "    .set_table_styles([\n",
    "        {\"selector\":\"th\", \"props\":[(\"background-color\",\"#F0F0F0\")]},\n",
    "        {\"selector\":\"td\", \"props\":[(\"padding\",\"4px 8px\")]}\n",
    "    ])\n",
    "    .hide(axis=\"index\")\n",
    "    .set_caption(\"🔝 F1 상위 5개 결과\")\n",
    ")\n",
    "\n",
    "styled_auc = (\n",
    "    df_top_auc\n",
    "    .style\n",
    "    .format(fmt)\n",
    "    .set_table_styles([\n",
    "        {\"selector\":\"th\", \"props\":[(\"background-color\",\"#F0F0F0\")]},\n",
    "        {\"selector\":\"td\", \"props\":[(\"padding\",\"4px 8px\")]}\n",
    "    ])\n",
    "    .hide(axis=\"index\")\n",
    "    .set_caption(\"🔝 ROC AUC 상위 5개 결과\")\n",
    ")\n",
    "\n",
    "# Jupyter 에선 아래 두 줄만 실행하시면 순서대로 테이블이 렌더링됩니다.\n",
    "styled_f1\n",
    "styled_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# 디렉토리 생성\n",
    "os.makedirs('./fig/confusion_matrices', exist_ok=True)\n",
    "\n",
    "# metric 분리\n",
    "cm_metrics = ['true_0_pred_0', 'true_0_pred_1', 'true_1_pred_0', 'true_1_pred_1']\n",
    "f1_metrics = ['f1_macro', 'f1_micro']\n",
    "cm_metrics = [f'test_{m}' for m in cm_metrics]\n",
    "f1_metrics = [f'test_{m}' for m in f1_metrics]\n",
    "\n",
    "# pivot\n",
    "mean_cm_df = SUMMARY_EVAL[SUMMARY_EVAL['metric'].isin(cm_metrics)].pivot(index=['label', 'alg'], columns='metric', values='mean')\n",
    "std_cm_df = SUMMARY_EVAL[SUMMARY_EVAL['metric'].isin(cm_metrics)].pivot(index=['label', 'alg'], columns='metric', values='SD')\n",
    "f1_df = SUMMARY_EVAL[SUMMARY_EVAL['metric'].isin(f1_metrics)].pivot(index=['label', 'alg'], columns='metric', values='mean')\n",
    "\n",
    "# 시각화 및 저장\n",
    "for idx in mean_cm_df.index:\n",
    "    try:\n",
    "        mean_cm = np.array([\n",
    "            [mean_cm_df.loc[idx, 'test_true_0_pred_0'], mean_cm_df.loc[idx, 'test_true_0_pred_1']],\n",
    "            [mean_cm_df.loc[idx, 'test_true_1_pred_0'], mean_cm_df.loc[idx, 'test_true_1_pred_1']]\n",
    "        ])\n",
    "        std_cm = np.array([\n",
    "            [std_cm_df.loc[idx, 'test_true_0_pred_0'], std_cm_df.loc[idx, 'test_true_0_pred_1']],\n",
    "            [std_cm_df.loc[idx, 'test_true_1_pred_0'], std_cm_df.loc[idx, 'test_true_1_pred_1']]\n",
    "        ])\n",
    "        annotations = np.empty_like(mean_cm, dtype=object)\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                annotations[i, j] = f\"{mean_cm[i, j]:.1f}±{std_cm[i, j]:.1f}\"\n",
    "\n",
    "        # f1 score 값\n",
    "        macro_f1 = f1_df.loc[idx, 'test_f1_macro']\n",
    "        micro_f1 = f1_df.loc[idx, 'test_f1_micro'] if 'test_f1_micro' in f1_df.columns else None\n",
    "\n",
    "        # 플롯\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(mean_cm, annot=annotations, fmt='', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "        plt.title(f'Confusion Matrix: {idx[0]} | {idx[1]} (mean ± std)')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.ylabel('True label')\n",
    "\n",
    "        # 텍스트로 F1 표시\n",
    "        f1_text = f\"Macro F1: {macro_f1:.3f}\"\n",
    "        if micro_f1 is not None:\n",
    "            f1_text += f\" | Micro F1: {micro_f1:.3f}\"\n",
    "        plt.figtext(0.5, -0.05, f1_text, ha='center', fontsize=10)\n",
    "\n",
    "        # 저장\n",
    "        filename = f\"confmat_{idx[0]}_{idx[1]}.png\".replace(\" \", \"_\")\n",
    "        filepath = os.path.join('./fig/confusion_matrices', filename)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {idx} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    split  test_inst_0  test_inst_1  test_f1_1\n",
      "35  fold2         6468         4893   0.742617\n",
      "40  fold3         5859         5334   0.772129\n",
      "41  fold1         6174         5838   0.761541\n",
      "42  fold4         4410         6027   0.803188\n",
      "47  fold5         4641         5355   0.754143\n"
     ]
    }
   ],
   "source": [
    "worst_splits = RESULTS_EVAL[\n",
    "    (RESULTS_EVAL['label'] == 'attention') &\n",
    "    (RESULTS_EVAL['alg'] == 'rf_ns') &\n",
    "    (RESULTS_EVAL['test_f1_1'] < 1.1)\n",
    "]\n",
    "print(worst_splits[['split', 'test_inst_0', 'test_inst_1', 'test_f1_1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional\n",
    "\n",
    "\n",
    "def feature_importance(\n",
    "    estimator\n",
    "):\n",
    "    if not hasattr(estimator, 'feature_names_in_') or not hasattr(estimator, 'feature_importances_'):\n",
    "        return None\n",
    "    \n",
    "    names = estimator.feature_names_in_\n",
    "    importances = estimator.feature_importances_\n",
    "    \n",
    "    return names, importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "IMPORTANCE_EVAL = defaultdict(list)\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "\n",
    "for l in ['attention']:\n",
    "    dir_l = os.path.join(DIR_EVAL, l)\n",
    "    if not os.path.exists(dir_l):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(dir_l):\n",
    "        res = load(os.path.join(dir_l, f))\n",
    "\n",
    "        f_norm = f[:f.index('.pkl')]\n",
    "        alg = f_norm[:f.rindex('#')]\n",
    "        \n",
    "        feat_imp = feature_importance(res.estimator)\n",
    "        if not feat_imp:\n",
    "            continue\n",
    "            \n",
    "        names, importance = feat_imp\n",
    "        new_names = []\n",
    "        for n in names:\n",
    "            for c in res.categories:\n",
    "                n = n.replace(f'{c}_', f'{c}=')\n",
    "            new_names.append(n)\n",
    "        \n",
    "        d = pd.DataFrame(\n",
    "            importance.reshape(1, -1),\n",
    "            columns=new_names\n",
    "        )\n",
    "        IMPORTANCE_EVAL[(l, alg)].append(d)\n",
    "        \n",
    "\n",
    "IMPORTANCE_SUMMARY = []\n",
    "\n",
    "for (l, alg), v in IMPORTANCE_EVAL.items():\n",
    "    new_v = pd.concat(\n",
    "        v, axis=0\n",
    "    ).fillna(0.0).mean().reset_index().set_axis(\n",
    "        ['feature', 'importance'], axis=1\n",
    "    ).assign(\n",
    "        label=l,\n",
    "        alg=alg\n",
    "    )\n",
    "    IMPORTANCE_SUMMARY.append(new_v)\n",
    "    \n",
    "IMPORTANCE_SUMMARY = pd.concat(IMPORTANCE_SUMMARY, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%R` not found.\n"
     ]
    }
   ],
   "source": [
    "%%R -i IMPORTANCE_SUMMARY -w 26 -h 16 -u cm\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(patchwork)\n",
    "\n",
    "data <- IMPORTANCE_SUMMARY %>% filter(label == 'attention')\n",
    "\n",
    "p_label <- ggplot() + geom_text(\n",
    "    aes(x = .5, y = .5),\n",
    "    label = 'Attention',\n",
    "    family = 'ssp',\n",
    "    fontface = 'bold',\n",
    "    size = 4\n",
    ") + theme_void()\n",
    "\n",
    "p_rf <- ggplot(\n",
    "    data %>% filter(alg == 'rf_os') %>% top_n(n = 10, wt = importance),\n",
    "    aes(x = reorder(feature, -importance), y = importance)\n",
    ") + geom_col() +\n",
    "    THEME_DEFAULT + theme(\n",
    "        axis.text.x = element_text(angle = 90, size = 10, hjust = 1, vjust = .5),\n",
    "        axis.title.x = element_blank(),\n",
    "        axis.title.y = element_blank()\n",
    "    ) + labs(subtitle = 'Random Forest')\n",
    "\n",
    "p_xgb <- ggplot(\n",
    "    data %>% filter(alg == 'xgb_os') %>% top_n(n = 10, wt = importance),\n",
    "    aes(x = reorder(feature, -importance), y = importance)\n",
    ") + geom_col() +\n",
    "    THEME_DEFAULT + theme(\n",
    "        axis.text.x = element_text(angle = 90, size = 10, hjust = 1, vjust = .5),\n",
    "        axis.title.x = element_blank(),\n",
    "        axis.title.y = element_blank()\n",
    "    ) + labs(subtitle = 'XGBoost')\n",
    "\n",
    "p <- p_label / (p_rf | p_xgb) + plot_layout(heights = c(1.1, 10))\n",
    "\n",
    "ggsave('./fig/imp_attention.pdf', plot = p, width = 26, height = 16, unit = 'cm', device = cairo_pdf)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ray-env)",
   "language": "python",
   "name": "ray-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
