# ML ëª¨ë¸ë§ (Attention ì˜ˆì¸¡ - K-EmoPhone ê¸°ë°˜)

ì´ Jupyter Notebookì€ K-EmoPhone ë°ì´í„°ì…‹ ê¸°ë°˜ì˜ `attention` ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ë° ì´ˆì ì„ ë‘¡ë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

## ğŸ“¦ ì‚¬ìš© ë°ì´í„°
- **ë°ì´í„°ì…‹**: K-EmoPhone (attention ë¼ë²¨ í¬í•¨)
- **í˜•íƒœ**: `attention.pkl` íŒŒì¼ì—ì„œ ë¡œë“œëœ feature matrix (`X`), label (`y`), ê·¸ë£¹ ì •ë³´ (`group`), ì‹œê°„ ì •ë³´ (`t`)

## âš™ï¸ ì£¼ìš” ì²˜ë¦¬ ê³¼ì •
1. **í”¼ì²˜ êµ¬ì„±**:
   - ì‹œê³„ì—´ ë° ESM ê¸°ë°˜ì˜ ë‹¤ì–‘í•œ í†µê³„ í”¼ì²˜ í¬í•¨ (ì˜ˆ: `bpm#AVG#60`, `EDA#TSC#120`, `ESM#HRN=EVENING` ë“±)
   - ë²”ì£¼í˜• í”¼ì²˜ì™€ ìˆ˜ì¹˜í˜• í”¼ì²˜ êµ¬ë¶„í•˜ì—¬ ê´€ë¦¬

2. **ëª¨ë¸ ì •ì˜ ë° ì‹¤í—˜ ì„¸íŒ…**:
   - ì‚¬ìš© ëª¨ë¸:
     - `LogisticRegression (L1)`
     - `RandomForestClassifier`
     - `LightGBMClassifier`
     - `VotingClassifier (Logreg + RF + LGBM)`
     - `EvXGBClassifier` (ì»¤ìŠ¤í…€)
   - ëª¨ë“  ëª¨ë¸ì€ `SelectFromModel(LinearSVC)` ê¸°ë°˜ feature selectionì„ ì ìš©
   - StratifiedGroupKFold (5-fold) ë°©ì‹ìœ¼ë¡œ êµì°¨ê²€ì¦ ìˆ˜í–‰

3. **ë³‘ë ¬ ì²˜ë¦¬**:
   - `ray`ë¥¼ í™œìš©í•œ ë³‘ë ¬ í•™ìŠµ (`on_ray(num_cpus=12)`)

## ğŸ§  ì£¼ìš” ëª¨ë¸ ì˜ˆì‹œ: LightGBM
```python
LGBMClassifier(
    random_state=42,
    learning_rate=0.03,
    max_depth=5,               
    num_leaves=31,              
    min_child_samples=10,     
    reg_alpha=2.0,
    reg_lambda=2.0,
    subsample=0.8,
    colsample_bytree=0.8,
    n_estimators=100,
    importance_type='gain',
    verbosity=-1               
)
```

## ğŸ’¾ ì¶œë ¥ ê²°ê³¼
- `eval/attention/` ê²½ë¡œì— ê° ëª¨ë¸ì˜ í‰ê°€ ê²°ê³¼ ì €ì¥
- ìµœì¢…ì ìœ¼ë¡œ `.pkl` í˜•ì‹ì˜ ëª¨ë¸ ê°ì²´ë¥¼ exportí•˜ì—¬ ì¶”ë¡  API ë˜ëŠ” ëŒ€ì‹œë³´ë“œì—ì„œ ì‚¬ìš© ê°€ëŠ¥

## âœ… ì˜ˆì¸¡ ëŒ€ìƒ
- ì´ì§„ ë¶„ë¥˜ (`attention_bin`) : ì§‘ì¤‘ / ë¹„ì§‘ì¤‘ ìƒíƒœ
- `y` ë¼ë²¨ ì˜ˆì‹œ: `array([0, 1, 1, 0, ...])`

---

ğŸ“ ì°¸ê³  íŒŒì¼: `ml_model.ipynb`
